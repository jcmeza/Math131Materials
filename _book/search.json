[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Numerical Analysis Lecture Notes",
    "section": "",
    "text": "Preface\nThe first time I heard about numerical analysis was a course at Rice University taught by Prof. Richard Tapia.\nAfter I graduated and as a freshly minted PhD, I had the opportunity to teach the same course as a postdoc. It was both a pleasure to teach the same material and utterly terrifying as it challenged me to go over every single concept I thought I knew so well and realize that in fact there were subtleties that I had never known existed.\nOver the years I’ve practiced computational mathematics at various places including Exxon Production Research, Sandia National Laboratories, and Lawrence Berkeley Laboratory. The one common thread in all of these places was the sheer breadth of the applications that one can apply the fundamental concepts of numerical analysis to real-world problems. However, it also became clear that while the concepts were widely applicable, many of the techniques didn’t work, either because of the scale of the problem or because of the underlying assumptions. As we used to joke, “In theory, there is no difference between theory and practice, but in practice there is.\nEver since I have always wanted to document the types of problems that a practicing numerical analyst might encounter in everyday situations. Without taking anything away from standard text books, what I wanted to do was to provide the underlying concepts, but also point out where the standard assumptions might fail and what one can do to overcome those barriers.\nThis book then is intended as an undergraduate level numerical analysis course, with all of the Important concepts described. In addition, however, the reader will frequently be pointed to a real-world problem for which those same standard techniques will not work - at least not out of the box. Instead, I’ll try to point to the fundamental concepts as a starting point and how one can use those techniques to adapt, modify, and extend them to work on real-world problems.\nThis is a compilation of various numerical analysis notes from over the years. The material is at the level of a junior or senior level applied mathematics student. The main reason for this book is to include code snippets that demonstrate some of the fundamental concepts in numerical analysis.\nHere, our goal is to provide both an introduction to some of the major numerical methods techniques as well as some practical advice as to when one would use one method versus another.\nAnother goal is to give the reader some of the elementary theoretical foundations needed to be able to analyze the methods and their performance. One consequence of this is that when one encounters real-world problems, the assumptions that mathematicians make when analyzing the methods will generally not hold. Nonetheless it is important to be able to recognize the assumptions being made so that one can recognize when a method isn’t working because the assumptions have been violated rather than because of some other issue.\nFinally, my own experience has taught me that the history behind many of the methods can provide a rich context as to why a numerical method was initially proposed and how others extended the methods to other problems. This continual evolution of numerical analysis can sometimes point the student towards how they could in turn extend the methods to their own problems.\nAcknowledgments\nI am grateful for all the insightful comments offered by the many people who have looked over the draft versions of these notes. The generosity and expertise of one and all have improved these notes in innumerable ways and saved me from many errors; those that inevitably remain are entirely my own responsibility.\nThis is a Quarto book. To learn more about Quarto books visit https://quarto.org/docs/books.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "Intro.html",
    "href": "Intro.html",
    "title": "Introduction",
    "section": "",
    "text": "Numerical analysis has a long history that goes back beyond the modern electronic computing era. With the advent of computers the field has grown even more rapidly and is now used in virtually all scientific areas. The history is one of computational advances going hand in hand with advances in numerical methods.\nBut what is numerical analysis? One popular definition of numerical analysis “is the study of algorithms for the problems of continuous mathematics” (Trefethen 2022). This is a great definition and captures the essence of numerical analysis succinctly. I also adhere to this definition, although I would expand or change the last part to include some areas of discrete mathematics as well.\nIn this book, I would also like to advance another possible way of viewing numerical analysis. In practice, numerical analysis is a balancing act of several goals when solving mathematical problems on a computer. From this viewpoint, numerical analysis is the fine art of balancing accuracy, efficiency, and robustness of numerical algorithms for mathematical problems.\nThis book is intended as an introduction to the fundamental concepts and methods used in numerical analysis. As such, we need to assume that the reader has a foundation in some of the basic concepts of calculus. In particular, we will have need to use ideas such as the Mean Value Theorem, the Intermediate Value Theorem, the Weighted Mean Value Theorem, and Taylor’s Theorem. You will find a brief review of the first 3 of these in the Appendix. Here we will provide a quick refresher on Taylor’s Theorem - if you are familiar with this idea and how to use it, you may want to skip to the next section.\nAny numerical method today will also entail some form of implementation on a computer. As such, we also review how arithmetic is done on a computer and the consequences of only being able to do computations with finite precision. If you’re familiar with these concepts, you may also want to skip those sections.\nWhichever view you decide to take, I hope you enjoy the concepts and the immense practical value and impact that numerical analysis has had on solving some of today’s most pressing scientific and societal problems.",
    "crumbs": [
      "Introduction"
    ]
  },
  {
    "objectID": "Foundations.html",
    "href": "Foundations.html",
    "title": "1  Foundations",
    "section": "",
    "text": "1.1 Frequently Used Theorems from Calculus\nNumerical analysis relies on several fundamental theorems or analysis. We will refer to several of these repeatedly and have use of the following 4 in particular.\nWe will be looking at numerous cases of continuous functions over closed and bounded intervals. The following theorem will prove useful in our analyses.\nRemark: One way to interpret the IVT says is that if a continuous function on an interval takes on any 2 values, it takes on every value in between. This will be particularly useful in our analysis of root finding methods.\nSimilar to the MVT above, there is a variation that applies to integrals. It is well worth noting that in this case, there is an important assumption without which the theorem does not apply, so care must be taken when applying it to certain problems.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Foundations</span>"
    ]
  },
  {
    "objectID": "Foundations.html#frequently-used-theorems-from-calculus",
    "href": "Foundations.html#frequently-used-theorems-from-calculus",
    "title": "1  Foundations",
    "section": "",
    "text": "Theorem 1.1 (Mean Value Theorem) Suppose that (1) f is continuous on the closed finite interval \\([a,b]\\) and (2) \\(f^\\prime(x)\\) exists for every x in the open interval \\((a,b)\\). Then there exists a point \\(c\\) such that\n\\[\na &lt; c &lt; b\n\\]\nand\n\\[\nf^\\prime(c) = \\frac{f(b) - f(a)}{b-a}\n\\]\n\n\n\nTheorem 1.2 (Intermediate Value Theorem) Suppose that (1) f is continuous on the closed finite interval \\([a,b]\\) and (2) \\(f(a) &lt; c &lt; f(b)\\). Then there exists some point \\(x \\in [a,b]\\) such that \\(f(x) = c\\).\n\n\n\n\nTheorem 1.3 (Weighted Mean Value Theorem for Integrals) Suppose that \\(f \\in C[a,b]\\), the Riemann integral of \\(g\\) exists on \\([a,b]\\), and \\(g(x)\\) does not change sign of \\([a,b]\\). Then there exists a number \\(c \\in (a,b)\\) such that\n\\[\n\\int_a^b f(x) g(x) dx = f(c) \\int_a^b g(x) dx\n\\]",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Foundations</span>"
    ]
  },
  {
    "objectID": "Foundations.html#computer-programming",
    "href": "Foundations.html#computer-programming",
    "title": "1  Foundations",
    "section": "1.2 Computer Programming",
    "text": "1.2 Computer Programming\nIn terms of programming, we suggest one of 3 possible languages: Matlab, python, or R. Python and R have the advantage of being open-source and most of our examples will be in R and sometimes in python. In addition, both python and R can be easily installed on most computer platforma and both have powerful programming environments similar to Matlab. For python, one can use JupyterLab (jupyter); for R, one can use Rstudio/Posit (Posit).\nWe will also note that in real-world applications, most scientific codes will use other languages such as Fortran or C++. For the purposes of this introductory course, any high-level language will suffice.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Foundations</span>"
    ]
  },
  {
    "objectID": "Foundations.html#other-useful-references",
    "href": "Foundations.html#other-useful-references",
    "title": "1  Foundations",
    "section": "1.3 Other Useful References",
    "text": "1.3 Other Useful References\nYou should be able to find references to all of the material here in standard introductory courses on calculus. A good online reference for some of the material above can be found at openstax.org.\n\nMean Value Theorem\nIntermediate Value Theorem\nMean Value Theorem for Integrals\nTaylor polynomials and Taylor’s Theorem\n\nAnother good set of resources are the one-pagers provided by the UCM Math Center. You can check them all out at: UCM The Math Center and in particular the Math 23 refresher one-pager might prove useful: Math 23 refresher.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Foundations</span>"
    ]
  },
  {
    "objectID": "TaylorTheorem.html",
    "href": "TaylorTheorem.html",
    "title": "2  Taylor’s Theorem",
    "section": "",
    "text": "2.1 Taylor Polynomials\nA fact that is highly underappreciated is that most functions in mathematics cannot be evaluated exactly. Common examples include functions such as \\(\\exp(x), \\cos(x), \\ln(x)\\).\nThis leads us to consider ways to approximate a function \\(f(x)\\) by something else that is easier to compute. Let’s consider the simple case of the exponential:\n\\[\n\\exp(x) = \\sum_{k=0}^{\\infty} \\frac{x^k}{k!} = 1 + x + \\frac{x^2}{2!} + \\frac{x^3}{3!} + \\ldots\n\\]\nThe first approximation we might try is \\(1+x\\), which is clearly easy to compute, but likely not very accurate. A second attempt might be to use the first three terms \\(1 + x + \\frac{x^2}{2}\\). We could proceed in the obvious way, adding new terms until we are satisifed or we get tired.\nBut there is an underlying question - when should we stop? One would hope that as \\(k\\) increases we should get more accuracy, but it’s also clear that the more terms we use the harder is to compute the approximation.\nGoal: Find functions that approximate \\(f\\) at some point, but with some guarantee of accuracy. Hopefully, these approximating functions are also cheaper to compute than the original function.\nA first natural approach is to use a polynomial. They are 1) easy to understand, 2) easy to compute, and 3) in general easier to analyze. One commonly used approach is that of approximating a function via a Taylor polynomial. In addition, we will see that Taylor’s Theorem with remainder can be used to analyze our approximations. You should be familiar with both the concepts and how to apply them in different situations.\nLet’s take a quick look at how some of the approximations work on \\(exp(x).\\)\nSome observations:\nUsing Taylor polynomials to approximate a function \\(f(x)\\) leads to several natural questions:\nThe question of the existence of all of the derivatives is a non-trivial one. We will have need of them in order to analyze the approximation, but in practice, one rarely has more than the first derivatives available. For the remainder of the course, we will assume that we have enough derivatives to allow us to proceed with our analysis, but the student should be aware that such assumptions are difficult to establish in real-world problems.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Taylor's Theorem</span>"
    ]
  },
  {
    "objectID": "TaylorTheorem.html#taylor-polynomials",
    "href": "TaylorTheorem.html#taylor-polynomials",
    "title": "2  Taylor’s Theorem",
    "section": "",
    "text": "Important\n\n\n\nIn numerical analysis there is a constant trade off between accuracy and computational work. We seek to balance these two goals for a given problem.\n\n\n\n\nDefinition 2.1 (Taylor Polynomials) Suppose \\(f\\) is a function with \\(n\\) derivatives at the point \\(x=x_0.\\) Then the \\(n\\)th Taylor polynomial for \\(f\\) at \\(x_0\\) is given by:\n\\[\nP_n(x) = f(x_0) + (x-x_0) f^{\\prime}(x_0)+ \\frac{(x-x_0)^2}{2!}f^{\\prime\\prime}(x_0) + \\cdots + \\frac{(x-x_0)^n}{n!} f^{(n)}(x_0)\n\\tag{2.1}\\]\n\n\n\n\n\nFirst and second order approximations to \\(e^x\\). Red is exp(x), green is \\(1 + x + x^2/2\\), blue is \\(1 + x\\)\n\n\n\n\nAs \\(n\\) increases, we might expect accuracy to increase\nAs we move away from the selected point \\(x_0\\), we might expect the accuracy to decrease.\n\n\n\nHow do we know all the derivatives exist?\nWhat is the error when approximating \\(f(x)\\) by \\(P_n(x)\\)?\nGiven a desired accuracy, how do we choose \\(n\\)?",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Taylor's Theorem</span>"
    ]
  },
  {
    "objectID": "TaylorTheorem.html#taylors-theorem",
    "href": "TaylorTheorem.html#taylors-theorem",
    "title": "2  Taylor’s Theorem",
    "section": "2.2 Taylor’s Theorem",
    "text": "2.2 Taylor’s Theorem\nIn order to answer questions 2-3 above, we will need the following theorem.\n\nTheorem 2.1 (Taylor’s Theorem with remainder) Let \\(f \\in C^{n+1}\\) on an interval \\(I\\) containing the real number \\(x_0\\). Also, let \\(P_n(x)\\) be the \\(n\\)th Taylor polynomial of \\(f\\) at \\(x_0\\) as defined by Equation 2.1. Then for each \\(x\\) in \\(I\\), we can write \\[\nf(x) = P_n(x) + R_n(x),\n\\] where \\(R_n(x)\\) is given by: \\[\nR_n(x) = \\frac{(x-x_0)^{n+1} }{(n+1)!} f^{(n+1)}(\\xi),  \n\\] for some \\(\\xi\\) between \\(x_0\\) and \\(x\\).\n\n\n\n\n\n\n\nImportant\n\n\n\n\nIt is important to note that the value of \\(\\xi\\) will depend on \\(x\\), (and hence the derivative term \\(f^{n+1}(\\xi)\\)).\n\n\n\nTaylor’s theorem will prove to be incredibly useful in our analysis of algorithms. In particular, we will use it to determine the accuracy of various approximations and more importantly it will be essential in the error analysis of algorithms.\n\n\n\n\n\n\nRemark\n\n\n\nWe will have use of other forms of Taylor’s Theorem - you should get comfortable recognizing and using them. For example, use the substitution \\(h = x - x_0\\) to rewrite Taylor’s Theorem.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Taylor's Theorem</span>"
    ]
  },
  {
    "objectID": "TaylorTheorem.html#examplesexercises",
    "href": "TaylorTheorem.html#examplesexercises",
    "title": "2  Taylor’s Theorem",
    "section": "2.3 Examples/Exercises",
    "text": "2.3 Examples/Exercises\n\nExample 2.1 Consider \\(f(x) = \\exp(x)\\). Evaluate the \\(nth\\) Taylor polynomial about the point \\(x_0 = 0\\) and evaluate its remainder at \\(x_0\\).\n\n\nSolution. \n\n\nFirst we write down the Taylor Polynomial for \\(f(x) = \\exp(x)\\) at \\(x_0\\).\n\\[  P_n(x) = f(x_0) + (x-x_0) f^{\\prime}(x_0)+ \\frac{(x-x_0)^2}{2!}f^{\\prime\\prime}(x_0) + \\cdots + \\frac{(x-x_0)^n}{n!} f^{(n)}(x_0)  \\]\nNext we note that \\(f^{(k)}(x) = \\exp(x), k = 0, 1, 2, \\ldots\\), so all of the derivatives exist. In particular, for the point \\(x_0 = 0\\), we can also evaluate the function and all of its derivatives, \\(e^{x_0} = e^0 = 1 , \\forall \\ k = 0, 1, \\ldots .\\)\n\nThat means we can write the Taylor polynomial and the remainder term as follows:\n\n\\[  \\begin{aligned} P_n(x) &= 1 + x + \\frac{x^2}{2!} + \\cdots + \\frac{x^n}{n!} \\\\ R_n(x) &= \\frac{x^{n+1} }{(n+1)!} \\large{ e ^{\\xi(x)}}, \\end{aligned} \\]\n\n\n\n\nExercise 2.1 (In class exercise) Consider \\(f(x) = \\sqrt[3]{x}\\). a) Find the first and second Taylor Polynomials for \\(f(x)\\) at \\(x_0=8\\). b) Evaluate both Taylor polynomials at the point \\(x=11\\).\n\n\nSolution. \n\n\nLet’s break this down into steps:\n\nStep 1. Writing out the first two polynomials using Taylor’s theorem we see that:\n\\[\n\\begin{aligned}  \nP_1(x) &= f(x_0) + (x-x_0) f^{\\prime}(x_0) \\\\  \nP_2(x) &= f(x_0) + (x-x_0) f^{\\prime}(x_0)+ \\frac{(x-x_0)^2}{2!}f^{\\prime\\prime}(x_0)\n\\end{aligned}  \n\\] Step 2. Now let’s substitue for the point \\(x_0=8\\): \\[\n\\begin{aligned}\nP_1(x) &= f(8) + (x-8) f^{\\prime}(8) \\\\  \nP_2(x) &= f(8) + (x-8) f^{\\prime}(8)+ \\frac{(x-8)^2}{2!}f^{\\prime\\prime}(8)  \n\\end{aligned}\n\\tag{2.2}\\] Step 3. The next step is to calculate the various derivative terms in the polynomial and evaluate them at the point \\(x_0=8\\). It is helpful to write out a table that includes all of the necessary terms as shown below.\n\nTaylor Polynomial terms for \\(\\sqrt[3] x\\)\n\n\n\n\n\n\nTerm\nEvaluation at \\(x_0=8\\)\n\n\n\n\n\\(f(x) = \\large{\\sqrt[3] x}\\)\n\\(f(8) = \\large{\\sqrt[3] 8} = 2\\)\n\n\n\\(f^\\prime(x) = \\Large{\\frac{1}{3x^{2/3}}}\\)\n\\(f^\\prime(8)= \\Large{\\frac{1}{3\\cdot 8^{2/3}}} = \\frac{1}{12}\\)\n\n\n\\(f^{\\prime \\prime}(x) = \\Large{\\frac{-2}{9x^{5/3}}}\\)\n\\(f^{\\prime \\prime}(8) = -\\Large{\\frac{2}{9\\cdot 8^{5/3}}} = - \\frac{1}{144}\\)\n\n\n\nStep 4. Finally, inserting these values into Equation 2.2 yields:\n\\[\n\\begin{aligned}\nP_1(x) &= 2 + \\frac{(x-8)}{12} \\\\  \nP_2(x) &= 2 + \\frac{(x-8)}{12} - \\frac{(x-8)^2}{288}  \n\\end{aligned}\n\\]\n\nEstimate \\(f(11) = {\\sqrt[3] 11}\\)\n\n\\[\n\\begin{aligned}\nP_1(11) &= 2 + \\frac{(11-8)}{12} = 2.25 \\\\  \nP_2(11) &= 2 + \\frac{(11-8)}{12} - \\frac{(11-8)^2}{288} = 2.21875  \n\\end{aligned}  \n\\]\nFor comparison, \\({\\normalsize \\sqrt[3] 11 } \\approx {\\normalsize 2.22398009}\\)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Taylor's Theorem</span>"
    ]
  },
  {
    "objectID": "TaylorTheorem.html#other-forms-for-the-remainder-term",
    "href": "TaylorTheorem.html#other-forms-for-the-remainder-term",
    "title": "2  Taylor’s Theorem",
    "section": "2.4 Other forms for the Remainder Term",
    "text": "2.4 Other forms for the Remainder Term\nThere are alternate forms for the remainder term that you may see, the most common of which is the integral form, which is given by:\n\\[\nR_n(x) = \\frac{1}{n!} \\int_{x_0}^{x} (x - t)^n f^{(n+1)}(t) dt,  \n\\]\nIt is fairly easy to show that the two forms are equivalent through the use of the Weighted Mean Value Theorem for Integrals (Theorem 1.3). First note that the first term \\((x-t)^n\\) does not change sign over the interval \\([x_0, x]\\). Also by assumption \\(f^{(n+1)}\\) is continuous on the same interval. As a result, we can use the WMVTI as follows.\n\\[\n\\begin{aligned}\n\\int_{x_0}^{x} (x - t)^n f^{(n+1)}(t) dt &=  f^{(n+1)}(\\xi) \\int_{x_0}^{x} (x - t)^n  dt, \\\\\n&= f^{(n+1)}(\\xi) \\cdot \\frac{\\quad - (x - t)^{n+1}}{n+1} \\Bigg| _{x_0}^x, \\\\\n&= f^{(n+1)}(\\xi) \\cdot \\frac{\\quad (x - x_0)^{n+1}}{n+1}.\n\\end{aligned}\n\\]\nThe last step follows since the integrand vanishes at the upper endpoint. If We now multiply both sides by \\(1/n!\\) we get the desired result.\n\n\n\n\n\n\nRemark\n\n\n\nThere are other forms of the remainder term as well. The ones presented here are the most common. Which form you decide to use will depend on the particular situation. But it’s nice to have options.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Taylor's Theorem</span>"
    ]
  },
  {
    "objectID": "TaylorTheorem.html#choosing-p_nx-to-achieve-a-desired-accuracy",
    "href": "TaylorTheorem.html#choosing-p_nx-to-achieve-a-desired-accuracy",
    "title": "2  Taylor’s Theorem",
    "section": "2.5 Choosing \\(P_n(x)\\) to achieve a desired accuracy",
    "text": "2.5 Choosing \\(P_n(x)\\) to achieve a desired accuracy\nThis now leaves us with our finaly question: can we determine what degree polynomial is required for a given accuracy?\n\nExample 2.2 Once again, let’s consider \\(f(x) = \\exp(x)\\). Evaluate the \\(nth\\) Taylor polynomial about the point \\(x_0 = 0\\). How big should \\(n\\) be to approximate \\(\\exp(1)\\) to an accuracy of \\(10^{-9}.\\)\n\n\nSolution. \n\nRecall that \\[\nR_n(x) = \\frac{x^{n+1}}{(n+1)!} \\cdot \\large{e^{\\xi}}\n\\] Evaluating at \\(x = 1\\) gives us \\[\nR_n(x) = \\frac{1}{(n+1)!} \\cdot \\large{e^\\xi}\n\\] Our overall goal is to bound the remainder (error) such that: \\[\nl \\leq R_n(1) \\leq u\n\\] where \\(l,u\\) are some chosen bounds. In general it will be easier to work with the following form:\n\\[\n| R_n(1) | \\leq M\n\\] for some value of \\(M\\), in this case e.g. we would let \\(M = 10^{-9}\\).\nAs with many cases in numerical analysis, we will need to make use of any information we may have about the function and the domain we’re working with. In particular for this function we know that, \\(0 &lt; \\xi &lt; 1,\\) by Taylor’s Theorem. That means that: \\[\n1 = \\large{e^0} &lt; \\large{e^\\xi} &lt; \\large{e^1} = \\large{e}\n\\] dividing by \\((n+1)!\\) we see that: \\[\n\\frac{1}{(n+1)!} &lt; \\frac{\\large{e^\\xi}}{(n+1)!} &lt;  \\frac{\\large{e}}{(n+1)!}\n\\] Note that the middle term is just \\(R_n(1)\\). Since we’re not supposed to actually know the value of \\(\\large{e}\\), let’s just assume that we know a rough upper bound, say 3, (but we could just as easily have used any other number) and substitute it into the last term. Then what we’re really saying is that we would like to have: \\[\n| R_n(1) | &lt; \\frac{3}{(n+1)!} &lt; 10^{-9}\n\\] A quick calculation suggests that \\(n+1 \\geq 13\\) satisfies this condition, so that a \\(12th\\) degree Taylor polynomial should gives us the desired accuracy.\n\nExercise 2.2 (In class exercise)  \n\nWrite out the \\(nth\\) Taylor Polynomial for \\(f(x) = \\sin (x)\\) about \\(\\pi/4\\).\nFind the smallest degree Taylor polynomial such that the remainder \\[\n| R_n(\\pi/4) | &lt; 10^{-6}\n\\]on \\([0, \\pi/4]\\).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Taylor's Theorem</span>"
    ]
  },
  {
    "objectID": "TaylorTheorem.html#summary",
    "href": "TaylorTheorem.html#summary",
    "title": "2  Taylor’s Theorem",
    "section": "2.6 Summary",
    "text": "2.6 Summary\n\nWe showed that we can approximate a given function through the use of a Taylor Polynomial.\nTaylor’s Theorem allows us to write down exactly what the remainder (error) term is.\nTwo (equivalent) forms of the remainder term were introduced: Lagrange form and the Integral Form.\nWe can estimate the degree of the Taylor Polynomial needed to guarantee a desired accuracy over a given interval.\nUseful bounds will depend on knowledge of the given function and its derivatives.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Taylor's Theorem</span>"
    ]
  },
  {
    "objectID": "TaylorTheorem.html#references",
    "href": "TaylorTheorem.html#references",
    "title": "2  Taylor’s Theorem",
    "section": "2.7 References",
    "text": "2.7 References\nA good online reference for some of the material above can be found at openstax.org.\n\nTaylor polynomials and Taylor’s Theorem\n\nAnother good set of resources are the one-pagers provided by the UCM Math Center. You can check them all out at: UCM The Math Center and in particular the Math 23 refresher one-pager might prove useful: Math 23 refresher.\nAnd of course, there’s always Wikepedia:Taylor’s Theorem\nRevised: Tuesday, Sept. 5, 2023",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Taylor's Theorem</span>"
    ]
  },
  {
    "objectID": "Errors.html",
    "href": "Errors.html",
    "title": "3  Errors",
    "section": "",
    "text": "3.1 Sources of Errors\nOne of the first challenges when working in numerical analysis is the question of how to determine when a computed solution is sufficiently accurate. In order to talk about this we first need to develop some nomenclature and definitions that will allow us to quantify more precisely how good a solution we have.\nBoth absolute and relative errors are used in our analysis, but the relative error is generally preferred in practice as it is scale independent, and as long as you stay away from \\(x=0\\).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Errors</span>"
    ]
  },
  {
    "objectID": "Errors.html#sec-errors",
    "href": "Errors.html#sec-errors",
    "title": "3  Errors",
    "section": "",
    "text": "Definition 3.1 Suppose we have \\(x\\) and an approximation \\(\\hat{x}\\). Then the absolute error is given by \\[\n| x - \\hat{x} |.\n\\]\n\n\nDefinition 3.2 Similarly the relative error is defined by \\[\n\\frac{| x - \\hat{x}|}{|x|}.\n\\]\n\n\n\nPrecision and Accuracy\nPrecision and accuracy are often confused. In numerical analysis, they will have a specific meaning.\nBy accuracy, we mean the absolute or relative error of an approximation as defined in (Definition 3.1,Definition 3.2). Precision will refer to the accuracy with which the basic arithmetic operations (+, -, *, /) are performed. More of this to come.\nOne should also note that accuracy is not limited by the precision of a computer - there are many software packages that can provide extended precision in numerical calculations.(Bailey 1993)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Errors</span>"
    ]
  },
  {
    "objectID": "Errors.html#sources-of-errors",
    "href": "Errors.html#sources-of-errors",
    "title": "3  Errors",
    "section": "3.2 Sources of Errors",
    "text": "3.2 Sources of Errors\nThe next question that naturally arises is what types of errors might we encounter in solving a problem numerically and where might they arise? As it turns out, there are many different ways to classify errors. We will use the following general categories:\n\nmodel errors/uncertainty:\n\nerrors in mathematical models used to approximate a real world problem\nerrors in the input data, e.g. physical measurements, observations, etc.\n\napproximation errors:\n\nerrors in approximating our problem due to truncation/discretization , e.g. Taylor series, interpolation, integration.\n\nroundoff errors:\n\nerrors due to the finite precision inherent of computer arithmetic. This is a basic fact of computational mathematics and there is not much we can do to limit these. However, wise choices of algorithms can circumvent some of the problems and bad choices of algorithms can exarcebate them.\n\n\n\n\n\n\n\n\nRemarks\n\n\n\n\n\nModel errors and their quantification is a subject area all of its own - we will not cover it. The interested student can check out the vast literature on topics such as uncertainty quantification, verification, and validation.\nApproximation errors (truncation/discretization) usually dominate other types of errors and their analysis is a major task of numerical analysis\n\n\n\n\n\nExample 3.1 (Approximation/Discretization) Error)  \n\nSuppose we want to compute an approximation to \\(f^{\\prime}(x)\\) for some function \\(f(x)\\) at the point \\(x = x_0\\).\nThis situation might arise if you have the function but do not know \\(f^{\\prime}(x)\\), or perhaps it is too expensive to compute.\nLet’s use Taylor’s Theorem. Recall\n\\[\nf(x) = f(x_0) + (x-x_0)f^{\\prime}(x_0) + \\frac{(x-x_0)^2}{2!} f^{\\prime\\prime}(x_0)+ \\cdots + \\frac{\\ \\ \\quad (x-x_0)^{(n+1)} }{(n+1)!}f^{(n+1)}(c) .\n\\] for some \\(c\\) between \\(x\\) and \\(x_0\\). Note, that we need to assume \\(f\\) has \\(n+1\\) derivatives in some interval.\nNow let’s introduce some new notation. In particular, let\n\\[\nx = x_0 + h, \\quad h &gt; 0,\n\\]\nso that \\[\nh = x - x_0.\n\\]\nThen we can rewrite the Taylor expansion as\n\\[\nf(x_0 + h) = f(x_0) + hf^{\\prime}(x_0) + \\frac{h^2}{2!}f^{\\prime\\prime}(x_0) + \\cdots + \\frac{h^{(n+1)} }{(n+1)!}f^{(n+1)}(c).\n\\]\nRearranging the terms to put the derivative on the left hand side of the equation gives us:\n\\[\nf^{\\prime}(x_0) = \\frac{f(x_0 + h) - f(x_0)}{h} - \\left [ \\frac{h}{2}f^{\\prime\\prime}(x_0) + \\cdots + \\frac{h^{(n)} }{(n+1)!}f^{(n+1)}(c) \\right ].\n\\]\n\n\n\n\n\n\nIdea\n\n\n\nUse the first two terms on the RHS to approximate the derivative at \\(x_0\\) and “throw away” the rest of the terms.\n\n\nTaking absolute values, we can see that:\n\\[\n\\left | f^{\\prime}(x_0) - \\frac{f(x_0 + h) - f(x_0)}{h} \\right | =  \\left | \\frac{h}{2}f^{\\prime\\prime}(x_0) + \\cdots + \\frac{h^{(n)} }{(n+1)!}f^{(n+1)}(c) \\right | ,\n\\tag{3.1}\\]\nwhere we denote the RHS of Equation 3.1 by the discretization error. If \\(f^{\\prime\\prime} (x_0) \\neq 0\\), then for small enough \\(h\\), we can estimate the discretization error by:\n\\[\n\\left | f^{\\prime}(x_0) - \\frac{f(x_0 + h) - f(x_0)}{h} \\right | \\approx  \\left | \\frac{h}{2}f^{\\prime\\prime}(x_0) \\right |.\n\\]\nAgain, we are discarding all higher order terms, which if \\(h\\) is “small enough” seems like a reasonable idea (of course we will need to prove this rigorously, but that comes later). In the meantime, it will prove helpful to denote quantities like the right hand side by the following notation:\n\\[\n\\left | \\frac{h}{2}f^{\\prime\\prime}(x_0) \\right | = O(h).\n\\]\nHere by the notation, \\(O(h)\\) (read Big O of h), we mean that a quantity is at most proportional to \\(h\\), for example \\(Ch\\), for some constant \\(C\\). One way to think of it is as\n\\[\n\\lim\\limits_{h \\to 0}\\frac{O(h)}{h} = C &lt; \\infty\n\\]\nThis can be generalized to higher orders of \\(h\\) as well. (We’ll talk more about his later as well.)\nThe important concept is that we talk about the above approximation for the derivative as being an \\(O(h)\\) approximation to the true derivative. For more details (or if you need a refresher) on Big O notation see Section A.1.\n\nExample 3.2 Approximate \\(f^{\\prime}(x)\\) for \\(f(x) = \\cos(x)\\) and \\(h = 10^{-3} - 10^{-15}, x = \\pi/6\\).\n\n\n\n\n\n\n\nRemark\n\n\n\nNotice that for each decrease in the value of \\(h\\) by an order of magnitude, both the absolute and relative error have a corresponding decrease in their values. This is exactly what the theory predicts. However, it is important to note that this is true only up to a certain point. We’ll discuss this more fully when we get to the sections on computer arithmetic and roundoff error.\n\n\n\nExercise 3.1 Approximate \\(f^{\\prime}(x)\\) for \\(f(x) = \\sin(x)\\) at the point \\(x_0 = 1.2\\) and using \\(h = 0.1, 0.01, 0.001\\). Can you estimate the discretization error? Explain.\n\n\nSolution.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Errors</span>"
    ]
  },
  {
    "objectID": "Errors.html#summary",
    "href": "Errors.html#summary",
    "title": "3  Errors",
    "section": "3.3 Summary",
    "text": "3.3 Summary\nThis section covered\n\nthe concepts of absolute error and relative error,\nthe difference between accuracy and precision,\npresented some of the most common sources of errors when modeling problems through the use of mathematical or computational models,\nthe effects of discretization error and,\nprovided an example for approximating the first derivative of some known function.\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"\n\n\n\n\n\n\nBailey, David H. 1993. “Algorithm 719: Multiprecision Translation and Execution of FORTRAN Programs.” ACM Transactions on Mathematical Software 19 (3): 288–319. https://doi.org/10.1145/155743.155767.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Errors</span>"
    ]
  },
  {
    "objectID": "FloatPointSys.html",
    "href": "FloatPointSys.html",
    "title": "4  Floating Point Systems",
    "section": "",
    "text": "4.1 Floating Point Systems\nComputational mathematics is different than “continuous” mathematics, with the main difference being that instead of having infinite precision, the arithmetic is both fixed and finite, due to the fact that we are working on a computer. This means that not all real numbers can be represented on a computer - and most real numbers can only be approximated.\nTo help us understand some of the complications, let’s review how we normally represent numbers in scientific notation. For example to represent the number 51.7538 in scientific notation we could write it as:\n\\[+ 0.517538 \\cdot 10^2\\] In this notation, the various components are given the following names:\nThe number of digits in the significand is known as the precision. This will become important in future discussions. It is also important to note that the scientific notation is not unique. We could just as easily have written:\n\\[+ 0.0517538 \\cdot 10^3\\]or any number of other ways, by changing the exponent. As a result, we usually restrict our mantissas to have the leading digit (most significant) be nonzero. These numbers are known as normalized numbers.\nRemarks.\nLet’s adapt our scientific notation for arithmetic on a computer. Specifically, instead of the usual base 10 system, we use a system with base 2 (binary). As before, let’s represent a number as follows:\n\\[\nx = \\pm (0.d_1d_2d_3 \\ldots d_t)\\cdot 2^{e}\n\\]\nfor some exponent \\(e\\). Notice that when we write it in this form what we’re really saying is that\n\\[\nx = \\pm \\Big ( \\frac{d_1}{2^{1}} + \\frac{d_1}{2^2} + \\frac{d_1}{2^3} + \\ldots \\frac{d_1}{2^t} \\Big) \\cdot 2^{e}\n\\]\nThe representation of a real number on a computer is called the floating point representation, and we will denote it by \\(fl(x)\\). Here again, we will assume that \\(d_1 \\neq 0.\\)\nWith these changes in mind, let’s consider how to represent the finite set of floating points on a computer.\nBy a floating-point number system we mean a finite subset \\(F = F(\\beta, t, e_{min},e_{max})\\), of the real numbers whose elements have the form:\n\\[\nx = \\pm m \\cdot 2^{e-t+1}\n\\]\nHere \\(\\beta\\) is the base (2 on almost all computers), \\(t\\) is the precision and \\(e \\in [e_{min}, e_{max}]\\), and \\(m\\) is the significand satisfying \\(m \\leq 2^t - 1\\).\nIn order to ensure that we have a unique representation for each floating point number, we also make the assumption that \\(m \\geq \\beta^{t-1},\\) i.e. the leading digit of \\(m\\) is nonzero and hence it is normalized.\nThe figure below depicts all of the positive numbers representable in our system \\(F\\).\nThere are some general remarks we can make about our floating-point system:\nThere are several important numbers in a floating-point system that we will use a lot:\nThe unit roundoff (rounding unit) is defined by \\[u = \\frac{1}{2} \\beta^{1-t}. \\tag{4.1}\\]\nIn our example,\n\\[u = \\frac{1}{2} 2^{1-t} = \\frac{1}{2} 2^{-2} = 0.125 .\\] The unit roundoff is frequently used in error analysis.\nMachine epsilon is defined by \\[\\epsilon = \\beta^{1-t}. \\tag{4.2}\\] Machine epsilon, is frequently used in practice and as a means to denote very small quantities in our computations.\nIn our example,\n\\[u =  2^{1-t} = 2^{-2} = 0.25 .\\]\nThe maximum number \\(x_{max}\\) is defined by \\[x_{max} = \\beta^{e_{max}}(\\beta - \\beta^{1-t}).\\]\nIn our example,\n\\[x_{max} = 2^3 (2 - 2^{-2}) = 8 \\cdot(2 -1/4) = 14.\\]\nThe minimum number \\(x_{min}\\) is defined by \\[x_{min} = \\beta^{e_{min}} .\\]\nIn our example,\n\\[x_{min} = 2^{-2} = 1/4 = 0.25. \\]\nBoth the maximum and minimum value of \\(x\\) are important to know so that we have a better understanding of our computational results.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Floating Point Systems</span>"
    ]
  },
  {
    "objectID": "FloatPointSys.html#sec-float-point-sys",
    "href": "FloatPointSys.html#sec-float-point-sys",
    "title": "4  Floating Point Systems",
    "section": "",
    "text": "Parts of Scientific Notation\n\n\nName\nValue\n\n\n\n\nSign\n+/-\n\n\nBase\n10\n\n\nExponent\n+2\n\n\nSignificand (Mantissa)\n0.517538\n\n\n\n\n\n\n\nWe can only store a finite number of the set of real numbers on any computer. At best we can expect a solution to be as accurate as the precision of that computer.\nEvery computer operation we do will result in intermediate results which are also only as accurate as we can store them.\nThese inaccuracies can accumulate further compromising the accuracy of the final result. These accumulated errors are known as roundoff errors. Some typical situations that cause roundoff include:\n\ninaccurate additions of large sequences of numbers\ntaking the difference of two nearly equal numbers\ninaccurate solution of ill-conditioned problems (more on this later).\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe need to be aware of potential numerical pitfalls and code programs accordingly. A good numerical analyst is always on the lookout for these problems!\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy the +1?\n\n\n\nThere’s a +1 added to the exponent so as to be consistent with IEEE standard, which we will discuss later on. For now, you can just simply take it as part of the definition.\n\n\n\n\nExample 4.1 Let’s see what this means on a toy floating point system. Suppose we have a system with \\(\\beta = 2, t=3, e_{min} = -2, e_{max}=3\\). What does this look like?\n\n\n\n\n\nThere are a total of 49 points: 24 positive, 24 negative, and 1 zero.\nThe numbers are equally spaced between each power of 2\nThe spacing increases by a factor of 2 at each power of 2.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nUnit Roundoff and Machine Epsilon\n\n\n\nUnit roundoff is just \\(2*\\epsilon\\), i.e. twice machine epsilon (for binary computers). You only need remember one of the two. For numerical analysts unit roundoff is slightly more important.\n\n\n\nTypes of Rounding\nSince \\(F\\) only has a finite number of floating point numbers it can represent, most calculations will produce a result that needs to be mapped onto our field \\(F\\). There are two possible choices: chopping and rounding. In chopping, the computed result Is simply truncated to whatever precision is available. In rounding, we take as our result whichever floating point is nearer. If there’s a tie, we need a rule to break the tie, and normally we will round to the number that has an even last digit - round to even.\nIn terms of the notation we used above, chopping and rounding can be described as:\n\nChopping: truncate all digits after digit \\(t\\):\n\n\\[\nfl(x) = \\pm .d_1d_2d_3\\cdots d_t \\times \\beta^{e}\n\\]\n\nRounding:\n\\[fl(x) = \\pm .d_1d_2d_3\\cdots d_t \\times \\beta^{e} \\quad d_t &lt; \\beta/2\\] or\n\n\\[fl(x) = \\pm (.d_1d_2d_3\\cdots d_t + \\beta^{1-t} ) \\times \\beta^{e} \\quad d_t &gt; \\beta/2\\]\nIn the case of a tie, one must also choose a tie-breaking rule.\n\n\n\n\n\n\nOther forms of rounding\n\n\n\nThere are several ways that one can round including, round down, round up, round towards zero, round to nearest. Most often when speaking about rounding we will mean round to nearest. In addition, the IEEE standard requires that the default rounding mode be round to nearest. In this case, we always round towards the nearest number and if there’s a tie, we take the number whose least significant bit is equal to zero.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Floating Point Systems</span>"
    ]
  },
  {
    "objectID": "FloatPointSys.html#summary",
    "href": "FloatPointSys.html#summary",
    "title": "4  Floating Point Systems",
    "section": "4.2 Summary",
    "text": "4.2 Summary\nThe following table summarizes some of the main characteristics of floating point systems.\n\n\n\n\n\n\n\n\nInterpretation\nParameter\nValue\n\n\n\n\nUnit roundoff. Spacing of numbers between 1/2 and 1\n\\(\\large{u}\\)\n\\(\\large{\\frac{1}{2}\\beta^{1-t}}\\)\n\n\nMachine epsilon. Spacing of numbers between 1 and 2\n\\(\\large{\\epsilon}\\)\n\\(\\large{\\beta^{1-t}}\\)\n\n\nLargest floating point number representable by \\(F\\)\n\\(\\large{x_{max}}\\)\n\\(\\large{\\beta^{e_{max}}(\\beta^{t}-1)}\\)\n\n\nSmallest normalized floating point number representable by \\(F\\)\n\\(\\large{x_{min}}\\)\n\\(\\large{\\beta^{e_{min}}}\\)\n\n\nTotal number of floating point numbers representable by \\(F\\)\n\n\\(\\large{ 2(\\beta -1) \\beta^{t-1}(e_{max}-e_{min} + 1) + 1}\\)",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Floating Point Systems</span>"
    ]
  },
  {
    "objectID": "FloatPointSys.html#advanced",
    "href": "FloatPointSys.html#advanced",
    "title": "4  Floating Point Systems",
    "section": "4.3 Advanced",
    "text": "4.3 Advanced\nWe will note in passing that it is possible to represent even smaller numbers below \\(N_{min}\\) through the use of what are known as subnormal numbers. However, this is beyond the scope of this introductory course. The interested reader can check out one of many references on this topic (e.g. Accuracy and Stability of Numberical Algorithms, 2nd ed., N. Higham (2002)).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Floating Point Systems</span>"
    ]
  },
  {
    "objectID": "FloatPointSys.html#references",
    "href": "FloatPointSys.html#references",
    "title": "4  Floating Point Systems",
    "section": "4.4 References",
    "text": "4.4 References\n\n(Goldberg 1991)What Every Computer Scientist Should Know About Floating-Point Arithmetic.\n(Nicholas J. Higham 2021)The Mathematics of Floating Point Arithmetic.\n(Nicholas J. Higham 2002) Accuracy and Stability of Numerical Algorithms.\n(Overton 2001)Numerical Computing with IEEE Floating Point Arithmetic.\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"\n\n\n\n\n\n\nGoldberg, David. 1991. “What Every Computer Scientist Should Know about Floating-Point Arithmetic.” ACM Computing Surveys (CSUR) 23 (1): 548.\n\n\nHigham, Nicholas J. 2021. “The Mathematics of Floating-Point Arithmetic.” LMS Newsletter 493: 35–41. https://nickhigham.files.wordpress.com/2021/04/high21m.pdf.\n\n\nHigham, Nicholas J. 2002. Accuracy and Stability of Numerical Algorithms. 2nd ed. Philadelphia: Society for Industrial; Applied Mathematics.\n\n\nOverton, Michael L. 2001. Numerical Computing with IEEE Floating Point Arithmetic. Society for Industrial; Applied Mathematics. https://doi.org/10.1137/1.9780898718072.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Floating Point Systems</span>"
    ]
  },
  {
    "objectID": "IEEE.html",
    "href": "IEEE.html",
    "title": "5  IEEE Floating Point Standard",
    "section": "",
    "text": "5.1 IEEE Floating Point Standard\nComputers are all based on binary arithmetic, i.e. they only store 1’s and 0’s. Instead of decimal digits, computers use binary digits, which have come to be known as bits.\nA long time ago machines all did floating point representations and arithmetic slightly differently. This led to all sorts of problems. In 1985, IEEE published the IEEE 754 Floating Point Standard (since updated in 2008). Now almost all computers conform to this standard. Codes are much more portable and less reliant on special programming tricks (affectionally known as kludges).\nIEEE has both single and double precision representations, the main difference being the number of bits used to represent the floating point number; 32 bits for single precision and 64 bits for double precision. Almost everyone uses double precision and we will assume so for the rest of this course.\nThe IEEE double precision representation uses 64 bits (binary digits) that are divided up as follows:\nIn the IEEE standard, the double precision representation of a floating point number is written as:\n\\[\nfl(x) = (-1)^s \\  2^{e-1023}\\cdot (1 + m)\n\\tag{5.1}\\]\nEach of the components plays a different role:\nSolution:\nTo compute the floating point number represented by this bit string, we need to use Equation 5.1 and decipher the various components: \\(s, e,\\) and \\(m\\). Let’s take these one step at a time.\n1. The sign, s = 0, which means we’re dealing with a positive number.\n2. The unbiased exponent can be computed by:\n\\[\n\\begin{aligned}\ne &= 10000000011 \\\\\n&= 1 \\cdot 2^{10} + 0 + \\ldots + 1 \\cdot 2^1 + 1\\cdot 2^0 \\\\\n&= 1024 + 0 + \\ldots + 2 + 1 \\\\\n&= 1027\n\\end{aligned}\n\\]\nTo compute the biased exponent for the real number we need to subtract the bias, which for double precision is 1023 as noted above. This means that the exponent for the floating point number is \\(1027 - 1023 = 4\\).\n3. Following a similar procedure for the mantissa we get: \\[\n\\begin{aligned}\nmantissa &= 10111001000100000000000000000000000000000 .... 0\\\\\n&= 1 \\cdot 1/2 + 0 \\cdot 1/2^2+ 1 \\cdot 1/2^3 + 1 \\cdot 1/2^4 + 1 \\cdot 1/2^5+ 1 \\cdot 1/2^8 + 1 \\cdot 1/2^{12} + 0 + \\ldots + 0 \\\\\n&= 1/2 + 1/8 + 1/16 + 1/32 + 1/256 + 1/4096 + 0 + \\dots + 0 \\\\\n&= 0.722290039\n\\end{aligned}\n\\]\nHere we have to remember that the IEEE standard states that floating point numbers are normalized, so the leading (hidden) bit is 1 and the mantissa represents the digits to right of the decimal point.\nPutting it all together and using Equation 5.1 we get:\n\\[\n\\begin{aligned}\nfl(x) &= + \\ 2^4 \\cdot ( 1 + 0.722290039)\\\\\n&= 16\\cdot(1.722290039) \\\\\n&= 27.56640626\n\\end{aligned}\n\\]",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IEEE Floating Point Standard</span>"
    ]
  },
  {
    "objectID": "IEEE.html#sec-IEEE",
    "href": "IEEE.html#sec-IEEE",
    "title": "5  IEEE Floating Point Standard",
    "section": "",
    "text": "IEEE Double Precision\n\n\n\n\n\n\n\n\nSingle Precision\n\n\n\nFor completeness, the IEEE single precision standard specifies 8 bits for the exponent and 22 bits for the mantissa. While it was initially used widely, today this is reserved for special applications requiring more speed.\n\n\n\n\n\n\nThe sign is denoted by \\(s\\) and is either 0 (for positive) or 1 (for negative).\nThe exponent is known as a biased exponent, in the case of double precision the bias is 1023. Since the exponent stored is interpreted as an unsigned integer, we need some mechanism for allowing both positive and negative exponents. As a result of using the bias, all stored exponents less than 1023 can be interpreted as negative exponents.\nIEEE assumes that floating point numbers are normalized, meaning that the leading significant digit is 1. This allows us to not store it, thereby giving us one more bit of precision. The leading digit is called a hidden bit.\nThe mantissa \\(m\\) corresponds to the digits to the right of the decimal point. In double precision, this amounts to 52 digits, but because of the hidden bit, we actually have 53 bits of precision. This results in approximately 16 decimal digit precision.\n\n\nExample 5.1 What is the floating point number represented by the following bit string?\n\n\n\nSign\nExp (11 bits)\nMantissa (52 bits)\n\n\n\n\n0\n10000000011\n10111001000100000000000000000000000…….. 0",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IEEE Floating Point Standard</span>"
    ]
  },
  {
    "objectID": "IEEE.html#important-parameters-for-ieee-floating-point-system",
    "href": "IEEE.html#important-parameters-for-ieee-floating-point-system",
    "title": "5  IEEE Floating Point Standard",
    "section": "5.2 Important Parameters for IEEE Floating Point System",
    "text": "5.2 Important Parameters for IEEE Floating Point System\nWhen doing numerical computations, it is important to be aware of what the range of floating point numbers on a computer is. It is not uncommon to have a long computation where some of the intermediate results may extend outside the range that is allowed on the computer.\n\nUnit roundoff and machine epsilon\nRecall from Section 4.1 Equation 4.1 that unit roundoff was defined as:\n\\[\nu = 1/2 \\cdot \\beta^{1-t}.\n\\]\nHence for a double precision IEEE system, this results in a unit roundoff of:\n\\[\nu = 1/2 \\cdot 2^{-52} \\approx 1.11 \\cdot 10^{-16},\n\\]\nand \\[\nu = 1/2 \\cdot 2^{-23} \\approx  5.96 \\cdot 10^{-8},\n\\] for single precision.\nMachine epsilon is as previously defined (Equation 4.2) just \\(2 \\cdot u\\), i.e. twice the unit roundoff. You only need remember one of the two. For numerical analysts unit roundoff is slightly more important.\n\n\nRange of Floating Point Numbers\nThe IEEE standard states that the smallest exponent for double precision is \\(e_{min} = -1022\\), and the largest exponent is \\(e_{max} = 1023\\). Given this we can compute the smallest and largest numbers representable in double precision using Equation 5.1.\nThe smallest number representable:\n\n\\(s = 0\\)\n\\(e_{min} = -1022\\)\n\\(m = 0\\)\n\nso \\[\nfl(x) = + 2^{-1022} \\cdot ( 1 + 0.0)\n\\] \\[\nN_{min} \\approx 2.225073858507201 \\cdot 10^{-308}\n\\]\nThe largest number representable:\n\n\\(s = 0\\)\n\\(e_{max} = 1023\\)\n\\(m = 1 - 2^{-52}\\)\n\nso \\[\n\\begin{aligned}\nfl(x) &= + 2^{1023} \\cdot ( 1 + 1-2^{-52}) \\\\\n&= 2^{1023} \\cdot ( 2 - \\epsilon) \\\\\n\\end{aligned}\n\\] where \\(\\epsilon = 2^{-52}\\).\n\\[\nN_{max} \\approx 1.797693134862316 \\cdot 10^{308}\n\\]\nOne might ask what happens if a computation generates a floating point number outside the range of the allowed numbers within the IEEE floating point standard. If we compute a number that is less than \\(N_{min}\\) we get underflow (which is generally set to \\(0\\)). If we compute a number that is greater than \\(N_{max}\\) we get overflow (which could set the value to Infinity or it might generate an exception).\nIt is also possible to generate two other types of “numbers”, specifically an Infinity (for example dividing by 0) and something called “not a number” or a NaN (e.g. through a computation such as \\(0/0, 0 \\times \\infty\\), or the square root of a negative number). The IEEE standard reserves the exponent 2047 for both cases, which is why \\(e_{max} = 1023\\). Ideally your codes should be on the watch for situations when this might occur and take the appropriate precautions.\n\n\nRelative error of floating point representation\nOne of the nice things about the IEEE standard is that it can provide certain guarantees about the accuracy of the floating point representation of a real number. In particular, it can be shown that:\n\\[\nfl(x) = x (1 + \\delta), \\quad |\\delta| \\leq u,\n\\]\nwhere \\(u = \\frac{1}{2} \\cdot 2^{1-t}\\) is the unit roundoff, and \\(t\\) is the computer precision.\nAnother way to write this is as:\n\\[\n\\left | \\frac{fl(x) - x}{x} \\right | \\leq u .\n\\]\n\n\n\n\n\n\nImportant\n\n\n\nIn other words, the relative error in the floating point representation of a real number will be less than or equal to the unit roundoff on the machine.\n\n\n\n\nFloating Point Arithmetic Operations\nThe IEEE standard specifies that all computer operations must behave as if the requested operation were done in infinite precision and then rounded to the nearest floating point within the system. In particular, it can be shown that:\n\\[\nfl(x  \\ op \\ y) = (x \\ op \\ y) (1 + \\delta), \\quad |\\delta| \\leq u,\n\\] where \\(op = +, -, *, / .\\)\nOne way to interpret this is that the computed result from any floating point operation is as good as the exact answer rounded to the nearest floating point.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IEEE Floating Point Standard</span>"
    ]
  },
  {
    "objectID": "IEEE.html#summary",
    "href": "IEEE.html#summary",
    "title": "5  IEEE Floating Point Standard",
    "section": "5.3 Summary",
    "text": "5.3 Summary\nThe following table summarizes some of the main characteristics of IEEE floating point formats useful for numerical analysis:\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nSize\nMantissa\nExponent\nUnit Roundoff\nemin\nemax\nRange\n\n\n\n\nSingle\n32 bits\n23 bits + 1 hidden\n8 bits\n\\(2^{-24} \\approx 5.96 \\cdot 10^{-8}\\)\n-126\n127\n\\(10^{\\pm38}\\)\n\n\nDouble\n64 bits\n52 bits + 1 hidden\n11 bits\n\\(2^{-53} \\approx 1.11\\cdot 10^{-16}\\)\n-1022\n-1023\n\\(10^{\\pm308}\\)\n\n\n\n\n\n\n\n\n\nAdvanced\n\n\n\nWe will note in passing that it is possible to represent even smaller numbers below \\(N_{min}\\) through the use of what are known as subnormal numbers. However, this is beyond the scope of this introductory course. The interested reader can check out one of many references on this topic (e.g. Accuracy and Stability of Numerical Algorithms, 2nd ed., N. Higham (2002)).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IEEE Floating Point Standard</span>"
    ]
  },
  {
    "objectID": "IEEE.html#codes",
    "href": "IEEE.html#codes",
    "title": "5  IEEE Floating Point Standard",
    "section": "5.4 Codes",
    "text": "5.4 Codes\n\n\n\n\n\n\n\nCoding tip\n\n\n\nIn matlab you can call the function realmin to compute \\(N_{min}\\); likewise the function realmax will compute the value for \\(N_{max}\\).\nYou can do something similar in python through the use of the numpy finfo function. For example:\nimport numpy as np \nprint(np.finfo(float).eps) \nprint(np.finfo(float).max)\nprint(np.finfo(float).tiny)\nR has a similar capability which prints out the entire set of machine characteristics through the .Machine function. For specific values you need to append the name. For example:\n\n\nCode\n# Output machine parameters such as eps, Nmax, Nmin, etc.\n.Machine$double.eps\n\n\n[1] 2.220446e-16\n\n\nCode\n.Machine$double.xmax\n\n\n[1] 1.797693e+308\n\n\nCode\n.Machine$double.xmin\n\n\n[1] 2.225074e-308",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IEEE Floating Point Standard</span>"
    ]
  },
  {
    "objectID": "IEEE.html#references",
    "href": "IEEE.html#references",
    "title": "5  IEEE Floating Point Standard",
    "section": "5.5 References",
    "text": "5.5 References\n\n(Goldberg 1991)What Every Computer Scientist Should Know About Floating-Point Arithmetic.\n(Nicholas J. Higham 2021)The Mathematics of Floating Point Arithmetic.\n(Nicholas J. Higham 2002) Accuracy and Stability of Numerical Algorithms.\n(Overton 2001)Numerical Computing with IEEE Floating Point Arithmetic.\n(Hennessy and Patterson 2011)Computer Architecture A Quantitative Approach, Appendix A Computer Arithmetic\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"\n\n\n\n\n\n\nGoldberg, David. 1991. “What Every Computer Scientist Should Know about Floating-Point Arithmetic.” ACM Computing Surveys (CSUR) 23 (1): 548.\n\n\nHennessy, John L., and David A. Patterson. 2011. Computer Architecture, Fifth Edition: A Quantitative Approach. 5th ed. San Francisco, CA, USA: Morgan Kaufmann Publishers Inc.\n\n\nHigham, Nicholas J. 2021. “The Mathematics of Floating-Point Arithmetic.” LMS Newsletter 493: 35–41. https://nickhigham.files.wordpress.com/2021/04/high21m.pdf.\n\n\nHigham, Nicholas J. 2002. Accuracy and Stability of Numerical Algorithms. 2nd ed. Philadelphia: Society for Industrial; Applied Mathematics.\n\n\nOverton, Michael L. 2001. Numerical Computing with IEEE Floating Point Arithmetic. Society for Industrial; Applied Mathematics. https://doi.org/10.1137/1.9780898718072.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>IEEE Floating Point Standard</span>"
    ]
  },
  {
    "objectID": "AlgorithmsCondition.html",
    "href": "AlgorithmsCondition.html",
    "title": "6  Stability and Conditioning",
    "section": "",
    "text": "6.1 Algorithms\nAlgorithms have a long history dating back over 4000 years. The name itself is said to be derived from the mathematician al-Khwārizmī (c.780-c.850), who wrote a book on the subject.\nIn the broadest sense, one can think of an algorithm as a step by step procedure for solving some problem. A common analogy is that of a recipe in which one is given explicit instructions on how to make something. One can also think of an algorithm as a sytematic calculation or process for achieving some desired result.\nMore recently, the notion of finiteness has been added to the concept although it is not essential.\nFor our purposes we will use the following definition:",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Stability and Conditioning</span>"
    ]
  },
  {
    "objectID": "AlgorithmsCondition.html#sec-stabilitycond",
    "href": "AlgorithmsCondition.html#sec-stabilitycond",
    "title": "6  Stability and Conditioning",
    "section": "",
    "text": "Definition 6.1 An algorithm is a well-defined process that takes an input (or inputs) and produces an output in a finite-number of steps or time.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Stability and Conditioning</span>"
    ]
  },
  {
    "objectID": "AlgorithmsCondition.html#desired-properties-of-algorithms",
    "href": "AlgorithmsCondition.html#desired-properties-of-algorithms",
    "title": "6  Stability and Conditioning",
    "section": "6.2 Desired Properties of Algorithms",
    "text": "6.2 Desired Properties of Algorithms\nWhat kind of properties should a good numerical algorithm have? While one can come up with a long list of desirable characteristics for an algorithm, we will concentrate on three that were briefly introduced on the first day of class:\n\nAccuracy\nEfficiency\nRobustness\n\nLet’s take a look at each of these in turn.\nAccuracy. Since a numerical algorithm is designed to solve some mathematical problem, one of the key characteristics should be that it provides us with an accurate approximation to the true solution, whatever that might be. We’ve already seen some examples of these and how we can use error analysis to allow us to predict the behavior of an algorithm.\nEfficiency. We also would like to have an algorithm that is computationally as efficient as possible. For example, let’s consider the problem of evaluating a polynomial given by:\n\\[\np_n(x) = c_0 + c_1 x + c_2 x^2 + \\ldots c_nx^n .\n\\]\nA naive algorithm would require \\(O(n^2)\\) operations or flops (floating point operations) as they are called. To see this all you need to do is think about each of the terms in the polynomial in turn and add up all of the operations. For example, the last term requires \\(n\\) multiplications: \\(n-1\\) to compute \\(x^n\\) plus one more to multiply by \\(c_n\\). Each term of lower order will require one less multiplication. In all, there are \\(n + (n-1) + (n-2) + \\ldots +1 = O(n^2)\\) multiplications. Finally there are the \\(n\\) additions required to sum up all of the individual terms.\nInstead, we should consider rewriting the formula in what is known as the nested form:\n\\[\np_n(x) = c_0 + x (c_1 + x(c_2 +   \\cdots +  x(c_{n-1} + x (c_n)) \\cdots )),\n\\]which only requires \\(O(n)\\) operations. (You should work this out for yourself.) This may not make much of a difference for small values of \\(n\\), but one nonetheless needs to be careful as generally speaking we don’t know ahead of time how an algorithm will be used. For example, this polynomial evaluation could be at the heart of an algorithm that is called millions of times.\n\n\n\n\n\n\n\nFlops\n\n\n\nHistorically, the operation count (flops) has been an important measure of efficiency (or at least workload). On today’s computers, and especially supercomputers, there are many more things to consider when considering computational efficiency (memory access, communication, vectorization/parallelization, etc.).\n\n\nRobustness. Finally, we would like an algorithm that we can “trust”, in the sense that it either gives us an answer or reports back that something went wrong. Ideally, an algorithm should also work under most foreseeable circumstances and different values of inputs. Another thing to watch out for is the rate of accumulation of errors within an algorithm.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Stability and Conditioning</span>"
    ]
  },
  {
    "objectID": "AlgorithmsCondition.html#stability-and-conditioning",
    "href": "AlgorithmsCondition.html#stability-and-conditioning",
    "title": "6  Stability and Conditioning",
    "section": "6.3 Stability and Conditioning",
    "text": "6.3 Stability and Conditioning\nNext we consider what we can say about the problem and the algorithm to help us in making good decisions.\nThe first concept is that of the problem sensitivity or as it is more commonly referred, conditioning. By this we mean that a problem is well-conditioned if small changes in the inputs do not lead to large changes in the outputs. Otherwise the problem is said to be ill-conditioned.\n\n\n\n\n\n\nFigure 6.1: Ill-conditioned problem where small changes in the input can lead to large changes in the output\n\n\n\nThe second concept is that of stability in an algorithm. Here we say that an algorithm is stable if the output generated is the exact result for a slightly perturbed input. Another way of phrasing this is that a stable algorithm solves a nearby problem.\n\n\n\n\n\n\nFigure 6.2: A stable algorithm is one that is the exact solution to a slightly perturbed problem.\n\n\n\n\nExample 6.1 Let’s take a look at a simple example of a well-conditioned problem first. Consider the function \\(f(x) = \\sqrt{1 + x}\\) with \\(f^\\prime(x) = \\frac{1}{2\\sqrt{1+x}}.\\)\nLet’s suppose that we fix \\(|x| &lt;&lt; 1\\) and consider \\(\\bar{x} = 0\\) as a small perturbation of \\(x\\). Then\n\\[\n\\bar{y} = f(\\bar{x}) = \\sqrt{1 + 0} = 1,\n\\]\nand the change in the output can be given by\n\\[\ny - \\bar{y} = \\sqrt{1 + x} -1.\n\\]\nNow let’s approximate \\(\\sqrt{1 + x}\\) by the first 2 terms of a Taylor series about \\(0\\), i.e.\n\\[\nf(x) \\approx 1 + \\frac{x}{2}.\n\\]\nSubstituting into the prior equation we can write the change in the output by:\n\\[\ny - \\bar{y} \\approx  \\left (1 + \\frac{x}{2} \\right ) - 1 = \\frac{x}{2}.\n\\]\nThis can then be rewritten in terms of the change in the inputs as:\n\\[\ny - \\bar{y} \\approx \\frac{1}{2} (x - \\bar{x}).\n\\]\nNotice that if \\(x = 0.001\\) then the change in the output is only \\(y - \\bar{y} \\approx 0.0005\\), one half of what the change in input was.\n\nWe’re now ready for a more rigorous definition of conditioning. First, note that when we introduced the concept of conditioning is was to describe the sensitivity of a problem (function) to change in the input data x. As such it seems natural to look at:\n\\[\n\\frac{\\mbox{Relative change in } f(x)}{\\mbox{Relative change in } x}.\n\\]\nMathematically we can translate this into:\n\\[\n\\begin{aligned}\n\\large{\\left ( \\frac{\\frac{f(x) - f(\\bar{x})}{f(x)}}{\\frac{x - \\bar{x}}{x}}\\right)} &= \\frac{f(x) - f(\\bar{x})}{f(x)}\\cdot \\frac{x}{x - \\bar{x}} ,\\\\\n&= \\frac{f(x) - f(\\bar{x})}{x - \\bar{x}}\\cdot \\frac{x}{f(x)} ,\\\\\n&\\approx \\frac{f^\\prime(x) \\cdot x}{f(x)}.\n\\end{aligned}\n\\]\nThis leads us to the following definition:\n\nDefinition 6.2 The quantity\n\\[\n\\kappa = \\left | \\frac{f^\\prime(x) \\cdot x}{f(x)} \\right |.\n\\]\nis called the (relative) condition number of the problem.\n\nLet’s now discuss the concept of stability. It is natural to expect that any algorithm will produce some roundoff error. In fact, it is common that accumulation of roundoff error will occur as we progress through a computation.\nIf the error grows slowly as the computation proceeds it won’t be a problem, but if it grows too fast then we need to be more careful.\nLet \\(E_n\\) be the error at the \\(nth\\) step of some computation.\nIf the error \\(E_n \\approx C\\cdot n E_0,\\) where \\(C\\) is a constant and \\(E_0\\) is the original error, then the growth of error is said to be linear.\nIf the error \\(E_n \\approx C^n E_0,\\) where \\(C\\) is a constant and \\(E_0\\) is the original error, then the growth of error is said to be exponential.\nAn algorithm that has an exponential error growth rate is said to be unstable. We should note that an algorithm could be stable for solving one problem, but unstable for solving another problem.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Stability and Conditioning</span>"
    ]
  },
  {
    "objectID": "AlgorithmsCondition.html#tips-on-designing-stable-algorithms",
    "href": "AlgorithmsCondition.html#tips-on-designing-stable-algorithms",
    "title": "6  Stability and Conditioning",
    "section": "6.4 Tips on designing stable algorithms",
    "text": "6.4 Tips on designing stable algorithms\nWhile there are no hard and fast rules, there are several things to watch out for in designing an algorithm. The tips below are paraphrased from the excellent discussion given in Higham (Higham 2002).\n\nWatch out for cancellation errors. Try to avoid subtracting quantities of near equal magnitude, especially if they are contaminated by error.\nLook for different formulations that are mathematically equivalent, but perhaps numerical better.\nIt can be useful to write formulas in the form of:\n\n\\[x_{new} = x_{old} + \\Delta x\\]\nwhere \\(\\Delta x\\) is a small correction to the previous (old) value. You’ll see that many numerical methods take this form.\n\nMinimize the size of intermediate results relative to the final result. It’s also a good idea to check the intermediate results when first writing a code.\nAvoid ill-conditioned transformations of the problem.\nTake precautions against underflow and overflow.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Stability and Conditioning</span>"
    ]
  },
  {
    "objectID": "AlgorithmsCondition.html#summary",
    "href": "AlgorithmsCondition.html#summary",
    "title": "6  Stability and Conditioning",
    "section": "6.5 Summary",
    "text": "6.5 Summary\nThis lesson covered the fundamental concepts of conditioning of numerical problems and stability of algorithms. Some of the takeaway messages include:\n\nThe condition of a problem, which speaks to the sensitivity of the outputs to the inputs is related to the relative change in the output of a problem to the relative change in the inputs.\nAll algorithms will generate some errors as a consequence of doing finite digit arithmetic. If the error growth rate is reasonable, for example linear with respect to the number of steps in the calculation, then we can expect good results (if the problem is also well-conditioned).\nIf the error growth rate is exponential instead, then the algorithms is said to be unstable.\nAn algorithm can be stable for one type of problem but unstable for another type of problem.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Stability and Conditioning</span>"
    ]
  },
  {
    "objectID": "AlgorithmsCondition.html#advanced",
    "href": "AlgorithmsCondition.html#advanced",
    "title": "6  Stability and Conditioning",
    "section": "6.6 Advanced",
    "text": "6.6 Advanced\nThe condition number of a problem is especially useful in numerical linear algebra, where it can be used to estimate the accuracy of the solutions for systems of linear equations, such as \\(Ax = b\\). The stability of algorithms will become important in our study of initial value problems (ODEs).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Stability and Conditioning</span>"
    ]
  },
  {
    "objectID": "AlgorithmsCondition.html#references",
    "href": "AlgorithmsCondition.html#references",
    "title": "6  Stability and Conditioning",
    "section": "6.7 References",
    "text": "6.7 References\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"\n\n\n\n\n\n\nHigham, Nicholas J. 2002. Accuracy and Stability of Numerical Algorithms. 2nd ed. Philadelphia: Society for Industrial; Applied Mathematics.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Stability and Conditioning</span>"
    ]
  },
  {
    "objectID": "RootsEqn.html",
    "href": "RootsEqn.html",
    "title": "Nonlinear Equations",
    "section": "",
    "text": "Nonlinear equations\nSuppose that we have a scalar, nonlinear equation \\(f: \\mathbb{R}^1 \\rightarrow \\mathbb{R}^1\\) on an interval \\([a,b]\\)\nIf \\(x^* \\in \\mathbb{R}\\) is such that \\[\nf(x^*) = 0,\n\\tag{1}\\]\nthen we will call \\(x^*\\) a zero or root of \\(f\\).\nFor the time being, let’s assume that \\(f(x)\\) is continuous on the closed interval \\([a,b].\\) As it turns out, except for some special cases, nonlinear equations will not have a closed form solution, so we are naturally led to developing alternative means for solving Equation 1.\nWe could have just as easily defined the problem in higher dimensions, i.e. \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^p\\), for \\(n &gt;1, p&gt;1\\), and \\(n\\) not necessarily equal to \\(p\\). This would most likely be the case for a real-world problem, but while many of the ideas (and algorithms) can generalized to higher dimensions, the concepts are easier to understand in one dimension to begin with.\nWe note in passing that if \\(n=p\\), then this is an example of finding the roots of a nonlinear system of equations. If \\(n \\neq p\\), then this is an example of a nonlinear least squares problem.\nMost nonlinear equations cannot be solved analytically and as a result most approaches involve some form of iteration, which can be described at a high-level as:\nThis is the essence of an iterative method.\nUsing an iterative technique to find roots of equations can be tricky however. The initial guess can sometimes be important, and if not chosen properly can lead to slow convergence or even non-convergence.\nHow one updates the guess is also important. Without some theory behind the updating scheme, an iterative method is nothing more than trial and error.\nFinally, there is always the question as to when to terminate an iterative method, in other words when is an estimate of the root “good enough”? For all of these reasons, having an algorithm based on sound theoretical foundations is of fundamental importance.\nIn the next few sections, we discuss some of the more popular iterative methods for finding the roots of a nonlinear equation and provide some general guidance for when to use them. In particular, we will study the bisection method (7.1 Bisection), Newton’s method (8.1 Newton’s Method), secant method (9.1 Secant Method) and fixed-point iterations (10.1 Fixed Point).",
    "crumbs": [
      "Nonlinear Equations"
    ]
  },
  {
    "objectID": "RootsEqn.html#sec-nonlineq",
    "href": "RootsEqn.html#sec-nonlineq",
    "title": "Nonlinear Equations",
    "section": "",
    "text": "Relation to optimization\n\n\n\nMany of the methods that we study in this section are also applicable to the problem of optimization. For example:\n\\[\n\\min f(x)\n\\]\nsince a minimum will occur at points where \\(f^\\prime(x) = 0\\). Of course, special care must be taken that the method approaches a minimum and not a maximum or an inflection point, but this is usually not hard to handle.\n\n\n\n\n\n\n\n\nExamples\n\n\n\n\n\\(f(x) = 6x^2 - 7x + 2 = (2x -1)(3x-2)\\)\n\\(f(x) = 2^{x^2} - 10x + 1\\)\n\\(f(x) = \\cosh(\\sqrt{x^2+1} - e^x) + \\log|\\sin(x)|\\)\n\\(f(x) = \\blacksquare \\leftarrow\\) some black box\n\n\n\n\n\nFirst guess a solution,\nCheck to see how accurate it is, and if not satisfied,\nUpdate the guess and try again, i.e. go back to step 1",
    "crumbs": [
      "Nonlinear Equations"
    ]
  },
  {
    "objectID": "Bisect.html",
    "href": "Bisect.html",
    "title": "7  Bisection Method",
    "section": "",
    "text": "7.1 Bisection\nOne of the simplest methods for solving a nonlinear equation is known as the bisection method. The main advantage is the robustness of the method - if the method is applicable to the problem, it is guaranteed to find a solution. On the other hand, the method can often take far more iterations than some of the other methods we will discuss.\nLet’s first describe the general method.\nMathematically, if \\(f(x) \\in C[a,b]\\) and \\(f(a) \\cdot f(b) &lt; 0\\), then there exists an \\(x^{*} \\in [a,b]\\) such that \\(f(x^{*}) = 0\\). This leads us to the following general procedure:\nWriting this in pseudocode might lead to something like the following:\nLet’s take a look at how this pseudocode could be implemented in python.\nCode\nimport numpy as np\n\ndef bisect(x0, a0, b0, ftol):\n  ak = a0\n  bk = b0\n  converged = False\n  \n  k = 0\n  \n  while (not converged):\n    k = k+1\n    mid = (ak + bk)/2\n    fmid = fx(mid)\n    if ( fx(ak)*fmid &lt; 0):\n      bk = mid\n    else:\n      ak = mid\n    if (np.abs(fmid) &lt; ftol):\n      converged = True\n  else:\n      print(\"Bisection converged after %d iterations at: \\n x = %e with f(x) = %e\" % (k, mid, fmid))\n      \n  return mid\nLet’s define a function and call the bisection algorithm. For this example, let’s use the function:\n\\[\nf(x) = (x - 1.5)^3 - x + 2\n\\] on the interval \\(I = [a,b] = [0, 2.5]\\).\nFor initial values we’ll use an initial starting guess of \\(x_0 = 2.0\\) and a function tolerance of \\(ftol = 10^{-6}\\)\nCode\n# Example function\n\ndef fx(x):\n  fvalue = (x-1.5)**3 - x + 2\n  return fvalue\n\n#Initialize\na = 0.0\nb = 2.5\nx0 = 2.0\nftol = 1.e-6\n\n\n# Check assumptions\nfa  = fx(a)\nprint (\"fa = %f\" %(fa))\n\n\nfa = -1.375000\n\n\nCode\nfb  = fx(b)\nprint (\"fb = %f\" %(fb))\n\n\nfb = 0.500000\n\n\nCode\n# Call Bisection function\nxstar = bisect(x0, a, b, ftol)\n\n\nBisection converged after 22 iterations at: \n x = 3.085119e-01 with f(x) = -8.565410e-07",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bisection Method</span>"
    ]
  },
  {
    "objectID": "Bisect.html#sec-bisect",
    "href": "Bisect.html#sec-bisect",
    "title": "7  Bisection Method",
    "section": "",
    "text": "Figure 7.1: Bisection Method\n\n\n\n\n\n\n\n\n\nIdea\n\n\n\nSuppose that we happen to know two points where the function is of opposite sign as in Figure 7.1. Using the Intermediate Value Theorem we also know that if the function is continuous, then the function must take every value in between the two values and, in particular, it must be equal to 0 somewhere in the interval.\n\n\n\n\nStart with an interval \\([a,b]\\) such that \\(f(a) \\cdot f(b) &lt; 0.\\)\nCut the interval in half (bisect).\nEvaluate the function \\(f\\) at the midpoint of the interval.\nChoose whichever sub-interval contains a sign change.\nRepeat as necessary.\n\n\n\n\n\n\n\n\nFigure 7.2: Bisection Algorithm\n\n\n\n\nExample 7.1 Consider \\(f(x) = x^3 + 4x^2 - 10 = 0\\) on \\([1,2]\\) where \\(x^{*} = 1.365\\). We should first check that the function has opposite signs on the given interval:\n\\[\\begin{aligned}\n&f(1) = 1 + 4 - 10 = -5 \\\\\n&f(2) = 8 + 16 - 10 = 14 \\\\\n&f(1) \\cdot f(2) &lt; 0 \\quad \\quad \\quad \\quad \\quad YES!\n\\end{aligned}\n\\]\n\nCompute \\(p = \\frac{a + b}{2} = \\frac{1 + 2}{2}= 1.5\\)\nEvaluate \\(f(1.5) = 3.375 + 9 - 10 = 2.375\\)\n\\(f(a)\\cdot f(p) = f(1) \\cdot f(1.5) &lt; 0\\) so we choose left interval and set \\(b=p\\)\nRepeat\n\nIn the book, after 13 iterations \\(p= 1.365112305,\\) \\(f(p) = -0.00194,\\) and \\(|b_{14}-a_{14}| = 0.000122070.\\)",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bisection Method</span>"
    ]
  },
  {
    "objectID": "Bisect.html#sec-stopping",
    "href": "Bisect.html#sec-stopping",
    "title": "7  Bisection Method",
    "section": "7.2 Stopping (Convergence) Criteria",
    "text": "7.2 Stopping (Convergence) Criteria\nBefore proceeding further, we should discuss when and how to terminate an iterative algorithm. This decision is one of great importance in real-world applications because many of the problems are expensive or time consuming. Both the expense and time are usually a result of the complexity of the function being evaluated. In some cases it could take hours if not days of computer time to yield one function evaluation. In these cases, it is not unusual that a scientist or an engineer will decide to terminate an algorithm based simply on how much computer time they are willing to use.\nIn practice, there are numerous possibilities for convergence criteria, each with pros and cons. The most obvious would be to check to see how close we are to our desired solution, but in general this would be impossible since we don’t know what the solution is ahead of time (except for academic exercises). On the other hand, it is not unreasonable to assume that we might have some sort of bound, for example in some cases, the solution might be known to be positive or have a maximum value.\nSuppose that an iterative algorithm has produced a sequence of iterates starting with an initial guess:\n\\[\nx_0, \\ x_1, \\ x_2, \\ \\ldots, \\  x_k.\n\\]One logical approach is to take a look at the magnitude of \\(f(x_k)\\) and check to see how close we are to zero:\n\\[\n| f(x_{k}) | &lt; atol\n\\]\nAnother frequent approach is to stop an iteration when “sufficient” progress has been made. In other words, an engineer is simply interested in reducing the initial function value by some fraction, i.e.\n\\[\n\\frac{| f(x_{k}) |}{|f(x_0)|} &lt; ftol\n\\]\nIn general, these are good approaches, but there are cases for which progress towards the solution may be slow and little is to be gained from each new iteration. In this case, we may decide to stop if we believe we are not making sufficient progress towards a solution. This could be construed, for example, if the difference between successive iterates becomes small:\n\\[\n|x_{k+1} - x_{k} | &lt; xtol\n\\]\nHere, we should note that it might also make sense to check that the relative step size is small:\n\\[\n\\frac{|x_{k+1} - x_{k} |}{|x_{k+1}|} &lt; rtol\n\\]\nIn practice, many algorithms will employ some combination of these (and sometimes others). Experience and knowledge of the specific problem are usually needed to ensure that we don’t stop too early or waste time iterating for too long.",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bisection Method</span>"
    ]
  },
  {
    "objectID": "Bisect.html#sec-bisecterror",
    "href": "Bisect.html#sec-bisecterror",
    "title": "7  Bisection Method",
    "section": "7.3 Convergence of Bisection method",
    "text": "7.3 Convergence of Bisection method\nOne of the first questions one should ask about any iterative method is when and under what conditions do we expect that it might converge to a solution. In the case of the bisection method, it turns out that the only condition we need to have is that the function \\(f(x)\\) is continuous, given that the two initial points yield functions values with opposite signs.\nThe alert student should recognize that this is really just a consequence of Theorem 1.2 - the Intermediate Value Theorem.\nMoreover, if these conditions hold, we can prove that the error bound between the solution and the iterates \\(x_n\\) can be given by:\n\\[\n|x^* - x_k | \\leq \\frac{b - a}{2^k}, \\quad k=0,1, \\ldots.\n\\tag{7.1}\\]\n\nNotice that for \\(k=0\\) all we’re really saying is that the root must lie within the given interval \\([a_0, b_0]\\). At the next step, the interval and hence the error is cut in half so that\n\\[\n|x^* - x_1| \\leq \\frac{b_0 - a_0}{2}.\n\\]\nAt each iteration, the interval is cut in half by construction, so that at the \\(kth\\) iteration we get our desired result.\n\nAs constructed then, the bisection method cannot fail. This type of method is known as a robust algorithm.\nAdditionally, we can use the error bound to estimate the number of iterations required to achieve a certain accuracy, \\(\\epsilon\\).\nUsing Equation 7.1 we want \\[\n| x^* - x_k | \\leq \\frac{b-a}{2^k} \\leq \\epsilon.\n\\] Taking logs of both side we have \\[\n\\log (b-a) - \\log{2^k} \\leq \\log \\epsilon ,\n\\] or rearranging \\[\n\\log (b-a) - \\log \\epsilon \\leq k \\log 2 .\n\\] If we would like to have the error be less than \\(\\epsilon\\) then solving for the number of iterations gives us \\[\nk \\geq \\frac{\\log [ (b-a)/\\epsilon]}{\\log 2} .\n\\tag{7.2}\\]\nFor example, let’s set \\(\\epsilon = 0.001\\) and \\(a=1, b=2\\). Then solving for \\(k\\), we have \\[\nk \\geq \\frac{\\log [ 1/ 0.001]}{\\log 2} = \\frac{3}{0.301} \\approx 9.97,\n\\] so \\(k=10\\) iterations should suffice to achieve an error tolerance of \\(\\epsilon = 0.001\\).",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bisection Method</span>"
    ]
  },
  {
    "objectID": "Bisect.html#summary",
    "href": "Bisect.html#summary",
    "title": "7  Bisection Method",
    "section": "7.4 Summary",
    "text": "7.4 Summary\nTo recap, bisection is a robust algorithm for finding the zero of a nonlinear function. It needs to have two initial points where the function value is of opposite sign, but it is guaranteed to converge. The advantages and disadvantages can be summarized as follows:\n\nBisection Method Summary\n\n\n\n\n\n\nAdvantages\nDisadvantages\n\n\n\n\nAlways converges, i.e. robust algorithm\nNeed to provide a specific interval, with 2 points where function is of opposite sign\n\n\nError bound easily derived and can be used to estimate number of iterations need to achieve a desired tolerance\nSlow convergence - error only decreases by 1/2 at each iteration\n\n\nCan be used to start other methods\nNot clear how to generalize to higher dimensions\n\n\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Bisection Method</span>"
    ]
  },
  {
    "objectID": "Newton.html",
    "href": "Newton.html",
    "title": "8  Newton’s Method",
    "section": "",
    "text": "8.1 Newton’s Method\nIn the last lecture we saw that while the bisection method was robust and would always converge to a solution given the right set of initial values, it could exhibit slow convergence. As a result, most solvers used other types of root-finding algorithms. In this section we will study two such methods that can provide much faster convergence to a root.\nNewton’s method is likely the most popular and certainly the most powerful method for solving nonlinear equations (Meza 2011). The idea behind Newton’s method is to use the slope of the function at the current iterate to compute a new iterate. Naturally, this requires that we first assume that the given function \\(f(x)\\) is differentiable.\nUsing this idea let’s solve for the root of the linear model, i.e.\n\\[\n\\begin{aligned}\nf^{\\prime}(x_0)(x-x_0) + f(x_0) &= 0,\\\\\n\\implies x^\\star = x_0 - \\frac{f(x_0)}{f^{\\prime}(x_0)}.\n\\end{aligned}\n\\]\nWe can then set \\(x_1 = x^\\star\\) as the next iterate in our sequence and repeat the process. This gives us the general procedure for Newton’s method:\nWe could have derived the same equation by just noting that we could take the derivative at the current iterate and use that to set up a linear equation, which we can solve for the new iterate.\n.\nFinally, we will also note in passing that another derivation (which we went through in class) was to use Taylor’s theorem to approximate our function \\(f(x)\\) out to the first degree with a remainder term that included the second derivative. We then chose to ignore the second derivative term based on the argument that when we are near the solution the term would be small. When we solved for our new iterate, we derived the same equation for Newton’s method.\nStopping criteria for Newton’s method (and all of its variants) are similar to the ones discussed in the section on Bisection Method (Section 7.2.)\nNotice that after only 3 iterations, the iterates is already correct to 3 significant digits.\nSeveral questions one might consider at this point include:",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Newton's Method</span>"
    ]
  },
  {
    "objectID": "Newton.html#sec-newton",
    "href": "Newton.html#sec-newton",
    "title": "8  Newton’s Method",
    "section": "",
    "text": "Idea\n\n\n\nOne approach for deriving Newton’s method is to think about building a linear model of the function at the current iterate. Let’s consider the linear model \\(m(x)\\):\n\\[\nm(x) = f(x_0) + f^{\\prime}(x_0)(x-x_0).\n\\tag{8.1}\\]\nNotice that at \\(x = x_0\\) the model agrees with the function \\(f(x),\\) in other words \\(m(x_0) = f(x_0).\\) The idea is to then solve for the root of Equation 8.1 and use the root as the next guess of our iterative method:\n\n\n\n\n\n\n\n\n\n\n\nNewton’s Method\n\n\n\n\\[\nx_{k+1} = x_k - \\frac{f(x_k)}{f^{\\prime}(x_k)}, \\quad k=0,1, \\ldots\n\\tag{8.2}\\]\n\n\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\nA natural question to ask is under what conditions does Newton’s method converge. In fact, it isn’t hard to show that if the initial point \\(x_0\\) is not chosen properly (i.e. close enough to a root), Newton’s method will diverge. A typical example would be \\(y = \\arctan(x),\\) where if \\(x_0\\) isn’t close enough to the root the iterates quickly diverge to infinity.\n\n\n\n\n\nExample 8.1 Let \\(f(x) = x^6- x - 1 = 0\\) and let \\(x_0 = 1.5\\). It is easy to verify that one root is given by \\(x^{*} = 1.134724.\\)\nTo use Newton’s method we first need to calculate the derivative - \\(f^{\\prime}(x)= 6x^5 -1.\\)\nUsing Equation 8.2 allows us to compute the \\(k+1\\) iteration:\n\\[\n\\begin{aligned}\nx_{k+1} &= x_k - \\frac{f(x_k)}{f^{\\prime}(x_k)}, \\\\\nx_{k+1} &= x_k - \\frac{x^6_k- x_k - 1 }{6x^5_k- 1 }.\n\\end{aligned}\n\\]\nProceeding in the natural way from \\(x_0\\), we can generate the following sequence of iterates:\n\n\n\n\n\n\n\n\n\\(k\\)\n\n\\(x_k\\)\n\n\n0\n1.5\n1.5\n\n\n1\n\\(x_{1} = x_0 - \\frac{x^6_0- x_0 - 1 }{6x^5_0- 1 } = 1.5 - \\frac{8.8906}{44.5625}\\)\n1.3005\n\n\n2\n\\(x_{2} = x_1 - \\frac{x^6_1- x_1 - 1 }{6x^5_1- 1 } = 1.3005 - \\frac{2.5373}{21.3197}\\)\n1.1815\n\n\n3\n\\(x_{3} = x_2 - \\frac{x^6_2- x_2 - 1 }{6x^5_2- 1 } = 1.1815 - \\frac{0.5387}{12.8140}\\)\n1.1395\n\n\n\n\n\n\n\nUnder what conditions might we expect (local) convergence? Here by local we mean that the algorithm will converge if we start sufficiently close to a root. We will define this more carefully later.\nIf Newton’s method converges, how fast can we expect the convergence to be?",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Newton's Method</span>"
    ]
  },
  {
    "objectID": "Newton.html#error-analysis-for-newtons-method",
    "href": "Newton.html#error-analysis-for-newtons-method",
    "title": "8  Newton’s Method",
    "section": "8.2 Error Analysis for Newton’s Method",
    "text": "8.2 Error Analysis for Newton’s Method\nLet’s consider the Taylor expansion about \\(x = x^*\\).\n\\[\n0 = f(x_k) + (x^* - x_k) f^{\\prime}(x_k) + \\frac{(x^* - x_k)^2}{2} f^{\\prime\\prime}(\\xi).\n\\]\nDividing by \\(f^\\prime(x_k)\\) (we will assume for the time being that it’s not equal to zero for any \\(x_k\\)) we get:\n\\[\n0 = \\frac{f(x_k)}{f^{\\prime}(x_k)} + (x^* - x_k)  + \\frac{f^{\\prime\\prime}(\\xi)}{f^{\\prime}(x_k)} \\frac{(x^* - x_k)^2}{2} .\n\\]\nUsing the equation for Newton’s method we see that the first term is nothing but \\(x_k - x_{k+1}\\) and substituting into the above equation we get:\n\\[\n0 = x_k - x_{k+1} + (x^* - x_k)  + \\frac{f^{\\prime\\prime}(\\xi)}{f^{\\prime}(x_k)} \\frac{(x^* - x_k)^2}{2} .\n\\] We see that the \\(x_k\\) terms cancel out. Rearranging to put the error on the left-hand side of the equation yields:\n\\[\nx^* - x_{k+1}  =  \\frac{f^{\\prime\\prime}(\\xi)}{2 f^{\\prime}(x_k)} \\ (x^* - x_k)^2.\n\\tag{8.3}\\]\nThe quantity on the left-hand side of the equation is just the error at the \\(k+1\\) iteration, while the last term on the right-hand side is the error at the \\(k\\) iteration. As a result, we can interpret the equation to mean that the error at the \\(k+1\\) iteration is proportional to the square of the error at the \\(k\\) iteration. This type of error bound is called quadratic convergence (see Definition 11.1).\n\n\n\n\n\n\nRemark\n\n\n\nIf \\(f \\in C^2[a,b]\\) and \\(f^\\prime(x^*) = 0\\), then Newton’s method still converges but just not as rapidly. Consider for example \\(f(x) = x^4,\\) which has a root at \\(x=0\\), but where the first derivative is also equal to 0.\n\n\n\nSummary for Newton’s Method\n\nNewton’s Method Summary\n\n\n\n\n\n\nAdvantages\nDisadvantages\n\n\n\n\nDoesn’t require interval with function sign change\nNeed to have derivatives\n\n\nFast convergence rate – quadratic\nMay not converge from all starting points\n\n\nCan generalize to higher dimension\nCan be expensive (especially in higher dimensions)\n\n\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"\n\n\n\n\n\n\nMeza, Juan C. 2011. “Newton’s Method.” Wiley Interdisciplinary Reviews: Computational Statistics 3 (1): 75–78.",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Newton's Method</span>"
    ]
  },
  {
    "objectID": "Secant.html",
    "href": "Secant.html",
    "title": "9  Secant Method",
    "section": "",
    "text": "9.1 Secant Method\nRecall that Newton’s method uses the derivative of the function whose roots we seek. That is both its power and its main disadvantage. In many real-world problems, the derivative may be difficult to compute. In other cases, it could be expensive. And in the worst case, it may not even be available.\nThe secant method tries to address this disadvantage through an approximation to the derivative \\(f^{\\prime}(x)\\) that uses two points close to each other, i.e. the secant. Using the secant, a new iterate is computed in a fashion similar to Newton’s method.\nConsider a line through two points \\((x_0, f(x_0))\\) and \\((x_1, f(x_1))\\). Let \\(x_2\\) be the \\(x\\) intercept of this line.\nThen it follows that\n\\[\n\\frac{f(x_1) - f(x_0)}{x_1 - x_0} =  \\frac{f(x_1) - f(x_2)}{x_1 - x_2}\n\\]\nBut notice that \\(f(x_2) = 0\\), which leads to\n\\[\n\\frac{f(x_1) - f(x_0)}{x_1 - x_0} =  \\frac{f(x_1) - 0}{x_1 - x_2}\n\\]\nRearranging and solving for \\(x_2\\) yields\n\\[\nx_2 = x_1 - \\left[ \\frac{(x_1 - x_0)}{f(x_1) - f(x_0)} \\right] f(x_1)\n\\]\nwhich is used as the next guess in our sequence.\nThis then yields the form for the general secant method:",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Secant Method</span>"
    ]
  },
  {
    "objectID": "Secant.html#sec-secant",
    "href": "Secant.html#sec-secant",
    "title": "9  Secant Method",
    "section": "",
    "text": "Historical Note\n\n\n\nThe secant method is one of the oldest methods for solving nonlinear equations, and has an interesting history that can be traced back to the Rule of Double False Position described in the 18th-century BCE Egyptian Rhind Papyrus(Papakonstantinou 2009).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSecant Method\n\n\n\n\\[\nx_{k+1} = x_k - \\left[ \\frac{(x_k - x_{k-1})}{f(x_k) - f(x_{k-1})} \\right] f(x_k), \\quad k=0, 1, \\ldots\n\\tag{9.1}\\]\n\n\n\n\n\n\n\n\nRemark\n\n\n\nAnother way to view this is to note that the term in the brackets \\(\\frac{(x_k - x_{k-1})}{f(x_k) - f(x_{k-1})}\\) approximates the derivative of a function (or rather in this case, the inverse). Therefore, one could interpret the secant method as just Newton’s method with a finite difference approximation to the derivative.\n\n\n\nSummary for Secant Method\n\nSecant Method Summary\n\n\n\n\n\n\nAdvantages\nDisadvantages\n\n\n\n\nDo not need to have derivatives\nNeed to provide 2 initial points.\n\n\nCan have fast convergence (although not quadratic)\nMay not converge from all starting points\n\n\nGeneralizes to higher dimensions\nCan be expensive in higher dimensions\n\n\n\n\n\n\n\n\n\nRegula Falsi\n\n\n\nGiven that both bisection and secant method require two points, it may not be surprising to learn that the two methods can be combined into a new method, where the updated points in the secant method are chosen in a manner similar to bisection. This method goes by several names including the method of false position and regula falsi.",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Secant Method</span>"
    ]
  },
  {
    "objectID": "Secant.html#advanced-root-finding-in-higher-dimensions",
    "href": "Secant.html#advanced-root-finding-in-higher-dimensions",
    "title": "9  Secant Method",
    "section": "9.2 Advanced: Root Finding in Higher Dimensions",
    "text": "9.2 Advanced: Root Finding in Higher Dimensions\nFinding roots of nonlinear functions in dimensions higher than one has a long and rich history. So far of the methods that we have discussed: 1) bisection, 2) Newton’s, and 3) Secant, only Newton’s method has an obvious path forward. This section gives a brief overview on how one proceeds in the case of Newton’s method, and also provides a more general iterative procedure that is used in many applications.\nRecall that Newton’s method is based on approximating the next iterate in the sequence of approximations by using the following equation:\n\\[\nx_{k+1} = x_k - \\frac{f(x_k)}{f^{\\prime}(x_k)}, \\quad k=0,1, \\ldots\n\\]\nFirst, let’s rewrite the equation as follows:\n\\[\nx_{k+1} = x_k - {f^{\\prime}(x_k)}^{-1}{f(x_k)}, \\quad k=0,1, \\ldots\n\\]\nLet’s now assume that \\(F: \\mathbb{R}^n \\rightarrow \\mathbb{R}^n\\), where \\(n &gt;1\\). We can still take the derivative of this function, following all the usual rules. In this case, it results in a matrix, which is called the Jacobian and is given by:\n\\[\nJ(x_k) = {F^{\\prime}(x_k)} = \\left(  \\frac{\\partial f_i(x_k)}{\\partial x_j}\\right) \\quad i,j = 1, \\ldots, n.\n\\]\nNewton’s method can then be written as:\n\\[\nx_{k+1} = x_k - {J(x_k)}^{-1}{f(x_k)}, \\quad k=0,1, \\ldots\n\\]\nwhere the inverse is interpreted as matrix inversion.\n\n\n\n\n\n\nRemark\n\n\n\nIt is a fundamental precept in numerical analysis that one rarely computes the inverse of a matrix. As such, the usual method for stating Newton’s method in higher dimensions is as follows – at each iteration \\(k\\) solve for the step \\(s_k = (x_{k+1} - x_k)\\) by solving the linear equation: \\[{J(x_k)}s_k = {F(x_k)}. \\]\n\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"\n\n\n\n\n\n\nPapakonstantinou, JM. 2009. “Historical Development of the BFGS Secant Method and Its Characterization Properties,” April, 1167.",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Secant Method</span>"
    ]
  },
  {
    "objectID": "FixedPt.html",
    "href": "FixedPt.html",
    "title": "10  Fixed Point Method",
    "section": "",
    "text": "10.1 Fixed Point\nMethods for root finding are hard to analyze, especially if we include derivatives of \\(f\\). Another approach is to reformulate the problem to allow for easier analysis using what is known as a fixed point formulation. This approach has a long history and is also known as functional iteration, Picard iteration, and successive substitution.\nFirst let’s start with a definition.\nUsing the definition it is easy to see that finding fixed points is equivalent to finding roots of an equation.\nThe general idea is that if we have an approximation to the fixed point \\(x^*\\), then if we take \\(x_1 = g(x_0)\\), our hope is that \\(x_1\\) will be an even better approximation. There are many choices we can make for \\(g(x)\\) for any given \\(f(x)\\). And not too surprisingly, the choice of \\(g(x)\\) will be extremely important in determining whether we produce a good algorithm or not.\nIn the rest of the section, we will look into some of the details of this approach and what conditions are needed to ensure that the iteration converges.\nFor now, let’s state our algorithm as follows:\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Fixed Point Method</span>"
    ]
  },
  {
    "objectID": "FixedPt.html#sec-FixedPt",
    "href": "FixedPt.html#sec-FixedPt",
    "title": "10  Fixed Point Method",
    "section": "",
    "text": "Note:\n\n\n\nWe will do everything in \\(\\mathbb{R}^1\\) but the ideas hold in higher dimensions with appropriate generalizations.\n\n\n\n\nDefinition 10.1 The point \\(x^{*} \\in \\mathbb{R}\\) is said to be a fixed point of \\(g:\\mathbb{R} \\rightarrow \\mathbb{R}\\) if \\(g(x^{*}) = x^{*}.\\)\n\n\n\nTheorem 10.1 (Fixed Point) Suppose \\(x^*\\) is not a zero of g(x). Then \\(x^*\\) is a zero of \\(f(x)\\) if and only if \\(x^*\\) is a fixed point of \\(g(x)\\).\n\n\nProof. If \\(x^*\\) is a zero of \\(f(x)\\) , i.e. \\(f(x^*) = 0,\\) then clearly \\(g(x^*) = x^*\\). On the other hand, if \\(g(x^*) = x^*\\) then\n\\[\nx^* = x^* + g(x^*)f(x^*)\n\\]\nfrom which it follows that \\[\ng(x^*)f(x^*) = 0\n\\] and therefore \\(f(x^*) = 0\\) since we assumed that \\(g(x^*) \\neq 0\\)\n\n\n\n\n\n\n\nNote\n\n\n\nNote that once we know how to find fixed points, we can find zeros of a function.\n\n\n\n\n\nx = x0\nfor (i in 1:maxiter) {\n  xplus &lt;- g(x)\n  if (g(xplus) &lt; ftol) {break}\n  x &lt;- xplus\n}\n# Either we met the maxiter criteria or the ftol criteria\nxsol &lt;- xplus\n  \n\nExample 10.1 Let’s suppose that the sqrt key on your calculator is broken and you need to compute \\(\\sqrt 3\\). This is equivalent to finding a solution of the function \\(f(x) = x^2 - 3 = 0\\).\nFirst attempt:\n\\(g(x) = 3/x, x_0 = 1\\)\nUsing the algorithm above we get the following sequence of iterates:\n\\[\n\\begin{aligned}\nx_0 &= 1 \\\\\nx_1 &= 3/x_0 = 3 \\\\\nx_2 &= 3/x_1 = 1 \\\\\nx_3 &= 3/x_2 = 3 \\\\\n\\vdots\n\\end{aligned}\n\\]\nApparently, this is not a good choice!\nSecond attempt:\n\\(g(x) = \\frac{1}{2}(x + 3/x), x_0 = 1\\)\nThis time the sequence of iterates is:\n\\[\n\\begin{aligned}\nx_0 &= 1 \\\\\nx_1 &= \\frac{1}{2}(x_0+3/x_0) = 2\\\\\nx_2 &= \\frac{1}{2}(x_1+3/x_1) = 1.75 \\\\\nx_3 &= \\frac{1}{2}(x_2+3/x_2) = 1.73214 \\\\\nx_4 &= \\frac{1}{2}(x_3+3/x_3) = 1.7320508 \\\\\n\\vdots\n\\end{aligned}\n\\]\nNote that after only 4 iterations, our solution appears to be a great approximation to \\(\\sqrt 3\\). Later on, we’ll find out why this choice of \\(g(x)\\) is a good choice.\n\n\nExercise 10.1 (In class exercise:) Compute \\(\\sqrt 5\\) using the same procedure as above with \\(g(x) = \\frac{1}{3}(2x + 5/x^2), \\ x_0 = 1.\\)\n\\[\n\\begin{aligned}\nx_0 &= 1 \\\\\n\\\\\nx_1 &= \\frac{1}{3}(2x_0+5/x_0^2) = \\\\\n\\\\\nx_2 &=  \\\\\n\\\\\nx_3 &=  \\\\\n\\\\\nx_4 &=  \\\\\n\\\\\n\\vdots\n\\end{aligned}\n\\]",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Fixed Point Method</span>"
    ]
  },
  {
    "objectID": "FixedPtEU.html",
    "href": "FixedPtEU.html",
    "title": "11  Fixed Point Existence and Uniqueness",
    "section": "",
    "text": "11.1 Existence and Uniqueness of Fixed Points\nAt this point, there are several questions that arise naturally:\nWe’ll take each of these points in turn starting with (1) and (2) using the following theorem.",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fixed Point Existence and Uniqueness</span>"
    ]
  },
  {
    "objectID": "FixedPtEU.html#sec-fpexistuniq",
    "href": "FixedPtEU.html#sec-fpexistuniq",
    "title": "11  Fixed Point Existence and Uniqueness",
    "section": "",
    "text": "Is there a fixed point \\(x^*\\) in the interval \\([a,b]?\\)\nIf yes, is it unique?\nDoes a given fixed point iteration generate a sequence of iterates \\(\\{ x_k \\} \\rightarrow x^*?\\)\nAnd if yes, how fast will the iterates converge to the fixed point?\n\n\n\nTheorem 11.1 If \\(g \\in C[a,b]\\) and \\(g(x) \\in [a,b] \\ \\forall x \\in [a,b],\\) then there exists a fixed point \\(x^* \\in [a,b].\\)\nIf in addition, \\(g^\\prime(x)\\) exists on \\((a,b)\\) and there exists a positive constant \\(k &lt; 1\\) with \\(| g^\\prime(x) | \\leq k \\quad \\forall x \\in (a,b)\\) then there exists exactly 1 fixed point in \\([a,b]\\).\n\n\nProof. The first part of the theorem states the condition for the existence of a fixed point. The second part states the conditions necessary for uniqueness. Let’s take them one at a time.\nExistence.\nThere are two cases to consider. The first is if the fixed point is one of the endpoints of the interval \\([a,b]\\). The second case, is if the fixed point is in the interior.\nIf \\(g(a) =a\\) or \\(g(b) = b\\), then clearly the fixed point \\(x^* = a\\) or \\(b,\\) so we’re done.\nIf not, then if the fixed point exists it must lie in the interior, i.e. \\(g(a) \\neq a\\) and \\(g(b)\\neq b\\). By assumption \\(g(x)\\) maps the interval \\([a,b]\\) onto itself, so we can deduce that\n\\[\ng(a) &gt; a \\quad \\mbox{and} \\quad g(b)  &lt; b.\n\\]\nLet’s now consider the function\n\\[\nh(x) = g(x) - x\n\\]\nFirst note that \\(h(x)\\) is continuous on \\([a,b]\\) since \\(g(x)\\) is continuous. Next, it is easy to see that it also satisfies the conditions:\n\\[\n\\begin{aligned}\nh(a) &= g(a) - a &gt; 0 \\\\\nh(b) &= g(b) - b &lt; 0\n\\end{aligned}\n\\]\nNow, by the Intermediate Value Theorem, there exists a point \\(x^* \\in (a,b)\\) such that \\(h(x^*) = 0.\\) But using the definition of \\(h(x)\\) that means that\n\\[\n\\begin{aligned}\nh(x^*) &= 0 = g(x^*) - x^* \\\\\n&\\implies g(x^*) = x^*\n\\end{aligned}\n\\]\nSo \\(x^*\\) must be a fixed point in \\([a,b]\\).\nUniqueness To show that a unique fixed point exists we will have need of the second condition \\[\n| g^\\prime (x) | \\leq k &lt; 1\n\\] The proof will be by contradiction. Let’s assume that we have two fixed points \\(x^*, y^*\\) and that \\(x^* \\neq y^*\\). Using the Mean Value Theorem we can say that: \\[\n\\frac{g(x^*) - g(y^*)}{x^* - y^*} = g^\\prime(\\xi) \\quad \\xi \\in [x^*, y^*] \\subset[a,b].\n\\] Let’s now consider \\(|x^* - y^*|\\): \\[\n|x^* - y^*| = |g(x^*) - g(y^*)| = | g^\\prime(\\xi)| \\cdot |x^* - y^*| &lt; k \\cdot|x^* - y^*|\n\\] The first equation is true by the definition of a fixed point, and the second from the equation above derived from the MVT. The final inequality is due to the assumption on the bound of the derivative of \\(g.\\) But since the constant \\(k &lt; 0,\\) this reduces to: \\[\n|x^* - y^*| &lt;  |x^* - y^*|\n\\] which is a contradiction. Therefore, \\(x^*\\) must be unique. \\(\\blacksquare\\)",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fixed Point Existence and Uniqueness</span>"
    ]
  },
  {
    "objectID": "FixedPtEU.html#more-on-convergence-of-sequences",
    "href": "FixedPtEU.html#more-on-convergence-of-sequences",
    "title": "11  Fixed Point Existence and Uniqueness",
    "section": "11.2 More on convergence of sequences",
    "text": "11.2 More on convergence of sequences\nThe question of convergence is not simply a matter of deciding when one should stop an iterative method. When one has a choice of different algorithms to pick from, it would make sense to choose the one that is fastest, where fastest can be loosely defined to be the one that is likely to take the fewest number of iterations. Towards that end, let’s discuss convergence in a bit more detail.\n\nDefinition 11.1 We say that the rate of convergence of \\(x_k\\) to \\(x^*\\) is of q-order \\({p} &gt; 0\\) if \\[\n\\lim_{k\\rightarrow \\infty} \\frac{|x_{k+1} - x^*|}{|x_{k} - x^*|^p} &lt; \\infty\n\\] For the special case of \\(p=1\\) we ask instead that \\[\n\\lim_{k\\rightarrow \\infty} \\frac{|x_{k+1} - x^*|}{|x_{k} - x^*|} &lt; 1\n\\]\nThis is known as a linear rate of convergence.\nIn addition, if for some sequence \\(\\{ c_k \\} \\rightarrow 0\\) we have\n\\[\n|x_{k+1} - x^*| \\leq c_k \\ |x_{k} - x^*|\n\\]\nthen the sequence \\(\\{ x_k \\}\\) is said to converge q-superlinearly to \\(x^*\\).\n\n\n\n\n\n\n\nRemark\n\n\n\nIf \\(p=2\\), we say the rate of convergence is quadratic. All other things being equal, the larger the value of \\(p\\), the faster an algorithm will converge to a solution. In other words, a quadratic rate of convergence is superior to a linear rate of convergence. Superlinear rate of convergence lies between quadratic and linear.\n\n\n\nExamples.\n\n\\(x_k = a^k, \\quad 0 &lt; a &lt; 1\\)\n\\(x_k = a^{2^k}, \\quad 0 &lt; a &lt; 1\\)\n\\(x_k = \\big (\\frac{1}{k} \\big )^k\\)\n\n\n\nSolutions:\n(1) linear, (2) quadratic, (3) superlinear.\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Fixed Point Existence and Uniqueness</span>"
    ]
  },
  {
    "objectID": "FixedPtConvg.html",
    "href": "FixedPtConvg.html",
    "title": "12  Fixed Point Iteration Convergence (Part 1)",
    "section": "",
    "text": "12.1 Fixed Point Iteration Convergence (Part 1)\nNow that we’ve answered questions (1) and (2) on the existence and uniqueness of fixed points, we will turn our attention to the last two questions dealing with the convergence of the fixed point iteration itself.\nLet’s first recall what a fixed point iteration looks like:\nIn order to better understand the possible cases, let’s take a look at a couple of pictures.\nWhat the third case appears to show is that if the slope of the function \\(g(x)\\) is too large, then the iteration might not converge. Another way to think about this is that the derivative must be bounded in some way for the fixed point iteration to converge.\nWe can in fact prove this rigorously. Your textbook proves convergence by making an assumption on the derivative of \\(g(x)\\) and specifically that there is a constant \\(k &lt;1\\) such that:\n\\[\n|g^\\prime (x) | \\leq k \\quad \\forall x \\in [a,b]\n\\]\nHere, we will use another concept that will prove useful in later lectures. It also has the additional benefit of not requiring the assumption that the derivative of \\(g(x)\\) exists.\nAs it turns out there is a close relation of the Lipschitz constant to the derivative. Recall that by the MVT\n\\[\ng(x) - g(y) = g^\\prime(\\xi)(x-y) \\quad \\xi \\in (x,y) \\subset [a,b].\n\\]\nTaking absolute values of both sides we get:\n\\[\n\\big | g(x) - g(y) \\big |= \\big | g^\\prime(\\xi) \\big | \\cdot \\big | x-y \\big | \\quad \\xi \\in (x,y) \\subset [a,b].\n\\]\nNow, if we let\n\\[\nL = \\max _{\\xi \\in [a,b]}| g^\\prime(\\xi) \\big |,\n\\]\nit follows that:\n\\[\n\\big | g(x) - g(y) \\big | \\leq L \\cdot \\big | x-y \\big | \\quad x \\in [a,b].\n\\]\nIntuitively this makes sense as bounding the derivative is similar to bounding the change in the function values.\nTo begin our proof, we will need one final definition.",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Fixed Point Iteration Convergence (Part 1)</span>"
    ]
  },
  {
    "objectID": "FixedPtConvg.html#sec-FixedPtConvg",
    "href": "FixedPtConvg.html#sec-FixedPtConvg",
    "title": "12  Fixed Point Iteration Convergence (Part 1)",
    "section": "",
    "text": "Does a given fixed point iteration generate a sequence of iterates \\(\\{ x_k \\} \\rightarrow x^*?\\)\nAnd if yes, how fast will the iterates converge to the fixed point?\n\n\nx = x0\nfor (i in 1:maxiter) {\n  xplus &lt;- g(x)\n  if (g(xplus) &lt; ftol) {break}\n  x &lt;- xplus\n}\n# Either we met the maxiter criteria or the ftol criteria\nxsol &lt;- xplus\n\n\n\n\n\n\n\nNote\n\n\n\nTo do: Insert pictures here:\n\n\n\n\n\n\n\nDefinition 12.1 A function \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\) is said to be Lipschitz continuous if\n\\[\n|g(x) - g(y) | \\leq L \\ | x-y| \\quad \\forall x \\in [a,b].\n\\]\n\\(L\\) is called the Lipschitz constant.\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition 12.2 We say that \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\) is a contraction mapping if\n\\[\n|g(x) - g(y) | \\leq L \\ | x-y| \\quad \\forall x \\in [a,b].\n\\] with \\(L&lt;1\\).\n\n\nExample:\n\\[\nf(x) = e^x - 2x - 1 \\quad \\mbox{on } [1,2] \\\\\ng(x) = \\ln(2x+1)\n\\]\n\n\nSolution:\nOutline:\n\nCompute \\(g^\\prime\\)\nNote that \\(g^\\prime\\) is monotonically decreasing on given interval\nShow bound on \\(g^\\prime\\), and in particular that the bound is &lt; 1.\n\nWe’re now ready to show our first convergence theorem for fixed point iterations.\n\nTheorem 12.1 (Fixed Point Convergence) Suppose \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\), with \\(g(x) \\in [a,b] \\quad \\forall x \\in [a,b]\\) be a continuous contraction mapping. Then there exists a unique fixed point \\(x^*\\) with \\(g(x^*) = x^*\\) and the fixed point iteration converges to \\(x^*\\) for any starting point \\(x_0 \\in [a,b]\\).\n\n\nProof. Existence and uniqueness of a fixed point was proven earlier. To prove convergence of the fixed point iteration we need to show that \\(\\{ x_k \\} \\rightarrow x^*\\) for the fixed point iteration:\n\\[x_{k+1} = g(x_k)\\]\nLet’s consider:\n\\[x_k - x^* = g(x_{k-1}) - g(x^*)\\]\nTaking absolute values and using the fact that \\(g\\) is a contraction mapping we can write\n\\[\\big | x_k - x^* \\big |= \\big | g(x_{k-1}) - g(x^*) \\big | \\leq L \\ \\big | x_{k-1} - x^* \\big |.\\]\nNow we apply this inductively:\n\\[\n\\big | x_k - x^* \\big | \\leq L^k \\ \\big | x_0 - x^* \\big |.\n\\]\nBut since \\(L &lt; 1\\) we know that \\(L^k \\rightarrow 0, k \\rightarrow \\infty\\) and therefore \\[\n\\big \\| x_k - x^* \\big \\| \\rightarrow 0, k \\rightarrow \\infty\n\\] as we set out to show. \\(\\blacksquare\\)\n\nRemark: As it turns out, while a contraction mapping is a useful tool, it is often hard to verify in a real-world application. Instead what is usually assumed is that either the function is Lipschitz continuous in a neighborhood of the fixed point \\(x^*\\), or that the function has a bounded derivative at the root.\nAnother thing to keep in mind is that it might be unrealistic to assume a contraction mapping property for all \\(x \\in [a,b]\\). An alternative is to assume that we have some property that holds at or near the solution. In this case, then we have a different type of convergence.\n\nDefinition 12.3 The iterative process \\(x_{k+1} = g(x_k)\\) is said to be locally convergent to the fixed point \\(x^*\\) if there exists \\(\\delta &gt; 0\\) such that \\({x_k} \\rightarrow x^*\\) for any \\(x_0\\) satisfying \\(| x^* - x_0 | \\leq \\delta.\\)\n\nPerhaps the simplest interpretation of this definition is to say, if we start close enough to a fixed point, then the method will converge to it. What defines close enough, will depend not only on the initial point, but also on the function we use.\nWith this background, we can state the following theorem.\n\nTheorem 12.2 Suppose \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\) is continuously differentiable and:\n\n\\(x^* = g(x^*)\\)\n\\(| g^{\\prime} (x^*) | &lt; 1\\)\n\nThen the iterative process \\(x_{k+1} = g(x_k)\\) is locally convergent to \\(x^*\\).\n\nRemark: Note the difference here that we are only asking for a bound on \\(g^\\prime\\) at a single point, namely the fixed point, \\(x^*\\).\n\nProof. The proof follows much the same as before, but now we have to also show that \\(\\big | g^\\prime (x) \\big | &lt; 1\\) for all \\(x\\) in a neighborhood of \\(x^*\\). Since we are assuming that \\(g\\) is continuously differentiable, this is fairly easy to show.\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Fixed Point Iteration Convergence (Part 1)</span>"
    ]
  },
  {
    "objectID": "FixedPtQConvg.html",
    "href": "FixedPtQConvg.html",
    "title": "13  Fixed Point Iteration Convergence (Part 2)",
    "section": "",
    "text": "13.1 Fixed Point Iteration Convergence (Part 2)\nRemark: This theorem shows us that if we want quadratic convergence, we should look for fixed point methods such that \\(g^\\prime(x^*) = 0\\).\nLet’s consider the general form \\[\ng(x) = x - \\phi(x) f(x)\n\\tag{13.2}\\]\nwhere \\(\\phi(x)\\) is differentiable and to be chosen later. Taking derivatives we have: \\[\ng ^\\prime (x) = 1 - \\phi^\\prime(x) f(x) - f^\\prime(x) \\phi(x).\n\\] Letting \\(x = x^*\\), such that \\(f(x^*) = 0\\), we get: \\[\ng ^\\prime (x^*) = 1 - f^\\prime(x^*) \\phi(x^*).\n\\] By our theorem, if we want quadratic convergence we need to have \\(g^\\prime (x^*) = 0\\), hence \\[\n0 = 1 - f^\\prime(x^*) \\phi(x^*),\n\\] and solving for \\(\\phi\\) we get the result: \\[\n\\phi(x^*) = \\frac{1}{ f^\\prime(x^*)}.\n\\] Substituting back into our general form (Equation 13.2) we have: \\[\ng(x) = x - \\frac{f(x)}{f^\\prime(x)}.\n\\] But that’s just Newton’s method!\nAs a result, an immediate corollary to (Theorem 13.1) is that Newton’s method is quadratically convergent.",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Fixed Point Iteration Convergence (Part 2)</span>"
    ]
  },
  {
    "objectID": "FixedPtQConvg.html#sec-FixedPtConvgB",
    "href": "FixedPtQConvg.html#sec-FixedPtConvgB",
    "title": "13  Fixed Point Iteration Convergence (Part 2)",
    "section": "",
    "text": "Theorem 13.1 Suppose \\(g: \\mathbb{R} \\rightarrow \\mathbb{R}\\) is twice continuously differentiable and the iterative process \\(x_{k+1} = g(x_k)\\) is locally convergent.\nThen the convergence rate is linear if \\[| g^{\\prime} (x^*) | \\neq 0\\]\nand the convergence rate is at least quadratic if\n\\[\n|g^{\\prime} (x^*) | = 0.\n\\]\n\n\nProof. We’ve already shown that the fixed point iteration converges (Theorem 12.1). To show that we have linear convergence, we can either show that we can bound the derivative in a neighborhood of the fixed point or we can use the Lipschitz continuity condition, to show that the error at any iteration is bounded by \\(L &lt; 0\\), which gives us a linear rate of convergence.\nTo show that the convergence rate is at least quadratic, let’s first expand \\(g(x)\\) In a Taylor polynomial about the point \\(x^*\\).\n\\[\ng(x) = g(x^*) + g^\\prime(x^*) (x-x^*) + \\frac{g^{\\prime \\prime}(\\xi)}{2} (x - x^*)^2.\n\\tag{13.1}\\]\nBy assumption we know that:\n\\[\ng(x^*) = x^* \\mbox{ and  } g^\\prime(x^*) = 0.\n\\]\nSubstituting into (Equation 13.1), we get:\n\\[\ng(x) = x^* + 0 + \\frac{g^{\\prime \\prime}(\\xi)}{2} (x - x^*)^2.\n\\]\nSetting \\(x=x_k,\\) we have:\n\\[\ng(x_k) = x^* + \\frac{g^{\\prime \\prime}(\\xi_k)}{2} (x_k - x^*)^2,\n\\] with \\(\\xi_k\\) between \\(x_k\\) and \\(x^*\\).\nUsing the definition of the fixed point iteration: \\(x_{k+1} = g(x_k),\\) we have\n\\[\nx_{k+1} = x^* + \\frac{g^{\\prime \\prime}(\\xi_k)}{2} (x_k - x^*)^2,\n\\] Rearranging we have: \\[\n\\frac{x_{k+1} -x^*}{(x_k - x^*)^2} =  \\frac{g^{\\prime \\prime}(\\xi_k)}{2} ,\n\\] Finally, by assumption, the fixed point iteration is locally convergent which means that \\[\n\\{ x_k \\} \\rightarrow x^* \\implies \\{ \\xi_k \\} \\rightarrow x^*\n\\] since \\(\\xi_k\\) is between \\(x_k\\) and \\(x^*\\). Therefore\n\\[\n\\frac{x_{k+1} -x^*}{(x_k - x^*)^2} =  \\frac{g^{\\prime \\prime}(x^*)}{2} = C &lt; \\infty,\n\\] which proves that the iterates are converging q-quadratically.\n\n\n\n\n\n\nExample 13.1 Recall our earlier example (Example 10.1) where we wanted to find the root of \\(x^2 - 3,\\) that led us to try different fixed point iterations.\n\n\\(g(x) = 3/x, \\implies g^\\prime(x) = -3/x^2.\\) \\[ g^\\prime(x^*) = g^\\prime(\\sqrt 3) = -1 \\quad \\implies \\quad \\mbox{No convergence}\\]\n\\(g(x) = \\frac{1}{2}(x + 3/x), \\implies g^\\prime(x) = \\frac{1}{2}(1 -3/x^2).\\) \\[ g^\\prime(x^*) = g^\\prime(\\sqrt 3) = 0 \\quad \\implies \\quad \\mbox{q-quadratic convergence}\\]\n\\(g(x) = x - \\frac{x^2 -3}{7}, \\implies g^\\prime(x) = 1 - \\frac{1}{7}(2x).\\) \\[ g^\\prime(x^*) = g^\\prime(\\sqrt 3) = 0.505 \\quad \\implies \\quad \\mbox{Linear convergence}\\]",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Fixed Point Iteration Convergence (Part 2)</span>"
    ]
  },
  {
    "objectID": "FixedPtQConvg.html#final-note-on-convergence",
    "href": "FixedPtQConvg.html#final-note-on-convergence",
    "title": "13  Fixed Point Iteration Convergence (Part 2)",
    "section": "13.2 Final note on convergence",
    "text": "13.2 Final note on convergence\nSometimes it is useful to estimate the number of iterations required to achieve a certain reduction in the error. We were able to do this in the case of the bisection method as each iteration reduced the interval in half, so therefore it was easy to compute the number of iterations needed to reduce the error by a certain factor (Equation 7.2).\nWe can do something similar for other methods, although it can be a bit trickier. Suppose that we know that we have q-linear convergence with a constant \\(\\lambda,\\) i.e.\n\\[\n\\lim_{k\\rightarrow \\infty} \\frac{|x_{k+1} - x^*|}{|x_{k} - x^*|} = \\lambda &lt; 1\n\\]\nOne way to approach this is to consider our proof of convergence for the fixed point iteration (Theorem 12.1). We were able to show that\n\\[\n\\big | x_k - x^* \\big | \\leq L^k \\ \\big | x_0 - x^* \\big |.\n\\]\nSuppose we would like to reduce the error by a factor of \\(10\\) after \\(k\\) iterations. Setting \\(\\lambda = L\\), this means that we want to have:\n\\[\n\\lambda^k = 10^{-1}\n\\]\nTaking logs of both sides we have:\n\\[\nk \\ \\log_{10} \\lambda = -1\n\\]\nor equivalently\n\\[\nk = -\\frac{1}{\\log_{10} \\lambda}\n\\]\nThe value of \\(k\\) can be interpreted to mean that it approximates the number of iterations required to reduce the error by a factor of 10.\n\nExample 13.2 Suppose that we knew that a certain fixed point iteration \\(g\\) had a Lipschitz constant of \\(L = 2/3\\). Then setting \\(\\lambda = L\\).\n\\[\nk = - \\frac{1}{\\log_{10} (2/3)} \\approx \\frac{1}{0.176} = 5.68\n\\]\nwhich we can interpret to mean that it would take approximately \\(k = 6\\) iterations to reduce the error by a factor of 10.",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Fixed Point Iteration Convergence (Part 2)</span>"
    ]
  },
  {
    "objectID": "FixedPtQConvg.html#comparison-of-nonlinear-equation-methods",
    "href": "FixedPtQConvg.html#comparison-of-nonlinear-equation-methods",
    "title": "13  Fixed Point Iteration Convergence (Part 2)",
    "section": "13.3 Comparison of nonlinear equation methods",
    "text": "13.3 Comparison of nonlinear equation methods\nLet’s take a step back and summarize our main results:\n\nComparison of Different Solution Methods for Finding Roots of an Equation\n\n\n\n\n\n\n\n\nMethod\nAssumptions\nAdvantages\nDisadvantages\n\n\n\n\nBisection\n\\(f\\) is continuous; requires 2 starting points where function has opposite sign\nRobust; easy to implement\nLinear convergence\n\n\nNewton\n\\(f\\) is continuously differentiable\nFast convergence\nRequires derivatives\n\n\nSecant\n\\(f\\) is continuous\nDoesn’t require derivatives; superlinear convergence\nMight encounter cancellation error\n\n\nFixed Point\nNeed to have a good \\(g(x)\\)\nEasy to implement\nLinear convergence\n\n\n\nWe have not yet talked about the stability of the algorithms, but this will prove to be an important characteristic of any method we choose. More on this later.\n\nCorollary 13.1 Consider \\(f: \\mathbb{R} \\rightarrow \\mathbb{R}\\), twice continuously differentiable. Suppose:\n\n\\(f(x^*) = 0\\)\n\\(| f^{\\prime} (x^*) | \\neq 0\\)\n\nThen Newton’s method is locally convergent to \\(x^*\\).\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Nonlinear Equations",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Fixed Point Iteration Convergence (Part 2)</span>"
    ]
  },
  {
    "objectID": "PolyInterpIntro.html",
    "href": "PolyInterpIntro.html",
    "title": "Interpolation and Approximation",
    "section": "",
    "text": "Introduction\nWherein we cover methods for interpolation, approximation, and extrapolation. We will be following your textbook covering mostly sections 3.1, 3.3, and 3.5. Time permitting we may also some material on Chebyshev polynomials and least squares approximations.",
    "crumbs": [
      "Interpolation and Approximation"
    ]
  },
  {
    "objectID": "PolyInterpIntro.html#concepts-covered",
    "href": "PolyInterpIntro.html#concepts-covered",
    "title": "Interpolation and Approximation",
    "section": "Concepts Covered",
    "text": "Concepts Covered\n\nApproximation versus interpolation\nBasis Functions\nConstruction and evaluation of interpolants\nTheorem - Polynomial Interpolant Uniqueness\nLagrange Polynomials\nDivided Differences\nTheorem - Divided differences and derivatives\nTheorem - Polynomial Interpolant Error\nPiecewise Interpolation\nCubic Splines",
    "crumbs": [
      "Interpolation and Approximation"
    ]
  },
  {
    "objectID": "InterpIntro.html",
    "href": "InterpIntro.html",
    "title": "14  Polynomial Interpolation",
    "section": "",
    "text": "14.1 Interpolation and Extrapolation",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Polynomial Interpolation</span>"
    ]
  },
  {
    "objectID": "InterpIntro.html#sec-interpintro",
    "href": "InterpIntro.html#sec-interpintro",
    "title": "14  Polynomial Interpolation",
    "section": "",
    "text": "Motivation\nAlthough interpolation is usually not an end product in numerical analysis, it is used in many other techniques that we will study, so having a good understanding of the concepts in approximating functions or interpolating some given data will prove useful later.\nLet’s consider approximation first. There are two basic problems: 1) data fitting, and 2) approximating functions.\n\n\nData fitting\nFor ease, we will only consider the case of \\(\\mathbb{R^1}\\) here, although (as before) many of the ideas translate into higher dimensions. Suppose we are given a set of data points \\[\n\\{ (x_i, y_i) \\}_{i=0}^{n}.\n\\]\nOur goal is to find a function \\(v(x)\\) that fits the data in some yet to be determined way. As a quick aside, the points \\(x_i\\) are sometimes called the node points or simply just nodes.\nIf the data is believed to be accurate, we could also insist that \\(v(x)\\) match the data exactly, i.e. that \\[\nv(x_i) = y_i \\quad i = 0, 1, \\ldots n.\n\\]\nIf this is the case, then we say that \\(v(x)\\) interpolates the data.\nThis still leaves open the question of what we mean by fit, and also what might constitute a good function, i.e. what properties do we want in a function that fits the data.\nThe second area we will study is that of approximating a function. This situation might arise if we had a complicated or computationally expensive function. Our goal here is to find a simpler or cheaper function that we could use to approximate our expensive function. The techniques will be similar to the earlier case, but with the difference that here, we might be able to choose the points ourselves.\nOne typical use for approximating functions widely used in practice is to predict the value of the function at points other than those given (or chosen). If the point at which we want to predict the function value is inside the interval set by the data points, then we call it interpolation. If the point is chosen outside the interval, then we say it is extrapolation.\nAnother use for approximating functions arises in the context of other numerical methods. The most common example is in helping us to take derivatives or compute integrals of other functions.",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Polynomial Interpolation</span>"
    ]
  },
  {
    "objectID": "InterpIntro.html#general-representation",
    "href": "InterpIntro.html#general-representation",
    "title": "14  Polynomial Interpolation",
    "section": "14.2 General Representation",
    "text": "14.2 General Representation\nWe will first consider the general case of a linear form, in which we will write the approximating (interpolating) function as:\n\\[\nv(x) = \\sum_{j=0}^{n} c_j \\phi_j(x)\n\\]\nHere we call \\(\\{ c_j\\}_{j=0}^n\\) the unknown coefficients, and \\(\\{ \\phi_j\\}_{j=0}^n\\) the basis functions.\nWe will further assume that \\(\\{ \\phi_j\\}_{j=0}^n\\) are linearly independent.\n\n\n\n\n\n\nLinear form\n\n\n\nWhen we say that we will take the linear form, we mean that \\(v(x)\\) is written as a linear combination of the basis functions and not that \\(v(x)\\) is a linear function of x.\n\n\n\nExample 14.1 Examples of basis functions\n\nPolynomial (monomial): \\(\\phi_j(x) = x^j \\quad j=0, 1, \\ldots n\\)\nTrigonometric: \\(\\phi_j(x) = \\cos(jx) \\quad j=0, 1, \\ldots n\\)\n\n\nThere are many other forms that can be chosen, most of which are used for specific applications or problems with a special structure. For now we will restrict ourselves to polynomial interpolants. Some of the reasons that polynomials are a good first choice include:\n\nEasy to both construct and evaluate the interpolants.\nEasy to sum and multiply polynomials\nEasy to differentiate and integrate\nAnd despite their simple appearance, they can fit many different types of data.\n\nBefore we go to the next section, we should also say that there are two main stages when using polynomial interpolation.\n\nConstructing an interpolant. This usually entails computing the unknown coefficients given a particular set of data points. This can be expensive, but it is done only once for a given data set.\nEvaluating an interpolant. Once the polynomial is constructed, we are then able to evaluate the polynomial at some point or some set of points. This is typically much less expensive per evaluation, but we may want to do it many times.",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Polynomial Interpolation</span>"
    ]
  },
  {
    "objectID": "InterpIntro.html#sec-Interpolation",
    "href": "InterpIntro.html#sec-Interpolation",
    "title": "14  Polynomial Interpolation",
    "section": "14.3 Polynomial (Monomial) Interpolation",
    "text": "14.3 Polynomial (Monomial) Interpolation\nPolynomials of one form or another are ubiquitous in numerical analysis. We will see that they can be used to approximate data, they are used to approximate derivatives in other contexts, and even to help us evaluate integrals numerically. Some of the uses of polynomials include approximating commonly used functions and in computer graphics to smooth curves and surfaces of geometric objects.\nLet’s recall that we can write a polynomial as:\n\\[\n\\begin{aligned}\np(x) &= \\sum_{j=0}^n c_j x^j ,\\\\\n&= c_0 + c_1x + c_2 x^2 + \\cdots + c_nx^n,\n\\end{aligned}\n\\tag{14.1}\\]\nfor a given set of \\(n+1\\) data points:\n\\[\n(x_0, y_0), (x_1, y_1), \\ldots, (x_n, y_n).\n\\]\nOur goal is to find the \\(n+1\\) coefficients \\(c_0, c_1, \\ldots, c_n,\\) such that we satisfy the interpolating conditions:\n\\[\np(x_i)= y_i, \\quad i=0, 1, \\ldots, n.\n\\]\n\n\n\n\n\n\nNote\n\n\n\nReminder: a polynomial of degree \\(n\\) has \\(n+1\\) coefficients.\n\n\nIt will also be necessary to assume that the data points are distinct, i.e.\n\\[\nx_i \\neq x_j \\quad \\forall \\quad i \\neq j.\n\\]\n\nExample 14.2 (Construction of Interpolating Polynomial) Suppose we are given the data $(x_0,y_0) = (1,1), (x_1, y_1) = (2,3),(x_2, y_2) = (4,3), $ and we wish to interpolate the first two data points using a first degree polynomial \\(n=1\\). In other words we want to construct the interpolating linear polynomial\n\\[\np_1(x) = c_0 + c_1 x.\n\\tag{14.2}\\]\nThe interpolating conditions give us:\n\\[\n\\begin{aligned}\np_1(x_0) = c_0 + 1 \\cdot c_1 = 1 \\quad (= y_0), \\\\\np_1(x_1) = c_0 + 2 \\cdot c_1 = 3 \\quad (= y_1).\n\\end{aligned}\\]\nThis is a set of two equations in two unknowns, which you can easily verify has the solution:\n\\[\nc_0 = -1 \\quad c_1 = 2.\n\\]\nThese coefficients can then be substituted into our polynomial form given by Equation 14.2 to yield the desired polynomial interpolant:\n\\[\np_1(x) = 2x - 1.\n\\]\nAs we mentioned earlier, now that we have constructed the polynomial, we are free to evaluate it at any number of other points.\nRemark: An alternate derivation of this form can be found in the supplemental section at the end of this section, see Section 14.4.2.\nIn class exercise:\nConstruct interpolating polynomial of degree \\(n=2\\), using the additional third point given above \\((x_2, y_2) = (4,3).\\)\nSolution:\n\\[\np_2(x) = \\frac{1}{3} \\big (-2x^2 + 12x - 7 \\big ).\n\\tag{14.3}\\]\n\n\nVandermonde Matrices\nIn solving the exercise problem above you will have noticed that you had to set up a set of equations that looked like:\n\\[\n\\begin{aligned}\np_2(x_0) &= c_0 + c_1 x_0 + c_2 x_0^2 &= y_0 \\\\\np_2(x_1) &= c_0 + c_1 x_1 + c_2 x_2^2 &= y_1 \\\\\np_2(x_2) &= c_0 + c_1 x_1 + c_2 x_2^2 &= y_2.\n\\end{aligned}\n\\]\nThese can be written more concisely in matrix notation as:\n\\[\n\\left[ \\begin{matrix}\n1 &x_0 &x_0^2 \\\\\n1 &x_1 &x_1^2 \\\\\n1 &x_2 &x_2^2 \\\\\n\\end{matrix} \\right]\\left[ \\begin{matrix} c_0\\\\c_1 \\\\ c_2 \\end{matrix} \\right] = \\left[ \\begin{matrix} y_0\\\\y_1 \\\\ y_2 \\end{matrix} \\right].\n\\tag{14.4}\\]\nor simply as\n\\[\nXc = y.\n\\]\nThis system of linear equations can now be solved for the coefficients \\(c_0, c_1, c_2\\), which determine our interpolating polynomial. The matrix \\(X\\) in Equation 14.4 is an example of a Vandermonde matrix. It can be shown that the \\(\\det X \\neq 0,\\) as long as the given data points are distinct. This implies that \\(X\\) is nonsingular and hence the linear system has a unique solution.\nIt is relatively easy to show that the general form of the Vandermone matrix for \\(n+1\\) data points is given by:\n\\[\n\\left[ \\begin{matrix}\n1 &x_0 &x_0^2 &\\cdots &x_0^n\\\\\n1 &x_1 &x_1^2 &\\cdots &x_1^n \\\\\n\\cdots & \\cdots &\\cdots &\\cdots & \\cdots \\\\\n1 &x_2 &x_2^2 & \\cdots &x_n^n \\\\\n\\end{matrix} \\right]\\left[ \\begin{matrix} c_0\\\\c_1 \\\\ \\cdots \\\\  c_n \\end{matrix} \\right] = \\left[ \\begin{matrix} y_0\\\\y_1 \\\\ \\cdots \\\\ y_n\\end{matrix} \\right].\n\\tag{14.5}\\]\nThis observation leads to the following theorem.\n\nTheorem 14.1 (Polynomial Interpolant Uniqueness) For any real data points \\(\\{ (x_i, y_i) \\}_{i=0}^n\\) such that \\(x_i\\) are distinct there exists a unique polynomial \\(p(x)\\) of degree at most \\(n\\) that satisfies the interpolating conditions \\(p(x_i) = y_1\\) for \\(i=0,1, \\ldots, n\\).\n\n\n\nSummary\nLet’s quickly summarize the use of this particular type of basis functions (monomials) as an interpolating function.\n\nWe introduced the concepts of approximation and interpolation - fitting a given set of points with a function, with interpolation being a special case of approximation.\nConsidered the general linear form for construction our approximating function and looked at our first case using polynomials and specifically monomials, i.e. \\(\\phi_j(x) = x^j\\).\nThis led to the construction of the Vandermonde matrix, which is extremely easy to set up..\nThe coefficients can be computed by solving one system of linear equations, which can be done in \\(O(n^3)\\) operations, and the evaluation of the interpolating polynomials can be done in \\(O(n)\\) operations.\nA big disadvantage is that the Vandermonde matrices are notoriously ill-conditioned for even medium dimensions. For \\(n=10, \\kappa (A) \\approx 10^{10}\\). As a result, using this approach is highly discouraged. (Notwithstanding this comment, for small \\(n\\), this approach might be useful.)\nThe resulting coefficients don’t have a clear relation to the \\(y_i\\) values, which is sometimes desired. This will come up when we study numerical differentiation and integration.",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Polynomial Interpolation</span>"
    ]
  },
  {
    "objectID": "InterpIntro.html#supplemental-materials",
    "href": "InterpIntro.html#supplemental-materials",
    "title": "14  Polynomial Interpolation",
    "section": "14.4 Supplemental Materials",
    "text": "14.4 Supplemental Materials\n\nWeierstrass Approximation\nA natural question to ask is if or when a general function \\(f(x)\\) can be approximated by a polynomial. This was answered by Weierstrass (1885) in a theorem bearing his name.\n\nTheorem 14.2 (Weierstrass Approximation) Suppose \\(f(x)\\) is defined and continuous on a closed interval \\([a,b]\\), and \\(\\epsilon &gt;0\\) is given. Then there exists a polynomial \\(p(x)\\) on \\([a,b]\\) such that\n\\[\n| f(x) - p(x) | &lt; \\epsilon \\quad \\forall x \\in [a,b].\n\\]\nThe most common way of stating this is that any continuous function on a closed interval can be approximated with arbitrary precision by a polynomial.\n\n\n\nAlternate derivation of linear interpolation using monomial basis functions\nLet’s begin with some simple cases - in particular the linear case. Suppose we are given two points \\((x_0, y_0)\\) and \\((x_1, y_1)\\), and \\(x_0 \\neq x_1\\). Then the straight line passing through these two points is given by the linear polynomial:\n\\[\np_1(x) = \\frac{(x_1 - x) y_0 + (x - x_0) y_1}{x_1 - x_0}.\n\\tag{14.6}\\]\nLet \\(x_0, x_1, \\ldots, x_n\\) be \\(n+1\\) distinct points on some interval \\([a,b]\\).\nWe say that \\(p_1(x)\\) interpolates the value \\(y_i\\) at the points \\(x_i, i= 0,1\\) if\n\\[\np_1(x_i) = y_i \\quad i = 0, 1.\n\\]\nIt isn’t too hard to see that Equation 14.6 satisfies this property by construction. Specifically note that:\n\\[\n\\begin{aligned}\np_1(x_1) &= \\frac{(x_1 - x_1) y_0 + (x_1 - x_0) y_1}{x_1 - x_0} \\\\\n&= \\frac{(0) y_0 + (x_1 - x_0) y_1}{x_1 - x_0} \\\\\n&= \\frac{(x_1 - x_0)}{x_1 - x_0} y_1 \\\\\n&= y_1\n\\end{aligned}\n\\]\nYou can use a similar argument to show that \\(p_1(x_0) = y_0.\\)\n\n\nComputational Tip\n\n\n\n\n\n\nShifted Power Form\n\n\n\nWhile the form given by Equation 14.1 is the most convenient for analysis, it can lead to numerical errors and we will often see instead the shifted power form:\n\\[\np(x) = c_0 + c_1(x-a) + c_2(x-a)^2 +\\cdots + c_n(x-a)^n,\n\\]",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Polynomial Interpolation</span>"
    ]
  },
  {
    "objectID": "InterpIntro.html#references",
    "href": "InterpIntro.html#references",
    "title": "14  Polynomial Interpolation",
    "section": "14.5 References",
    "text": "14.5 References\n\nInterpolation and Approximation. (Davis 1975)\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"\n\n\n\n\n\n\nDavis, Philip J. 1975. Interpolation and Approximation. Courier Corporation.",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Polynomial Interpolation</span>"
    ]
  },
  {
    "objectID": "InterpLagr.html",
    "href": "InterpLagr.html",
    "title": "15  Lagrange Polynomial Interpolation",
    "section": "",
    "text": "15.1 Lagrange Polynomials\nAs a result of the advantages and disadvantages listed above, other approaches have been developed that attempt to address the disadvantages. One such approach for constructing an interpolating polynomial consists of using what are known as the Lagrange polynomials.\nProceeding as before, let’s try to construct a polynomial using the general linear form using the following equation:\\[\n\\begin{aligned}\np(x) = p_n(x) &= \\sum_{j=0}^n y_j L_j(x) ,\\\\\n&= y_0 L_0(x) + y_1 L_1(x) + y_2 L_2(x) + \\cdots + y_n L_n(x),\n\\end{aligned}\n\\tag{15.1}\\]\nwhere \\(L_j(x)\\) are called Lagrange polynomials with the following properties:\n\\[\nL_j(x_i) = \\biggl\\{\n\\begin{matrix} {0, \\; i \\neq j} \\\\ {1, \\; i = j} \\end{matrix} \\quad j=0,1, \\ldots, n.\n\\tag{15.2}\\]\nUsing this definition, it isn’t hard to show that\n\\[\np_n(x_i) = y_i, \\quad i= 0,1,2, \\ldots, n.\n\\]\nIn other words, \\(p_n(x)\\) is an interpolating polynomial.\nFigure 15.1: Lagrange Coefficient Polynomials\nFigure 15.2 shows all three of the Lagrange polynomials in addition to the final interpolating polynomial \\(p_2(x)\\) of degree 2 for the 3 given data points.",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Lagrange Polynomial Interpolation</span>"
    ]
  },
  {
    "objectID": "InterpLagr.html#sec-interplagr",
    "href": "InterpLagr.html#sec-interplagr",
    "title": "15  Lagrange Polynomial Interpolation",
    "section": "",
    "text": "Kronecker notation\n\n\n\nYou may also see the Lagrange polynomials written in the more concise notation:\n\\[\nL_j(x_i) = \\delta_{ij}\n\\]\nwhere \\(\\delta_{ij}\\) denotes the Kronecker \\(\\delta\\) function. In simple terms, the Lagrange polynomials are equal to 1 at their corresponding node point. For example, \\(L_0(x_0) = 1\\) and \\(L_0(x_i) = 0\\) at all of the other node points not equal to \\(x_0\\). (see Figure 15.1).\n\n\n\n\nExample 15.1 Construct \\(p_2(x)\\) for data points \\((1,1), (2, 3), (4,3)\\) using the Lagrange polynomial formulation.\n\n\n\nSolution. The first step Is to compute the individual \\(L_j(x)\\) for the given data points \\((1,1), (2, 3), (4,3).\\)\nLet’s start with the first Lagrange polynomial \\(L_0(x).\\) By definition (Equation 15.2), we know that the polynomial must satisfy the following conditions for \\(j=0\\).\n\\[\nL_0(x_i) = \\biggl\\{\n\\begin{matrix} {0, \\; i \\neq 0} \\\\ {1, \\; i = 0} \\end{matrix}.\n\\]\nWe also know that \\(L_0\\) must be a quadratic polynomial (Why? ) As a result, we know that the general form for \\(L_0\\) must be:\n\\[\nL_0(x) = a\\cdot(x - r_1)(x - r_2),\n\\] where \\(r_1, r_2\\) are the two roots. To satisfy condition \\(L_0(x) = 0\\) at the two nodes other than \\(x_0\\), means that the two other nodes, \\(x_1 = 2, x_2 = 4\\) must be the two roots of the quadratic.\n\\[\nL_0(x) = a\\cdot(x-2)(x-4).\n\\]\nWe can now use the remaining condition \\(L_0(x_0) = 1\\) to see that:\n\\[\n\\begin{aligned}\nL_0(x_0) = 1 &= a\\cdot(x_0 - 2)(x_0 - 4), \\\\\n&= a \\cdot(1-2)(1-4) \\\\\n&= 3a\n\\end{aligned}\n\\]\nTherefore \\(a = 1/3\\) giving us the solution:\n\\[\nL_0(x) = \\frac{1}{3} (x-2)(x-4)\n\\]\nUsing the same procedure, we can compute:\n\\[\nL_1(x) = -\\frac{1}{2}(x-1)(x-4).\n\\]\nand finally:\n\\[\nL_2(x) = \\frac{1}{6}(x-1)(x-2).\n\\]\nI leave the computation of these two for you to practice on.\nUsing (Equation 15.1), we can now combine the 3 Lagrange polynomials and multiply by the corresponding \\(y_j\\) values to gives us the desired interpolating polynomial :\n\\[\n\\begin{aligned}\np_2(x) &= \\frac{y_0}{3}(x-2)(x-4)  -\\frac{y_1}{2}(x-1)(x-4) \\\\\n&+ \\frac{y_2}{6}(x-1)(x-2)\n\\end{aligned}\n\\]\nSubstituting for the values of \\(y\\) we get:\n\\[\n\\begin{aligned}\np_2(x) &= \\frac{1}{3}(x-2)(x-4)  -\\frac{3}{2}(x-1)(x-4) \\\\\n&+ \\frac{3}{6}(x-1)(x-2)\n\\end{aligned}\n\\tag{15.3}\\]\n\n\n\n\n\n\n\n\nFigure 15.2: Lagrange Polynomials and resulting 2nd degree polynomial\n\n\n\n\n\n\n\n\n\nUniqueness (again)\n\n\n\nOne should note at this point that while the two approaches appear different, they yield the same second degree interpolating polynomial. In other words Equation 14.3 = Equation 15.3 .\nRemark: It can be easily shown that there is only one quadratic interpolating polynomial for any three (distinct) points.\nProof. Suppose there were 2 polynomials \\(p_2(x), q_2(x)\\) that interpolate the given points. Then define\n\\[\nr(x) = p_2(x) - q_2(x).\n\\]\nFirst note that \\(r(x)\\) is also of degree \\(\\leq 2\\). But\n\\[\nr(x_i) = p_2(x_i) - q_2(x_i) = y_i - y_i = 0, \\quad i=0,1,2\n\\]\nThis means that \\(r(x)\\) has three distinct roots and has degree \\(\\leq 2\\). That isn’t possible unless \\(r(x) \\equiv 0\\) by the Fundamental Theorem of Algebra. Therefore \\(p_2(x) = q_2(x)\\).",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Lagrange Polynomial Interpolation</span>"
    ]
  },
  {
    "objectID": "InterpLagr.html#general-form-of-lagrange-polynomials",
    "href": "InterpLagr.html#general-form-of-lagrange-polynomials",
    "title": "15  Lagrange Polynomial Interpolation",
    "section": "15.2 General Form of Lagrange Polynomials",
    "text": "15.2 General Form of Lagrange Polynomials\nTo generalize this idea to a higher number of data points, first notice that we can write the Lagrange polynomial fitting the \\(n\\) points as:\n\\[\n\\begin{aligned}\nL_j(x) &= \\frac{(x - x_0)(x - x_1) \\cdots {\\color{blue}(x - x_{j-1})(x - x_{j+1})} \\cdots (x - x_n)}{(x_j - x_0)(x_j - x_1) \\cdots (x_j - x_{j-1}) (x_j - x_{j+1}) \\cdots (x_j - x_n)} \\\\\n&= \\prod_{i=0}^{n} \\frac{x - x_i}{x_j - x_i}.\n\\end{aligned}\n\\tag{15.4}\\]\nNote that the term in the numerator: \\[\n(x - x_0)(x - x_1) \\cdots (x - x_{j-1}) (x - x_{j+1}) \\cdots (x - x_n) = 0 \\quad \\forall \\ x_i \\neq x_j\n\\]is missing the \\(jth\\) term, hence for all other node points it will be equal to \\(0\\). In addition, if \\(x_i = x_j\\), then the numerator and the denominator are equal, hence \\(L_j(x)\\) satisfies the conditions for a Lagrange polynomial.\nGiven this formulation, the construction and evaluation of the interpolating polynomials proceeds as before.\n\nConstruction of \\(L_j(x)\\).\n\nTo simplify notation, we define the following terms:\n\\[\n\\begin{aligned}\n\\rho_j &= \\prod_{i\\neq j}^{n} {x_j - x_i} \\quad j=0,1, \\ldots, n,\\\\\nw_j &= \\frac{1}{\\rho_j},\n\\end{aligned}\n\\tag{15.5}\\] where the \\(w_j\\) are called the barycentric weights. ((Berrut and Trefethen 2004))\nRemark: Having computed these weights that’s it for construction!\nNotice also that this computation can be done in \\(O(n^2)\\) flops.\n\nEvaluation of \\(p_n(x)\\)\n\nTo evaluate the polynomial we just need to bring the different parts together. In order to simplify this process, first notice that if we define \\[\n\\begin{aligned}\n\\Psi(x) &= (x - x_0)(x - x_1)  \\cdots (x - x_n) \\\\\n&= \\prod_{i=0}^{n} {(x - x_i)}\n\\end{aligned}\n\\tag{15.6}\\] then we can write the interpolating polynomial as:\n\\[\np_n(x) = \\Psi(x) \\sum_{j=0}^n \\frac{w_j\\cdot y_j}{(x - x_j)}.\n\\tag{15.7}\\] Here all we’ve done is notice that the numerator of Equation 15.4 is nothing more than Equation 15.6 divided by the missing term \\((x - x_j)\\). When we insert this into the formula for the interpolating polynomial then \\(\\Psi(x),\\) which doesn’t depend on \\(j\\) can be pulled out of the summation sign. This also has the advantage that we just need to compute that term once! The rest of the evaluation can be done if \\(O(n)\\) flops.\nLet’s do one quick example using the data given below:\n\nData\n\n\n\n\\(i = 0\\)\n\\(i = 1\\)\n\\(i = 2\\)\n\\(i = 3\\)\n\n\n\n\n\\(x\\)\n-1.1\n1.1\n2.2\n0.0\n\n\n\\(y\\)\n0.0\n6.75\n0.0\n0.0\n\n\n\nFirst we construct the barycentric weights, \\(w_j = 1/\\rho_j, \\ j=0, 1, 2, 3\\).\n\n\\(j=0\\) \\[\n\\begin{aligned}\n\\rho_0 &= \\prod_{i \\neq j}^n (x_j - x_i), \\qquad j=0\\\\\n&= (x_0 - x_1)(x_0 - x_2)(x_0 -x_3) \\\\\n&= (-1.1 - 1.1)(-1.1 - 2.2)(-1.1 - 0)  \\\\\n&= (-2.2)(-3.3)(-1.1) \\\\\n&= - 7.986\n\\end{aligned}\n\\]\nSimilarly for \\(j=1\\)\n\n\\[\n\\begin{aligned}\n\\rho_1 &= \\prod_{i \\neq j}^n (x_j - x_i), \\qquad j=1\\\\\n&= (x_1 - x_0)(x_1 - x_2)(x_1 -x_3) \\\\\n&= (1.1 - (-1.1))(1.1 - 2.2)(1.1 - 0)  \\\\\n&= (2.2)(-1.1)(1.1) \\\\\n&= - 2.662\n\\end{aligned}\n\\] I’ll leave the computation of the other two as an exercise.\nSolution. \\[\n\\begin{aligned}\n\\rho_2 &= (x_2 - x_0)(x_2 - x_1)(x_2 -x_3) \\qquad j=2\\\\\n&=  7.986 \\\\\n\\rho_3 &= (x_3 - x_0)(x_3 - x_1)(x_3 -x_2) \\qquad j=3\\\\\n&=  2.662\n\\end{aligned}\n\\]\nHaving computed the \\(\\rho\\) values, the barycentric weights can now be easily computed.\nAn interesting feature of this formulation is that the construction of the interpolating polynomial does not depend on the values of \\(y\\) - we only need the data nodes \\(x_i\\).\n\n\n\n\n\n\nTip\n\n\n\nOnce we have computed the weights for a given set of \\(x\\) values, we can use them for any function whatsoever (as long as we know values at those nodes). This also means that since we never assumed any order of the nodes, the weights are independent of the order that the nodes are in. Based on this, it is not hard to show that Equation 15.7 can be re-written in the more elegant form of:\n\\[\n\\large {p_n(x) = \\frac{\\sum_{j=0}^n \\frac{w_j\\cdot y_j}{(x - x_j)}}{\\sum_{j=0}^n \\frac{w_j}{(x - x_j)}}.}\n\\tag{15.8}\\]\nwhere the term \\(\\Psi(x)\\) has been eliminated.\n\n\n\nSummary\nLet’s summarize the use of Lagrange basis functions as an interpolating function.\n\nWe introduced the concept of a Lagrange polynomial that can be used as a basis for an interpolating function\nWe also showed how to construct an interpolating polynomial using a special set of weights called barycentric weights.\nThe construction of this polynomial can be shown to be \\(O(n^2),\\) and does not depend on the values of \\(y\\) or \\(f(x)\\).\nOnce the construction has been completed, the interpolating polynomial can be used for any number of different functions, each evaluation costing \\(O(n)\\) flops.\nIt can also be shown that if we choose the data point properly, then the algorithm for constructing and evaluating this polynomial is stable. ((Higham 2004))",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Lagrange Polynomial Interpolation</span>"
    ]
  },
  {
    "objectID": "InterpLagr.html#references",
    "href": "InterpLagr.html#references",
    "title": "15  Lagrange Polynomial Interpolation",
    "section": "15.3 References",
    "text": "15.3 References\n\nBarycentric Lagrange Interpolation. (Berrut and Trefethen 2004)\nThe numerical stability of barycentric Lagrange interpolation. (Higham 2004)\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"\n\n\n\n\n\n\nBerrut, Jean-Paul, and Lloyd N. Trefethen. 2004. “Barycentric Lagrange Interpolation.” SIAM Review 46 (3): 501–17. https://doi.org/10.1137/S0036144502417715.\n\n\nHigham, Nicholas J. 2004. “The Numerical Stability of Barycentric Lagrange Interpolation.” IMA Journal of Numerical Analysis 24 (4): 547–56. https://doi.org/10.1093/imanum/24.4.547.",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Lagrange Polynomial Interpolation</span>"
    ]
  },
  {
    "objectID": "InterpDividedDiff.html",
    "href": "InterpDividedDiff.html",
    "title": "16  Divided Differences and Newton Interpolating Polynomials",
    "section": "",
    "text": "16.1 Divided Differences\nAs noted earlier, although an interpolating polynomial for a given set of points is unique, there are several algebraic representations we can use. We have one more form for interpolating polynomials that is frequently used.\nIt has the advantage that the coefficients can be easily computed as new data becomes available. This could prove especially useful in an experimental setup where one may not know how much data will be available at the beginning of the experiment.\nWe’ll need some new notation first in order to write down this new form for an interpolating polynomial. Let’s first recall the shifted form for expressing a polynomial:\n\\[\n\\begin{aligned}\np_n(x) &= c_0 + c_1(x-x_0) + c_2(x-x_0)(x - x_1) + \\ldots \\\\\n&+ c_n(x-x_0)(x-x_1)\\ldots(x-x_{n-1})\n\\end{aligned}\n\\]\nNote that we could determine the coefficients through the following procedure:\n\\[\n\\begin{aligned}\np_n(x_0) &= c_0 = f(x_0) \\\\\np_n(x_1) &= c_0 + c_1(x_1-x_0) = f(x_1) \\implies c_1 = \\frac{f(x_1) - f(x_0)}{x_1 - x_0}\\\\\n\\cdots\n\\end{aligned}\n\\]\nThe following notation will prove useful.\nHigher order divided differences can likewise be defined recursively in terms of lower order divided differences. For example the second-order divided difference can be expressed as:\n\\[\nf[x_i, x_{i+1}, x_{i+2}] = \\frac{f[x_{i+1},x_{i+2}] - f[x_{i},x_{i+1}]}{x_{i+2} - x_i},\n\\] so specifically for \\(i=0\\) we would have:\n\\[\nf[x_0, x_1, x_2] = \\frac{f[x_1,x_2] - f[x_0,x_1]}{x_{2} - x_0}\n\\]\nIn general, we can express the divided difference can be written as:\n\\[\nf[x_0, x_1, x_2, \\ldots, x_j] = \\frac{f[x_1,x_2, \\ldots, x_j] - f[x_0,x_1,\\ldots, x_{j-1}]}{x_{j} - x_0}\n\\tag{16.1}\\]\nEquation 16.1 is also known as the Newton divided difference form.",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Divided Differences and Newton Interpolating Polynomials</span>"
    ]
  },
  {
    "objectID": "InterpDividedDiff.html#sec-divdiff",
    "href": "InterpDividedDiff.html#sec-divdiff",
    "title": "16  Divided Differences and Newton Interpolating Polynomials",
    "section": "",
    "text": "Definition 16.1 The zeroth divided difference of a function \\(f\\) with respect to \\(x_i\\) is defined as \\(f[x_i] = f(x_i).\\) Using the procedure above as our guide, the first divided difference is defined as:\n\\[\nf[x_i, x_{i+1}] = \\frac{f[x_{i+1}] - f[x_i]}{x_{i+1} - x_i}\n\\]\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nDivided differences have some useful properties that we will use later on. The first important one is that the order of the data points doesn’t matter. In other words:\n\\[\nf[x_{i_0}, x_{i_1}, x_{i_2}, \\ldots, x_{i_n}] = f[x_0, x_1, x_2, \\ldots, x_n]\n\\]\nwhere\\(({i_0}, {i_1}, {i_2}, \\ldots, {i_n})\\) is a permutation of \\(0,1,2, \\ldots ,n\\). One can easily show that, for example:\n\\[\nf[x_1, x_0] = f[x_0, x_1].\n\\]\n\n\n\nExample 16.1 Compute the first and second divided differences for \\(f(x) = cos(x)\\), using \\(x_0 = 0.2, x_1 = 0.3, x_2 = 0.4\\).\n\\[\n\\begin{aligned}\nf[x_0, x_1] &= \\frac{f[x_{1}] - f[x_0]}{x_{1} - x_0} \\\\\n&= \\frac{\\cos(0.3) - \\cos(0.2)}{0.3 - 0.2} \\\\\n&= \\frac{0.955336489 - 0.980066578}{0.1} \\\\\n&= -0.24730089\n\\end{aligned}\n\\]\nLikewise\n\n\\[\n\\begin{aligned}\nf[x_1, x_2] &= \\frac{f[x_{2}] - f[x_1]}{x_{2} - x_1} \\\\\n&= \\frac{\\cos(0.4) - \\cos(0.3)}{0.1} \\\\\n&= \\frac{0.921060994 - 0.955336489}{0.1} \\\\\n&= -0.34275495\n\\end{aligned}\n\\]\nThe second divided difference is therefore given by:\n\n\n\\[\n\\begin{aligned}\nf[x_0, x_1, x_2] &= \\frac{f[x_{1},x_2] - f[x_0, x_1]}{x_{2} - x_0} \\\\\n&= \\frac{(-0.34275495) - (-0.24730089)}{0.4 - 0.2} \\\\\n&= -0.477727030\n\\end{aligned}\n\\]\n\n\n\nSolution. Example 16.1\n\n\nCode\nx0 = 0.2; x1 = 0.3; x2 = 0.4\n\n# first 2 divided differences\nfx0x1 = (cos(x1) - cos(x0))/(x1 - x0)\nfx1x2 = (cos(x2) - cos(x1))/(x2 - x1)\n\n# second order divided difference\nfx0x1x2 = (fx1x2 - fx0x1)/(x2 - x0)\nfx0x1x2\n\n\n[1] -0.4772703\n\n\nCode\n# actual\nfc = -cos(x1)/2\nfc\n\n\n[1] -0.4776682",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Divided Differences and Newton Interpolating Polynomials</span>"
    ]
  },
  {
    "objectID": "InterpDividedDiff.html#newton-interpolating-polynomials",
    "href": "InterpDividedDiff.html#newton-interpolating-polynomials",
    "title": "16  Divided Differences and Newton Interpolating Polynomials",
    "section": "16.2 Newton Interpolating Polynomials",
    "text": "16.2 Newton Interpolating Polynomials\nWhile divided differences have many applications, the one we will use here is as a means to write down an interpolating polynomial with an important computational property.\nSuppose as before that we have an interpolating polynomial of degree \\(n\\) such that \\(p_n(x) = f(x_i), i= 0, 1, \\ldots, n\\) with distinct data points. Then an interpolating polynomial can be written using Newton divided differences as follows:\n\\[\n\\begin{aligned}\np_1(x) &= f(x_0) + f[x_0, x_1](x - x_0)  \\\\\np_2(x) &= f(x_0) + f[x_0, x_1](x - x_0)  + f[x_0,x_1,x_2](x - x_0)(x-x_1)\\\\\n\\vdots \\\\\np_n(x) &= f(x_0) + f[x_0, x_1](x - x_0)  + \\ldots \\\\\n&+ f[x_0,x_1,\\ldots, x_n](x - x_0)(x-x_1)\\cdots (x-x_{n-1})\n\\end{aligned}\n\\]\nNote that for all interpolating polynomial of degree \\(n\\)&gt;1, they can all be constructed by using the previous interpolating polynomial of degree \\(n-1\\), with one additional term. For example:\n\\[\n\\begin{aligned}\np_1(x) &= f(x_0) + f[x_0, x_1](x - x_0)  \\\\\np_2(x) &= p_1(x) + f[x_0,x_1,x_2](x - x_0)(x-x_1)\\\\\n\\vdots \\\\\np_n(x) &= {\\color{blue} p_{n-1}(x)} + f[x_0,x_1,\\ldots, x_n](x - x_0)(x-x_1)\\cdots (x-x_{n-1})\n\\end{aligned}\n\\]\nIn general we can write:\n\\[\np_{k+1}(x) = {\\color{blue} p_k(x)} + f[x_0,x_1,\\ldots, x_k](x - x_0)(x-x_1)\\cdots (x-x_{k})\n\\]\nThe beauty of this form is that we can easily go from a polynomial of degree \\(k\\) to degree \\(k+1\\), by adding one (\\(k{-}th\\) order) divided difference.\n\n\n\n\n\n\nNote\n\n\n\nRemark: As before, it is not difficult to show that the Newton divided difference interpolating polynomial is exactly the same as the one we derived earlier (if perhaps in a slightly disguised form).\n\n\nThe following theorem will prove useful in future analysis.\n\nTheorem 16.1 Let \\(n \\geq 1\\) and assume that \\(f(x) \\in C^{n}[a,b]\\). Let \\(x_0, x_1, \\ldots, x_n\\) be \\(n+1\\) distinct points in \\([a,b]\\). Then\n\\[\nf[x_0, x_1, x_2, \\ldots, x_n] =\\frac{1}{n!} f^{n} (\\xi),\n\\]\nfor some \\(\\xi\\) between the minimum and maximum of \\(x_0, x_1, \\ldots, x_n\\).\n\nRemark: This might look familiar as it looks similar to the remainder term in the Taylor polynomial. As a result, it won’t come as a surprise that it will be useful in our error analysis (Section 17.1)",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Divided Differences and Newton Interpolating Polynomials</span>"
    ]
  },
  {
    "objectID": "InterpDividedDiff.html#summary",
    "href": "InterpDividedDiff.html#summary",
    "title": "16  Divided Differences and Newton Interpolating Polynomials",
    "section": "16.3 Summary",
    "text": "16.3 Summary\nWe’ve now seen three different approaches for computing interpolating polynomials. Let’s briefly summarize some of the most important features of each of them.\n\nInterpolating Polynomials Summary\n\n\n\n\n\n\n\n\n\nBasis\n\\[\n\\phi_j(x)\n\\]\nConstruction\nCost\nEvaluation\nCost\nDistinguishing\nFeature\n\n\n\n\nMonomial\n\\[\nx^j\n\\]\n\\[\nO(n^3)\n\\]\n\\[\nO(n)\n\\]\nSimple, easy\n\n\nLagrange\n\\[L_j(x)\\]\n\\[\nO(n^2)\n\\]\n\\[\nO(n)\n\\]\n\\[\nc_j = y_j\n\\], most stable\n\n\nNewton\n\\[\n\\prod_{i=0}^{j-1} (x - x_i)\n\\]\n\\[\nO(n^2)\n\\]\n\\[\nO(n)\n\\]\nAdaptive (can add new points)\n\n\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Divided Differences and Newton Interpolating Polynomials</span>"
    ]
  },
  {
    "objectID": "InterpErr.html",
    "href": "InterpErr.html",
    "title": "17  Interpolation Error",
    "section": "",
    "text": "17.1 Error in Polynomial Interpolation\nIf we have an interpolating polynomial for a given function at a set of points, we know that by definition, it must match the function exactly at the nodes. However, this also brings up a related question - How does \\(p_n(x)\\) behave at points other than the nodes \\(\\{x_i \\}?\\)\nIn order to consider this question we will make a few assumptions to help us with the analysis, specifically:\nLet’s first define the error function for the \\(n{-}th\\) degree interpolating polynomial:\n\\[\ne_n(x) = f(x) - p_n(x), \\quad x \\in [a,b].\n\\]\nThe question we would like to ask is what does the error look like for a point in the interval \\([a,b]\\) that is not one of the node points.\nHere we will use the simple observation that any \\(x\\) that is not a node can be treated as a new interpolation point. As such, we can use the Newton Interpolation formula for adding a new point, i.e.\n\\[\nf(x) = p_{n+1}(x) = {\\color{blue} p_n(x)} + f[x_0,x_1,\\ldots, x_n, x] \\Psi_n(x),\n\\] where\n\\[\n\\Psi_n(x) = (x - x_0)(x-x_1)\\cdots (x-x_{n}).\n\\]\nSubstituting this into the error function we get:\n\\[\ne_n(x) = f(x) - p_n(x) = f[x_0,x_1,\\ldots, x_n, x] \\Psi_n(x).\n\\]\nThis seems a little unsatisfying however as the error seems to depend both on the data points and an individual point \\(x\\).\nUsing Equation 16.1 we can replace the divided difference with the derivative:\nto give us the following formula for the error function:\n\\[\ne_n(x) = f(x) - p_n(x) = \\frac{f^{n+1} (\\xi)}{(n+1)!}\\Psi_n(x).\n\\]\nThis leads us directly to the following theorem.\nThis theorem is nice, but in order to proceed much further, we would need to know more about both \\(f\\) and \\(\\Psi_n(x)\\). Nonetheless, it does suggest that in order to minimize the error, it would be good to keep the new point \\(x\\) close to one of the interpolating points.\nA final note is in order. We used the Newton form to obtain this error bound, but the bound will apply to other polynomial forms since we know we have a unique polynomial, and the various forms we have used are merely disguised versions of each other.",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Interpolation Error</span>"
    ]
  },
  {
    "objectID": "InterpErr.html#sec-interperr",
    "href": "InterpErr.html#sec-interperr",
    "title": "17  Interpolation Error",
    "section": "",
    "text": "\\(f(x)\\) is defined on \\([a,b].\\)\n\\(f\\) has all needed derivatives and they are bounded.\n\n\n\n\n\n\n\n\n\n\n\n\nTheorem 17.1 \\[\nf[x_0, x_1, x_2, \\ldots, x_n, x] =\\frac{f^{n+1} (\\xi)}{(n+1)!} ,\n\\]\n\n\n\n\n\nTheorem 17.2 (Polynomial Interpolation Error) Let \\(n\\geq 0\\) and \\(f \\in C^{n} [a,b]\\). Suppose we are given \\(x_0, x_1, \\ldots, x_n\\) distinct points in \\([a,b]\\). Then\n\\[\n    f(x) - p_n(x) =  \\frac{f^{n+1} (\\xi)}{(n+1)!}\\Psi_n(x),\n     \\tag{17.1}\\]\nwith \\(\\Psi_n(x) = \\prod_{i=0}^{n}(x - x_i).\\), for \\(a \\leq x \\leq b\\), where \\(\\xi(x)\\) is an unknown between the min and max of \\(x_0, x_1, \\ldots, x_n\\) and \\(x\\).\nFurthermore\n\\[\n\\max |f(x) - p_n(x) | \\leq \\frac{1}{(n+1)!} \\max_{a \\leq t \\leq b} \\big | f^{(n+1)}(t)\\big | \\cdot \\max_{a \\leq s \\leq b} \\prod_{i=0}^{n} \\big | s - x_i\\big |\n\\]\n\n\n\n\nExample 17.1 To Do:\n\nInclude one example here for theorem, e.g. f(x) = exp(x)\nInclude one example here for previous theorem, e.g. f(x) = cos(x)",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Interpolation Error</span>"
    ]
  },
  {
    "objectID": "InterpErr.html#sec-interptips",
    "href": "InterpErr.html#sec-interptips",
    "title": "17  Interpolation Error",
    "section": "17.2 Practical Tips",
    "text": "17.2 Practical Tips\n\nIn understanding the error we might encounter when using interpolation, we can use Equation 17.1, to give us a sense of how the error behaves throughout the interval. Clearly, at the node points themselves, the error will be zero, but what about the rest of the points in \\([a,b]\\)?\nWhen considering the error bounds above, the interpolation error is likely to be smaller when evaluated at points close to the middle of the domain.\nIn practice, high degree polynomials with equally spaced nodes are not suitable for interpolation because of this oscillatory behavior.\nHowever, if a set of suitably chosen data points that are not equally spaced may be useful in obtaining polynomial approximations of some functions.\n\n\nExample 17.2 An excellent example of the type of behavior that can occur when using equally spaced nodes was described by Runge in 1901. Using the seemingly innocuous function: \\(f(x) = 1/(1+x^2), -5 \\leq x \\leq 5\\). If one uses equally spaced nodes, for example \\(x_i = \\frac{2i}{n} - 1\\) on the interval \\([-1,1],\\) then it can be shown that the interpolation error grows without bound at the ends of the interval.\n\n\n\n\nExample: Runge Function using equally spaced nodes\n\n\n\n\n\n\n\n\nHigh-Degree Polynomials\n\n\n\nIn general, one should be wary of using a high-degree polynomial as they can oscillate drastically and care must be taken whenever used. In general, other approaches will prove to be more useful in situations where more accuracy is required or more data points are given.",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Interpolation Error</span>"
    ]
  },
  {
    "objectID": "InterpErr.html#chebyshev-points",
    "href": "InterpErr.html#chebyshev-points",
    "title": "17  Interpolation Error",
    "section": "17.3 Chebyshev Points",
    "text": "17.3 Chebyshev Points\nThe Chebyshev points are defined on the interval \\([-1,1]\\) by: \\[\nx_i = \\cos\\Big ( \\frac{2i+ 1}{2(n+1)} {\\large \\pi} \\Big), \\quad i = 0, \\ldots n.\n\\tag{17.2}\\]\nTo generate the desired points for a general interval \\([a,b]\\), one then uses the affine transformation on Equation 17.2:\n\\[\n\\tilde{x_i} = a + \\frac{b-a}{2} ( x_i + 1), \\quad i=0, \\ldots n.\n\\tag{17.3}\\]\nThese new points have the feature that they are clustered near the end points of the interval rather than being uniformly spaced across the interval.\nIf one uses, for example, the Lagrange polynomial form with the Chebyshev points defined by Equation 17.3 then it can be shown that the interpolation error is greatly reduced.\n\n\n\n\n\n\nNote\n\n\n\nChebyshev points and interpolation have many interesting properties and many different applications. Unfortunately, we will not have time to go over most of these advanced topics.\n\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Interpolation Error</span>"
    ]
  },
  {
    "objectID": "InterpCubicSplines.html",
    "href": "InterpCubicSplines.html",
    "title": "18  Piecewise Polynomials and Cubic Splines",
    "section": "",
    "text": "18.1 Piecewise Polynomials",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Piecewise Polynomials and Cubic Splines</span>"
    ]
  },
  {
    "objectID": "InterpCubicSplines.html#sec-interppiecewisepoly",
    "href": "InterpCubicSplines.html#sec-interppiecewisepoly",
    "title": "18  Piecewise Polynomials and Cubic Splines",
    "section": "18.2 Piecewise Linears",
    "text": "Lecture 18: November 2, 2023\n\n\nMotivation\nSo far we’ve spent a lot of time discussing the good properties of polynomial interpolants. However, they also have several shortcomings. Among these, we list four here:\n\nThe error term may not be small. Theorem 17.2 showed that the error bound depended on both the size of the interval as well as the higher derivatives, which could be large.\nHigher order polynomials oscillate (wiggle) a lot. When fitting data that doesn’t have a lot of oscillations the polynomial will not match the data in certain areas of the interval (usually near the ends of the intervals).\nData are often only piecewise smooth, but polynomials are infinitely differentiable. Asking a polynomial to fit data that isn’t as smooth as itself may not be fair.\nChanging a single data point could drastically alter the entire interpolant\n\nAs we discussed in the practical tips section (Section 17.2), it is best to think of using 1) low-order polynomials, 2) within small intervals, 3) and only think of them as local approximations.\nThis leads us to think about using an alternative approach, which can be briefly described as:\n\n\n\n\n\n\nIdea\n\n\n\nInstead of finding one single polynomial to fit all the data find a set of polynomials for different regions within the given interval.\n\n\nIn more detail, this approach can be described as:\n\nDivide the interval \\([a,b]\\) into a set of smaller subintervals (elements)\\[ a = t_0 &lt; t_1 &lt; \\ldots &lt; t_r = b.\\] The \\(t_i\\) are often referred to as break points, or sometimes just knots.\nFit a low-degree polynomial \\(s_i(x)\\) in each of the subintervals \\([t_i,t_{i+1}],\\ \\  i=0, \\ldots r-1\\)\nPatch (glue) the polynomials together so that \\[v(x) = s_i(x), \\ \\ t_i \\leq x \\leq t_{i+1} \\ \\ i = 0, \\ldots r-1.\\]\n18.2 Piecewise Linears\n\n\nExample 18.1 Suppose we were given the following data points\n\n\n\n\\(x\\)\n1\n2\n4\n5\n6\n\n\n\\(y\\)\n1\n1.8\n2\n1.8\n0.5\n\n\n\nConsider using the Newton form for a linear polynomial within each of the sub-intervals.\n\\[\nv(x) = s_i(x) = f(x_i) + f[x_i, x_{i+1}] (x - x_i), \\\\\n\\quad t_i \\leq x \\leq t_{i+1}, \\quad 0 \\leq i \\leq 4.\n\\]\nHere note that for now, \\(t_i = x_i\\)\nFor example, for \\(i=0\\), we would have:\n\\[\n\\begin{aligned}\ns_0(x) &= f(x_0) + f[x_0, x_{1}] (x - x_0), \\\\\n&= 1 + \\frac{1.8 - 1}{2 -1} (x-1), \\\\\n&= 1 + 0.8 (x - 1).\n\\end{aligned}\n\\]\nLikewise, we would then compute \\(s_1, s_2, s_3, s_4.\\)",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Piecewise Polynomials and Cubic Splines</span>"
    ]
  },
  {
    "objectID": "InterpCubicSplines.html#error-bounds",
    "href": "InterpCubicSplines.html#error-bounds",
    "title": "18  Piecewise Polynomials and Cubic Splines",
    "section": "18.3 Error Bounds",
    "text": "18.3 Error Bounds\nIt turns out to be fairly easy to compute an error bound for this case (we’ve done most of the heavy lifting in the previous sections already).\nFirst let’s provide some notation to help us in this new situation.\nLet\n\\[\n\\begin{aligned}\nn &= r &\\mbox{number of subintervals} \\\\\nt_i &= x_i \\\\\nh &= \\max_{1 \\leq i \\leq n} (t_i - t_{i+1})  &\\mbox{maximum subinterval size}\n\\end{aligned}\n\\]\nClaim:\n\\[\n\\Big | f(x) - v(x) \\Big | \\leq   \\frac{h^2}{8} \\max_{a \\leq \\xi \\leq b} f^{\\prime\\prime} (\\xi),\n\\] for any \\(x \\in [a,b].\\)\nProof: First, let’s note that for any $x \\in [a,b], $ it must lie in some interval, say \\(i,\\) therefore \\(t_{i-1} \\leq x \\leq t_{i}.\\) We can now apply Equation 17.1, and since we are using linear interpolation, \\(n=1\\), the bound states that:\n\\[\nf(x) - v(x) =  \\frac{f^{\\prime\\prime} (\\xi)}{2!}(x - t_{i-1})(x-t_{i}).\n\\tag{18.1}\\]\nNext we note that the maximum of the quantity \\((x - t_{i-1})(x-t_{i})\\) occurs at the point\n\\[\nx = \\frac{t_{i-1} + t_i}{2}.\n\\]\n(We did this in class, so we won’t repeat it here).\nTherefore we can say that:\n\\[\n\\begin{aligned}\n\\Big | (x - t_{i-1})(x-t_{i}) \\Big | &\\leq \\Big | \\Big ( \\frac{t_{i} - t_{i-1}}{2} \\Big )^2\\Big |, \\\\\n& \\leq \\frac{h^2}{4}.\n\\end{aligned}\n\\]\nThe result now follows by substituting this back into Equation 18.1.",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Piecewise Polynomials and Cubic Splines</span>"
    ]
  },
  {
    "objectID": "InterpCubicSplines.html#piecewise-constants",
    "href": "InterpCubicSplines.html#piecewise-constants",
    "title": "18  Piecewise Polynomials and Cubic Splines",
    "section": "18.4 Piecewise Constants",
    "text": "18.4 Piecewise Constants\nBefore moving to higher order piecewise interpolation, it might be good to note that sometimes it is useful to consider piecewise constants. This approach could be used, for example in applications where the data is known to have discontinuities. One application we presented in class was that of modeling the subsurface of the earth in oil reservoir and geophysical exploration models.\n\n\n\n\n\n\n\n\nReservoir Model with different layers\n\n\n\n\n\n\n\nPiecewise constant data for layers\n\n\n\n\n\n\nFigure 18.1: Oil Reservoir Model with piecewise constant data",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Piecewise Polynomials and Cubic Splines</span>"
    ]
  },
  {
    "objectID": "InterpCubicSplines.html#cubic-splines",
    "href": "InterpCubicSplines.html#cubic-splines",
    "title": "18  Piecewise Polynomials and Cubic Splines",
    "section": "18.5 Cubic Splines",
    "text": "18.5 Cubic Splines\nPiecewise linear polynomials appear to be a good compromise but they do have one clear disadvantage – the final interpolant will likely have corners at the knots.\n\n\n\n\n\nWhat if we want to have a smoother interpolant? This could be quite important if we are trying to approximate a function that is known to have certain smoothness properties, or if we are modeling some physical or engineering problem that we wish to have smoothness, such as an airplane wing or a car body.\nThe most popular approach for creating a smooth piecewise interpolant is known as cubic splines.\n\n\n\nCubic Spline with 6 data points\n\n\nLet’s consider a cubic interpolant for the \\(ith\\) interval, which we can write as:\n\\[\nv(x) = s_i(x) = a_i + b_i (x-t_i)+ c_i (x-t_i)^2\n+ d_i (x-t_i)^3 .\\]\nNote that there are 4 unknowns \\(a_i, b_i, c_i, d_i\\) per sub-interval. Hence there are \\(4n\\) unknowns in total. That means if we want to have a unique solution, we need to also have \\(4n\\) equations (conditions) specified.\nThe usual approach is to generate these equations through a combination of:\n\ninterpolation conditions, and\ncontinuity conditions\n\nLet’s first note that in the linear case we had:\n\\[\n\\begin{aligned}\ns_i(t_i) &= f(t_i), & i = 0, 1, \\ldots, n-1, \\\\\ns_i(t_{i+1}) &= f(t_{i+1}), & i = 0, 1, \\ldots, n-1.\n\\end{aligned}\n\\tag{18.2}\\]\nThis gave us \\(2n\\) conditions for the \\(2n\\) unknowns. In addition, continuity was implied because\n\\[\ns_i(t_{i+1}) = f(t_{i+1}) = s_{i+1}(t_{i+1}).\n\\]\nWith cubic splines, we can use the interpolating conditions (Equation 18.2) to give us \\(2n\\) conditions. The question before us now is how to choose the additional \\(2n\\) conditions required to give us a unique solution.\n\n\n\n\n\n\nIdea\n\n\n\nUse remaining \\(2n\\) conditions so as to satisfy \\(v(x) \\in C^2[a,b].\\) In other words, ensure that the spline is twice-continuously differentiable, i.e.\n\n\\(s_i(x)\\) is continuous at the knots\n\\(s_i^\\prime(x)\\) is continuous at the knots\n\\(s_i^{\\prime\\prime}(x)\\) is continuous at the knots\n\n\n\nMathematically, this idea translates into:\n\\[\n\\begin{aligned}\ns_i(t_i) &= f(t_i), & i = 0, 1, \\ldots, n-1, & \\quad n \\ \\mbox{conditions}\\\\\ns_i(t_{i+1}) &= f(t_{i+1}), & i = 0, 1, \\ldots, n-1, & \\quad n \\ \\mbox{conditions}\\\\\ns_i^{\\prime}(t_{i+1}) &= s_{i+1}^{\\prime}(t_{i+1}), & i = 0, 1, \\ldots, n-2,& \\quad n-1 \\ \\mbox{conditions} \\\\\ns_i^{\\prime\\prime}(t_{i+1}) &= s_{i+1}^{\\prime\\prime}(t_{i+1}), & i = 0, 1, \\ldots, n-2, & \\quad n-1 \\ \\mbox{conditions}\\\\\n\\end{aligned}\n\\]\nIt is important to note that the last two conditions only hold at the internal knots since that is where two splines meet and need to be aligned to maintain continuity of the derivatives. Counting up the conditions therefore leaves us with only \\(4n-2\\) conditions.\nThere are two popular approaches to resolving this problem:\n\nFree boundary (natural spline):\\[v^{\\prime\\prime}(t_0) = v^{\\prime\\prime}(t_n) = 0\\]\nClamped boundary:\\[\\begin{aligned}\nv^{\\prime\\prime}(t_0) &= f^\\prime(t_0),\\\\\nv^{\\prime\\prime}(t_n) &= f^\\prime(t_n).\n\\end{aligned}\n\\]\n\nThe free boundary approach is the easiest to implement and apply. However, it is rather arbitrary and there is no a priori reason to expect it to be true.\nThe clamped boundary approach is more realistic, but has the disadvantage of requiring the second derivative of the function. If the second derivative is known (or can be approximated) however, this approach would be preferred.",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Piecewise Polynomials and Cubic Splines</span>"
    ]
  },
  {
    "objectID": "InterpCubicSplines.html#summary",
    "href": "InterpCubicSplines.html#summary",
    "title": "18  Piecewise Polynomials and Cubic Splines",
    "section": "18.6 Summary",
    "text": "18.6 Summary\nThis section covered the idea of using piecewise interpolating polynomials within subintervals of the domain as opposed to using one single polynomial over the entire domain. This approach has several advantages over using one polynomial including the ability to take into account more of the structure of the problem as well as producing smoother interpolants over the entire region.\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Interpolation and Approximation",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Piecewise Polynomials and Cubic Splines</span>"
    ]
  },
  {
    "objectID": "NumerDiff.html",
    "href": "NumerDiff.html",
    "title": "Numerical Differentiation",
    "section": "",
    "text": "Motivation - Why/When do we use numerical differentiation\n\nApproximating Derivatives in ODEs and PDEs\nComputing Derivatives from data (experimental or computed)\n\nGoals\n\nIntroduce formulas for computing derivatives numerically\nRichardson Extrapolation\nAnalyze errors when computing numerical derivatives\nUnderstand stability of numerical algorithms",
    "crumbs": [
      "Numerical Differentiation"
    ]
  },
  {
    "objectID": "FwdDiff.html",
    "href": "FwdDiff.html",
    "title": "19  Finite Differences",
    "section": "",
    "text": "19.1 Motivation\nComputing derivatives numerically arises in many situations in numerical analysis as well as scientific computing. Some of the most common examples include:\nThe basic tools used for numerical derivatives include one tool that we’ve been using extensively (Taylor series), and one more recently (polynomial interpolation).",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Finite Differences</span>"
    ]
  },
  {
    "objectID": "FwdDiff.html#sec-finitediff",
    "href": "FwdDiff.html#sec-finitediff",
    "title": "19  Finite Differences",
    "section": "",
    "text": "Numerically solving ordinary differential equations (ODEs), partial differential equations (PDEs), nonlinear equations and optimization (e.g. Newton’s method).\nComputing derivatives of complicated functions.\nSituations where f is not known explicitly or only as a black box.",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Finite Differences</span>"
    ]
  },
  {
    "objectID": "FwdDiff.html#taylor-series-approach",
    "href": "FwdDiff.html#taylor-series-approach",
    "title": "19  Finite Differences",
    "section": "19.2 Taylor Series Approach",
    "text": "19.2 Taylor Series Approach\nLet \\(f: R^{1} \\to R^{1}\\) with as many derivatives as we need.\nRecall the Taylor series expansion for a function \\[\nf(x+h) = f(x) + h f^{\\prime}(x) + \\frac{h^2}{2} f^{\\prime\\prime} (\\xi), \\qquad \\xi \\in[x, x+h]\n\\]\nRearranging we can write: \\[\nf^\\prime (x)  = \\frac{f(x+h) - f(x)}{h} - \\frac{h}{2} f^{\\prime\\prime} (\\xi)\n\\]\nThis leads to the forward difference approximation, which can be written as:\n\\[\nf^{\\prime} = \\frac{f(x+h) - f(x)}{h}\n\\] where we will denote the truncation error by \\[\n-\\frac{h}{2}f^{\\prime\\prime}(\\xi)\n\\]\nNotice that the truncation error can be expressed in Big O notation as \\(O(h)\\) and we therefore say that forward differences are an \\(O(h)\\) approximation or that it is first order accurate.\n\n\n\n\n\n\nTruncation Error is NOT Roundoff Error\n\n\n\nThe truncation error should not be confused with roundoff error!\n\n\nSimilarly the backward difference approximation can be written as \\[\nf^{\\prime} = \\frac{f(x) - f(x-h)}{h}\n\\]\nwith a similar error term. Clearly, backward differences are also first order accurate.\nWhich one should I use?\nThere is no major difference between the two; it mostly comes down to a matter of convenience or preference. There are however some situations, where it makes more sense to use one over the other. One recent example is when we had to impose a condition on the cubic spline interpolant and we needed to have the derivative of the first and last spline math the derivative of the function. In that case, we should use the forward difference approximation for the first spline and the backward difference approximation for the last spline.\n\n\n\n\n\n\nReview - Big O Notation\n\n\n\nRemember that we denote a quantity \\(x\\) as \\(O(h)\\) if it is at most proportional to \\(h\\), for example \\(Ch\\) for some constant \\(C\\). One way to think of it as\n\\[\n\\lim\\limits_{h \\to 0}\\frac{O(h)}{h} = C &lt; \\infty\n\\]\nNotice that according to our definition, both forward and backward difference formulas have truncation error that is \\(O(h)\\).\nQuestion:\n\nWhat is the order of \\[\n\\frac{h}{2} f^{\\prime\\prime}(x) + \\frac{h^2}{3} f^{\\prime\\prime\\prime}(x) ?\n\\]\nJust need to take a look at the lowest power of \\(h\\). If the power of \\(h\\) is 1, we say that it is first order. If the power of \\(h\\) is 2, we say that it is second order, and so on.\n\nAll other things being equal, we want as high a power of \\(h\\) for our error term as we can achieve!\n\n\n\nExample 19.1 Computation of forward difference for \\(\\exp(x), x=1\\)\n\n\n\nCode\nx &lt;- c(1, 1, 1, 1, 1, 1)\nh &lt;- c(.1, .05, .025, .0125, 0.00625, 0.003125)\nxph &lt;- x + h\nfx &lt;- exp(x)\nfxph &lt;- exp(xph)\nffwd &lt;- (fxph-fx)/h\nfprime &lt;- fx\nerr &lt;- abs(ffwd-fprime)\n\n\n\n\n\n\n\n\nh\nfprime\nF.D\nerr (F.D)\n\n\n\n\n0.100000\n2.718282\n2.858842\n0.1405601\n\n\n0.050000\n2.718282\n2.787386\n0.0691040\n\n\n0.025000\n2.718282\n2.752545\n0.0342635\n\n\n0.012500\n2.718282\n2.735342\n0.0170603\n\n\n0.006250\n2.718282\n2.726794\n0.0085124\n\n\n0.003125\n2.718282\n2.722534\n0.0042517\n\n\n\nForward Difference for exp(x), x = 1\n\n\nExercise 19.1 Compute the forward difference of \\(f(x) = tan(x), x = \\pi/4, h = 0.1, 0.05, 0.025, 0.125, 0.00625, 0.003125\\)\nSolution:\n\n\nCode\nlibrary(knitr)\nx &lt;- (pi/4)*c(1, 1, 1, 1, 1, 1)\nh &lt;- c(.1, .05, .025, .0125, 0.00625, 0.003125)\nxph &lt;- x + h\nxmh &lt;- x - h\nfx &lt;- tan(x)\nfxph &lt;- tan(xph)\nfxmh &lt;- tan(xmh)\nffwd &lt;- (fxph-fx)/h\nfbwd &lt;- (fx - fxmh)/h\nfprime &lt;- 1 / (cos(x)^2)\nerr1 &lt;- abs(fprime-ffwd)\nerr2 &lt;- abs(fprime-fbwd)\n\nex1data &lt;- data.frame(h, fprime, ffwd, fbwd, err1, err2)\nnames(ex1data) &lt;- c(\"h\", \"fprime\", \"F.D\", \"B.D\", \"err (F.D)\", \"err (B.D)\")\nkable(ex1data,caption = 'Forward Difference for tan(x), x = pi/4')\n\n\n\nForward/Backward Difference for tan(x), x = pi/4\n\n\nh\nfprime\nF.D\nB.D\nerr (F.D)\nerr (B.D)\n\n\n\n\n0.100000\n2\n2.230489\n1.823712\n0.2304888\n0.1762881\n\n\n0.050000\n2\n2.107112\n1.906275\n0.1071118\n0.0937249\n\n\n0.025000\n2\n2.051721\n1.951616\n0.0517205\n0.0483838\n\n\n0.012500\n2\n2.025423\n1.975410\n0.0254233\n0.0245897\n\n\n0.006250\n2\n2.012605\n1.987603\n0.0126050\n0.0123966\n\n\n0.003125\n2\n2.006276\n1.993776\n0.0062761\n0.0062241",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Finite Differences</span>"
    ]
  },
  {
    "objectID": "FwdDiff.html#central-differences",
    "href": "FwdDiff.html#central-differences",
    "title": "19  Finite Differences",
    "section": "19.3 Central Differences",
    "text": "19.3 Central Differences\nConsider the Taylor series at \\(x+h\\) and \\(x-h\\) \\[\n\\begin{aligned}\nf(x+h) &= f(x) + hf^\\prime(x) + \\frac{h^2}{2}f^{\\prime\\prime}(x) + \\frac{h^3}{6}f^{\\prime\\prime\\prime}(\\xi_1(x)) \\quad\\quad \\\\\nf(x-h) &= f(x) - hf^\\prime(x) + \\frac{h^2}{2}f^{\\prime\\prime}(x) - \\frac{h^3}{6}f^{\\prime\\prime\\prime}(\\xi_2(x))\n\\end{aligned}\n\\tag{19.1}\\] for some \\(\\xi_1 \\in [x, x+h], \\xi_2 \\in [x-h, x]\\).\nSubtracting the second equation from the first gives us: \\[\nf(x+h) - f(x-h) = 2h f^\\prime(x) + \\frac{h^3}{6}[f^{\\prime\\prime\\prime}(\\xi_1(x))+f^{\\prime\\prime\\prime}(\\xi_2(x))]\n\\]\nand solving for \\(f^{\\prime}\\) we get:\n\\[\nf^\\prime(x) = \\frac{f(x+h) - f(x-h)}{2h} - \\frac{h^2}{6}\\cdot \\frac{1}{2}[f^{\\prime\\prime\\prime}(\\xi_1(x))+f^{\\prime\\prime\\prime}(\\xi_2(x))]\n\\]\nThe last term that includes the third derivative at two different points can be replaced by using the Intermediate Value Theorem:\n\n\nIntermediate Value Theorem: Suppose that (i) f is continuous on the closed finite interval \\([a,b]\\) and (ii) \\(f(a) &lt; c &lt; f(b)\\). Then there exists some point \\(x \\in [a,b]\\) such that \\(f(x) = c\\).\nNotice that, since the average value must lie in between the value at the two end points a straightforward application of the IVT says: \\[\n\\frac{1}{2}[f^{\\prime\\prime\\prime}(\\xi_1(x))+f^{\\prime\\prime\\prime}(\\xi_2(x))] = f^{\\prime\\prime\\prime}(\\xi), \\quad \\xi \\in [x-h,x+h]\n\\]\nSubstituting for the \\(f^{\\prime\\prime\\prime}\\) terms yields: \\[\nf^\\prime(x) = \\frac{f(x+h) - f(x-h)}{2h} - \\frac{h^2}{6}f^{\\prime\\prime\\prime}(\\xi(x))\n\\tag{19.2}\\]\nEquation 19.2 is called the central (or centered) difference approximation.\n\nExample 19.2 Compare central vs. forward differences for \\(f(x) = \\tan(x), x=\\pi/4\\)\n\n\n\n\n\n\n\nh\nF.D\nerr (F.D)\nC.D\nerr (C.D.)\n\n\n\n\n0.100000\n2.230489\n0.2304888\n2.027100\n0.0271004\n\n\n0.050000\n2.107112\n0.1071118\n2.006693\n0.0066934\n\n\n0.025000\n2.051721\n0.0517205\n2.001668\n0.0016683\n\n\n0.012500\n2.025423\n0.0254233\n2.000417\n0.0004168\n\n\n0.006250\n2.012605\n0.0126050\n2.000104\n0.0001042\n\n\n0.003125\n2.006276\n0.0062761\n2.000026\n0.0000260\n\n\n\nForward v. Central Difference for tan(x), x = pi/4\n\n\n\n\n\n\n\nPractical Tip\n\n\n\nIt is not too difficult to generate other 3- and 5- point formulats using similar techniques. One must remember that we need to balance accuracy with the additional work needed and to be aware of any special conditions or structure available - for example the case of specifying derivative conditions for cubic splines at the end points, discussed earlier in this section.",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Finite Differences</span>"
    ]
  },
  {
    "objectID": "FwdDiff.html#second-derivative-formulas",
    "href": "FwdDiff.html#second-derivative-formulas",
    "title": "19  Finite Differences",
    "section": "19.4 Second Derivative Formulas",
    "text": "19.4 Second Derivative Formulas\nUsing similar techniques as for the centered difference formulas we can develop approximations for the second derivative of a function. Consider once again the Taylor series for a function about a point:\n\\[\n\\begin{aligned}\nf(x+h) &= f(x) + hf^\\prime(x) + \\frac{h^2}{2}f^{\\prime\\prime}(x) + \\frac{h^3}{6}f^{\\prime\\prime\\prime}(x) + \\frac{h^4}{24}f^{(4)}(\\xi_1(x)) \\quad\\quad \\\\\nf(x-h) &= f(x) - hf^\\prime(x) + \\frac{h^2}{2}f^{\\prime\\prime}(x) - \\frac{h^3}{6}f^{\\prime\\prime\\prime}(x) + \\frac{h^4}{24}f^{(4)}(\\xi_2(x))\n\\end{aligned}\n\\]\nHere, as we want to have a formula for the second derivative, our goal is to get rid of the other terms, and in particular the first derivative. Hence, let’s add the two equations:\n\\[\nf(x+h) + f(x-h) = 2f(x)  + h^2f^{\\prime\\prime}(x) + \\frac{h^4}{24} \\Big [ f^{(4)}(\\xi_1(x))+ f^{(4)}(\\xi_2(x)) \\Big ]\n\\]\nSolving for \\(f^{\\prime\\prime}\\) we get:\n\\[\nf^{\\prime\\prime}(x) = \\frac{f(x+h)-2f(x) + f(x-h)}{h^2}  - \\frac{h^4}{24} \\Big [ f^{(4)}(\\xi_1(x))+ f^{(4)}(\\xi_2(x)) \\Big ]\n\\]\nNow using the same trick we used before by appealing to the IVT, we have the following formula for numerically computing the second derivative.\n\\[\nf^{\\prime\\prime}(x) = \\frac{f(x+h)-2f(x) + f(x-h)}{h^2}  - \\frac{h^2}{12} f^{(4)}(\\xi).\n\\]\nAgain, this approximation is clearly \\(O(h^2)\\) and we say that it is a second order approximation.\n\nExample 19.3 Second Derivatives using finite differences\n\n\n\nCode\nx &lt;- c(1, 1, 1, 1, 1)\nh &lt;- c(.1, .05, .025, .0125, 0.00625)\nxph &lt;- x + h\nxmh &lt;- x -h\nfx &lt;- exp(x)\nfxph &lt;- exp(xph)\nfxmh &lt;- exp(xmh)\nf2prime &lt;- (fxph - 2*fx + fxmh)/ (h^2)\nfprimeExact &lt;- fx\nerr &lt;- abs(f2prime-fprimeExact)\n\n\n\n\n\nSecond Derivate for exp(x), x = 1\n\n\nh\nf(x)\nf2prime\nerr\n\n\n\n\n0.10000\n2.718282\n2.720548\n0.0022660\n\n\n0.05000\n2.718282\n2.718848\n0.0005664\n\n\n0.02500\n2.718282\n2.718423\n0.0001416\n\n\n0.01250\n2.718282\n2.718317\n0.0000354\n\n\n0.00625\n2.718282\n2.718291\n0.0000088\n\n\n\n\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Finite Differences</span>"
    ]
  },
  {
    "objectID": "HigherOrderFD.html",
    "href": "HigherOrderFD.html",
    "title": "20  Finite Differences via Lagrange Polynomials (Optional)",
    "section": "",
    "text": "20.1 ( \\(n+1\\) )-point Formulas\nGeneral Idea\nAnother approach for producing general finite difference formulas relies on using interpolating polynomials. The key idea is to first replace the function \\(f(x)\\) by a Lagrange interpolating polynomial. Then in place of the derivative of \\(f(x)\\) we will use the derivative of the Lagrange polynomial. Appropriate error estimates can also be produced.\nThe starting point for this strategy is the formula for the Lagrange interpolating polynomials.\nInterpolating polynomials\nLet \\([x_0, x_1, \\ldots, x_n]\\) be \\(n+1\\) distinct points on some interval \\([a,b]\\).\nThen we can approximate \\(f(x)\\) by\n\\[\nf(x) = \\sum_{k=0}^{n} f(x_k) L_k(x) + \\frac{(x-x_o)(x-x_1)\\cdots(x-x_n)}{(n+1)!} f^{(n+1)} (\\xi(x)),\n\\tag{20.1}\\]\nwhere \\(\\xi(x) \\in [a,b], L_k(x)\\) is the \\(kth\\) Lagrange coefficient polynomial, and is written as \\[\nL_k (x) = \\prod_{i=0, i \\neq k}^{n} \\frac{(x - x_i)}{(x_k - x_i)}\n\\]\nThe second step is to differentiate Equation 20.1. Letting \\(D_x\\) denote the derivative with respect to \\(x\\), we can rewrite Equation 20.1 as:\n\\[\n\\begin{aligned}\nf^{\\prime}(x) = & \\sum_{k=0}^{n} f(x_k) L^{\\prime}_k (x) \\ + \\\\\n& D_x \\left[ \\frac{(x-x_o)(x-x_1)\\cdots(x-x_n)}{(n+1)!} \\right] f^{(n+1)} ( \\xi(x)) \\ + \\\\\n& \\frac{(x-x_o)(x-x_1)\\cdots(x-x_n)}{(n+1)!} D_x [ f^{n+1)} ( \\xi(x)) ]\n\\end{aligned}\n\\tag{20.2}\\]\nLet’s first consider the last term in Equation 20.2. Suppose we take \\(x = x_j\\), where \\(x_j\\) is one of the given node points. With this choice, it is easy to see that the last term vanishes, i.e.:\n\\[\n\\frac{(x-x_o)(x-x_1)\\cdots(x-x_n)}{(n+1)!} D_x [ f^{n+1)} ( \\xi(x)) ] = 0\n\\] since for any \\(x = x_j\\), one of the product terms in the numerator will be equal to \\(0\\).\nThe second thing to note is that for \\(x = x_j\\) we can simplify the second term \\[\nD_x \\left[ \\frac{(x-x_o)(x-x_1)\\cdots(x-x_n)}{(n+1)!} \\right] = \\prod_{k=0,k \\neq j}^{n} (x_j - x_k)\n\\] The easiest way to see this is to note that the numerator is nothing but a product of linear terms. So using the chain rule we get a sum of terms each one of which has the original product terms minus the one corresponding to the one we take the derivative with respect to \\(x_k, k = 0, \\ldots n\\).\nSubstituting \\(x_j\\) for \\(x\\), all the summand terms go to zero except for the one where \\(k \\neq j\\).\nTogether this means we can simplify Equation 20.2 to: \\[\nf^{\\prime}(x_j) = \\sum_{k=0}^{n} f(x_k) L^{\\prime}_k (x_j) + \\frac{f^{(n+1)} ( \\xi(x_j))}{(n+1)!} \\prod_{k=0,k \\neq j}^{n} (x_{j} - x_k)\n\\tag{20.3}\\]\nWe call this is the \\((n+1)\\)-point formula (Equation 4.2, p. 176, textbook).\nRemark: In general, more points leads to higher accuracy, but at the expense of more function evaluations. The extra computations will likely lead to more roundoff error as well.",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Finite Differences via Lagrange Polynomials (Optional)</span>"
    ]
  },
  {
    "objectID": "HigherOrderFD.html#sec-fdlagrpoly",
    "href": "HigherOrderFD.html#sec-fdlagrpoly",
    "title": "20  Finite Differences via Lagrange Polynomials (Optional)",
    "section": "",
    "text": "See Theorem 3.3, p. 112, textbook\n\n\n\n\nSee Equation 3.2, p. 110, textbook\n\n\n\nExcept for special cases we cannot estimate the truncation error as Equation 20.2 is currently written.",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Finite Differences via Lagrange Polynomials (Optional)</span>"
    ]
  },
  {
    "objectID": "HigherOrderFD.html#three-point-formulas",
    "href": "HigherOrderFD.html#three-point-formulas",
    "title": "20  Finite Differences via Lagrange Polynomials (Optional)",
    "section": "20.2 Three-Point Formulas",
    "text": "20.2 Three-Point Formulas\nThe most common versions are the 3-point and 5-point formulas. Let’s consider the specific case \\(n=2\\) (i.e. the 3-point case) applied to Equation 20.3\n\\[\n\\begin{aligned}\nf^{\\prime}(x_j) = & f(x_0) L^{\\prime}_0 (x_j) + f(x_1) L^{\\prime}_1 (x_j) + f(x_2) L^{\\prime}_2 (x_j) + \\\\\n& \\frac{f^{(3)} ( \\xi(x_j))}{6} \\prod_{k=0,k \\neq j}^{2} (x_{j} - x_k)\n\\end{aligned}\n\\tag{20.4}\\]\nConsider \\(L_0(x)\\), which can be written as:\n\\[\nL_0(x) = \\frac{(x - x_1)(x - x_2)}{(x_0 - x_1)(x_0 - x_2)}\n\\] Taking the derivative with respect to \\(x\\) yields \\[\nL^{\\prime}_0(x) = \\frac{(2x - x_1 - x_2)}{(x_0 - x_1)(x_0 - x_2)}\n\\tag{20.5}\\]\nLikewise for \\(L_1^\\prime\\) and \\(L_2^\\prime\\) we can write: \\[\nL^{\\prime}_1(x) = \\frac{(2x - x_0 - x_2)}{(x_1 - x_0)(x_1 - x_2)}, \\qquad L^{\\prime}_2(x) = \\frac{(2x - x_0 - x_1)}{(x_2 - x_0)(x_2 - x_1)}\n\\tag{20.6}\\]\nLet’s try to simplify matters a bit.\nTo start with, let’s assume equally spaced points \\([x_0, x_1, x_2]\\), i.e. \\([x_0, x_0+h, x_0 +2h]\\). Since we can choose \\(x_j\\) to be any of the node points let’s arbitrarily choose \\(x_j = x_0\\).\nThis means several of the terms in the Lagrange polynomial can be further simplied, in particular notice that: \\[\nx_1 - x_0 = x_2 - x_1 = h \\quad \\mbox{and} \\quad x_2 - x_0 = 2h\n\\]\nSubstituting this into the formulas for the derivatives of the Lagrange polynomials (Equation 20.5, Equation 20.6) means we can write those terms as:\n\\[\nL^{\\prime}_0(x_0) = \\frac{(2x_0 - x_1 - x_2)}{2h^2}, \\quad\nL^{\\prime}_1(x_0) = \\frac{(2x_0 - x_0 - x_2)}{-h^2}, \\quad L^{\\prime}_2(x_0) = \\frac{(2x_0 - x_0 - x_1)}{2h^2}\n\\]\nNow all we need to do is gather all the terms together and substitute them into Equation 20.4.\n\\[\n\\begin{aligned}\nf^{\\prime}(x_0) = & f(x_0) \\left[\\frac{(2x_0 - x_1 - x_2)}{2h^2} \\right] + \\\\\n& f(x_1) \\left[\\frac{(2x_0 - x_0 - x_2)}{-h^2} \\right] + \\\\\n& f(x_2) \\left[\\frac{(2x_0 - x_0 - x_1)}{2h^2} \\right] + \\\\\n& \\frac{f^{(3)} ( \\xi(x_j))}{6} 2h^2\n\\end{aligned}\n\\]\nHere we are also using the fact that: \\[\n\\prod_{k=0,k \\neq j}^{2} (x_{j} - x_k) = (x_0 - x_1)(x_0-x_2) = 2h^2\n\\]\nNow note that due to the equal spacing of the nodes the coefficient terms of \\(f(x_i), i=0,1,2\\) can also be simplified. For example, for the \\(f(x_0)\\) term we see that: \\[\n\\begin{aligned}\n2x_0 - x_1 - x_2 &= 2x_0 - (x_0+h) - (x_0+2h) \\\\\n&= 2x_0 - x_0 - h - x_0 - 2h \\\\\n&= -3h\n\\end{aligned}\n\\]\nA similar algebra exercise reduces the terms multiplying \\(f(x_1)\\) and \\(f(x_2)\\), resulting in: \\[\n2x_0 - x_0 - x_2 = -2h; \\quad 2x_0 - x_0 - x_1 = -h\n\\] Substituting and gathering like terms yields: \\[\nf^{\\prime}(x_0) = \\frac{1}{h} \\left[ \\frac{-3}{2} f(x_0) + 2 f(x_1) -  \\frac{1}{2} f(x_2) \\right] + \\frac{h^2}{3} f^{(3)} (\\xi_{0})\n\\]\nThis leads directly to the 3-point endpoint finite difference approximation\n\n\nEquation 4.4, p. 177, textbook\n\\[\nf^{\\prime} (x) = \\frac{-3f(x) + 4f(x+h) - f(x+2h)}{2h} + \\frac{h^2}{3} f^{(3)}(\\xi)\n\\tag{20.7}\\]\nUsing a similar set of arguments, we can derive the 3-point midpoint finite difference formula\n\n\nEquation 4.5, p. 177, textbook\n\\[\nf^{\\prime} (x) = \\frac{f(x + h) - f(x-h)}{2h} - \\frac{h^2}{6} f^{(3)}(\\xi)\n\\tag{20.8}\\]\nRemark: While the 3-point endpoint and midpoint formulas are both \\(O(h^2)\\), the endpoint formula requires an additional function evaluation over the midpoint formula. Also note that the mid-point formula is sometimes called the central difference formula.\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Finite Differences via Lagrange Polynomials (Optional)</span>"
    ]
  },
  {
    "objectID": "FDStability.html",
    "href": "FDStability.html",
    "title": "21  Richardson Extrapolation and Finite Difference Stability",
    "section": "",
    "text": "21.1 Richardson Extrapolation\nThe methods we’ve studied so far for computing numerical derivatives are good and generally lead to good approximations. But what if we need to have greater accuracy? This section covers one approach to generating higher-order (more accurate) approximations to derivatives using an idea dating back to 1927. In spirit, it is not unlike what we did when we derived the central difference approximation by noticing that if we took the two \\(O(h)\\) approximations for the forward and backward difference and combined them in such a way as to cancel out one of the error terms we could get a higher-order approximation \\(O(h^2)\\).\nLet’s consider how we arrived at the 3-point formula for the second derivative:\n\\[\nf^{\\prime\\prime}(x) = \\frac{f(x+h)-2f(x) + f(x-h)}{h^2}  - \\frac{h^2}{12} f^{(4)}(\\xi).\n\\] In that derivation we started with the Taylor series about \\(x+h\\) and \\(x-h.\\) This time let’s also consider one additional term, which would give us:\n\\[\nf^{\\prime\\prime}(x) = \\frac{f(x+h)-2f(x) + f(x-h)}{h^2}  - \\frac{h^2}{12} f^{(4)}(x) - \\frac{h^4}{360} f^{(6)}(\\xi) + O(h^5).\n\\tag{21.1}\\] Now replace \\(h\\) by \\(2h\\).\n\\[\nf^{\\prime\\prime}(x) = \\frac{f(x+2h)-2f(x) + f(x-2h)}{4h^2}  - \\frac{4h^2}{12} f^{(4)}(x) - \\frac{16h^4}{360} f^{(6)}(\\xi) + O(h^5).\n\\tag{21.2}\\] Notice that the second formula has the same term for the fourth derivative except it is multiplied by 4. This leads to the natural idea of multiplying the first equation by 4 and subtracting the second equation from it, which will cancel that part of the error term. If we do this, we will (after a bit of simple algebra) get to the following formula:\n\\[\nf^{\\prime\\prime}(x) = \\frac{\\big [-f(x+2h) + 16f(x+h) - 30f(x) + 16f(x-h) - f(x-2h) \\big ]}{12h^2}  + \\frac{h^4}{90} f^{(6)}(x) + O(h^5).\n\\] This formula for the second derivative is now fourth order accurate.\nIf we take another approach, it will help us generalize for future applications.\nFirst, let’s define some terms to simplify the derivation. Let:\n\\[\n\\begin{aligned}\nM &= f^{\\prime\\prime}(x) \\\\\nN(h) &= \\frac{f(x+h)-2f(x) + f(x-h)}{h^2}\n\\end{aligned}\n\\] Using these we can write Equation 21.1 and Equation 21.2 as:\n\\[\n\\begin{aligned}\nM &= N(h) - \\frac{h^2}{12} f^{(4)}(x) - \\frac{h^4}{360} f^{(6)}(\\xi) + O(h^5). \\\\\nM &= N(h/2) - \\frac{4h^2}{12} f^{(4)}(x) - \\frac{16h^4}{360} f^{(6)}(\\xi) + O(h^5).\n\\end{aligned}\n\\]\nAs before, let’s multiply the first equation by 4 and subtract the first:\n\\[\n\\begin{aligned}\n4M &= 4N(h) - \\frac{4h^2}{12} f^{(4)}(x) - \\frac{4h^4}{360} f^{(6)}(\\xi) + O(h^5) \\\\\nM &= N(h/2) - \\frac{4h^2}{12} f^{(4)}(x) - \\frac{16h^4}{360} f^{(6)}(\\xi) + O(h^5)\\\\\n\\hline\n3M &= 4N(h) - N(h/2) + \\frac{12h^4}{360}f^{(6)}(\\xi) + O(h^5)\n\\end{aligned}\n\\]\nSolving for \\(M\\), leads to:\n\\[\nM = \\frac{1}{3} \\big [ 4N(h) - N(h/2) \\big ] + \\frac{h^4}{90}f^{(6)}(\\xi)  + O(h^5)\n\\]\nOne final adjustment is usually made - we will split \\(4N(h) = 3N(h) + N(h)\\) to give us the final form of the formula that is commonly used.\n\\[\nM = N(h) - \\frac{1}{3} \\big [N(h) - N(h/2) \\big ] + O(h^4).\n\\]\nThe procedure to obtain a fourth order accurate approximation using the two second order formulas is then easily accomplished through the following procedure:\nThere are advantages and disadvantages to Richardson extrapolation as for all numerical methods.\nOn the plus side, it is simple and general so we can apply the technique to many different problems. You will find applications in interpolation, numerical integration, and even differential equations. A great survey paper that describes many of these and others is\nIt also leads to formulas for higher-order approximations for derivatives, which are useful in certain applications. On the other hand, the technique requires more points at which to evaluate the function and it makes an assumption that the higher-order derivatives are nicely bounded, which may or may not hold true.",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Richardson Extrapolation and Finite Difference Stability</span>"
    ]
  },
  {
    "objectID": "FDStability.html#richardson-extrapolation",
    "href": "FDStability.html#richardson-extrapolation",
    "title": "21  Richardson Extrapolation and Finite Difference Stability",
    "section": "",
    "text": "Idea\n\n\n\nCombine 2 approximations with similar error terms to obtain a more accurate approximation. Can be used in many different contexts including interpolation (Aitken), quadrature (Romberg, adaptive methods), IVP, and even to accelerate convergence of sequences.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncompute \\(N(h)\\), for some given \\(h\\)\ncompute \\(N(h/2)\\)\nCombine the two using the formula \\(M = N(h) - \\frac{1}{3} \\big [N(h) - N(h/2) \\big ]\\)\n\n\n\n\n\n\n\nRemark\n\n\n\nNotice that using this approach wasn’t specific to the second derivative formula. All we needed was an approximation to some quantity where we knew the error term. Therefore we could use this same approach anytime we can write an approximation as:\n\\[\nM = N(h) + K_1h + K_2h^2 + K_3h^3 + \\ldots.\n\\]\nThe trick is then to find the right combination to cancel out the leading error term, when evaluating the equation at two different points, e.g. \\(h\\) and \\(h/2\\).",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Richardson Extrapolation and Finite Difference Stability</span>"
    ]
  },
  {
    "objectID": "FDStability.html#stability",
    "href": "FDStability.html#stability",
    "title": "21  Richardson Extrapolation and Finite Difference Stability",
    "section": "21.2 Stability",
    "text": "21.2 Stability\nSometimes an algorithm will fail to yield a good result due to stability. Computing derivatives by using finite differences is a prime example of such a possibility. This is due to the properties of computer arithmetic. In practice there is a delicate balance between truncation error and roundoff error. As a result one needs to be careful when choosing the step size, \\(h\\).\nWe briefly looked at an example in Section 3.1 where we looked at the accuracy of the forward difference approximation as a function of \\(h\\). Let’s look at a similar example, but this time using both forward and central differences.\n\nExample 21.1 Let’s take \\(f(x) = \\cos(x)\\) and \\(h = 10^{-3} - 10^{-15}, x = \\pi/6\\)\n\nLet’s try to analyze what is happening there.\nConsider the central difference formula for \\(f^{\\prime}(x)\\) at some point \\(x_0\\). \\[\nf^{\\prime} (x_{0} ) = \\frac{f(x_{0}+h) - f(x_{0}-h)}{2h} - \\frac{h^2}{6}f^{(3)}(\\xi(x))\n\\]\nWhen evaluating a function on a computer, we know that we do not have infinite precision, hence suppose: \\[\n\\begin{aligned}\nf(x_{0}+h) &= \\hat{f}(x_{0}+h) + e(x_{0}+h) \\\\\nf(x_{0}-h) &= \\hat{f}(x_{0}-h) + e(x_{0}-h)\n\\end{aligned}\n\\] where \\(e(x)\\) is the roundoff error as a result of computing \\(f(x)\\) and \\(\\hat{f}(x)\\) is the computed value of the function.\nThe error in the finite difference approximation can then be written as: \\[\nf^{\\prime} (x_{0} ) - \\left ( \\frac{f(x_{0}+h) - f(x_{0}-h)}{2h} \\right ) =  \\frac{e(x_{0}+h)- e(x_{0}-h)}{2h} - \\frac{h^2}{6}f^{(3)}(\\xi(x))\n\\]\nNow assume that: \\[\n\\begin{aligned}\ne(x_0 \\pm h) &&lt; \\tau, \\quad \\tau &gt; 0,\\\\\nf^{(3)}(\\xi) &&lt; M \\quad \\xi \\in [x_{0}-h, x_{0}+h].\n\\end{aligned}\n\\]\nThe error in the finite difference approximation can be bounded by \\[\n\\left | \\frac{\\tau}{h} + \\frac{h^2}{6}M \\right |\n\\]\nRemark: As \\(h \\rightarrow 0\\) the second term goes to 0, but the first term blows up.\nWe need to find the “sweet spot” to minimize the error in the approximation.\nCan show that the optimal \\(h^*\\) is given by: \\[\nh^{*} = \\sqrt[3] {\\frac{3 \\tau}{M}}\n\\] Unfortunately, one rarely knows either \\(\\epsilon\\) or \\(M\\).\nHowever a good rule of thumb is to choose \\(h\\) so that you only perturb half the digits of \\(x\\). That suggests \\[\nh^{*} = \\sqrt \\epsilon\n\\] where \\(\\epsilon\\) is called machine precision. On most modern computers \\(\\epsilon = 10^{-16}\\), so this translates into\n\\[\nh \\approx 10^{-8}\n\\]\n\n\n\n\n\n\nCaution\n\n\n\nFinite Difference approximations are an example of unstable algorithms.",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Richardson Extrapolation and Finite Difference Stability</span>"
    ]
  },
  {
    "objectID": "FDStability.html#summary",
    "href": "FDStability.html#summary",
    "title": "21  Richardson Extrapolation and Finite Difference Stability",
    "section": "21.3 Summary",
    "text": "21.3 Summary\nSome of the key takeaways\n\nTaylor series can be used to generate finite difference approximations to first derivatives, second derivatives, etc.\nWe can also use Lagrange polynomials to generate similar formulas. (covered in book as well as in the optional lecture in Section 20.1).\nRichardson extrapolation is a simple and general approach that combines lower-order formulas to generate higher-order approximations (at additional function evaluation costs).\nNumerical differentiation is inherently unstable - but it’s also (essentially) the only game in town. Care must be taken in choosing good step sizes.\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Numerical Differentiation",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Richardson Extrapolation and Finite Difference Stability</span>"
    ]
  },
  {
    "objectID": "NumerIntegr.html",
    "href": "NumerIntegr.html",
    "title": "Numerical Integration (Quadrature)",
    "section": "",
    "text": "Introduction\nThis section covers methods for numerically evaluating definite integrals of the form \\[\nI(f) = \\int_a^b f(x) dx,\n\\]where we do not have an explicit antiderivative or the antiderivative might not be easy to find or obtain. Numerical integration arises in numerous science and engineering (S&E) applications. These methods are most useful when the function doesn’t have explicit antiderivative or doesn’t have a closed form solution.\nFor example, think about\n\\[\n\\int_0^{\\pi} x^{\\pi} sin(\\sqrt(x)) dx,\n\\]\nor\n\\[\n\\int_{-1}^{1} \\exp(x) T_2(x) dx, \\quad \\ T_2 \\ \\mbox{is a Chebyshev polynomial} .\n\\]\nIn many real-world problems the integrals are in one, two or three dimensions. Here we will assume that our functions are scalar, that is \\(f: R^{1} \\to R^{1}\\) and with as many derivatives as we need.\nWe will note in passing, that there are many important cases for which the dimension of the problem can be quite large. These situations require special methods and we will not be covering them here, but see the references for further information.\nOther special cases involve integrals where one or both of the limits aren’t definite, which is to say that either \\(a\\) or \\(b\\) could be infinite. These cases can sometimes be handled with the methods we will discuss here, but one should be careful when approaching the solution to these types of problems.\nFinally, some functions are highly oscillatory. Again special care must be taken when trying to solve these types of problems. Here we will only point to several references that discuss these types of problems.",
    "crumbs": [
      "Numerical Integration (Quadrature)"
    ]
  },
  {
    "objectID": "NumerIntegr.html#introduction",
    "href": "NumerIntegr.html#introduction",
    "title": "Numerical Integration (Quadrature)",
    "section": "",
    "text": "Practical Applications\n\nStatistics - probability distribution, stochastic equations, Bayesian statistics, etc.\nIntegral transforms - uses in differential equations, signal processing, Fourier analysis, etc.\nFinite element methods - pdes\nBoundary Integral methods for solving pdes\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Numerical Integration (Quadrature)"
    ]
  },
  {
    "objectID": "NumIntBasics.html",
    "href": "NumIntBasics.html",
    "title": "22  Numerical Integration Basics",
    "section": "",
    "text": "22.1 Introduction\nLet’s start with a bit of background. What is the first thing you think of when you see:\n\\[\n\\int_a^b f(x) dx\n\\tag{22.1}\\]\nIf you said, the area under the curve, you’re right! This leads us to the general strategy:\nApproximate \\[\nI(f) = \\int_a^b f(x) dx \\approx \\sum_{i=0}^{n} a_i f(x_i)\n\\] for some yet to be determined coefficients \\(a_i\\).\nWe will call this numerical quadrature.\nTo do this we will follow the same strategy we used for numerical differentiation, i.e. we will replace the function whose integral we seek with one whose integral can be more easily evaluated – an interpolating polynomial.\nBefore we start, let’s first develop some intuition on what we’re doing. Consider Figure 22.1 in which we’ve plotted a generic function. A natural idea is to use the well-known trapezoidal rule to approximate the area under the curve.\nFigure 22.1: Trapezoidal Rule.\nIf we do this, it would make sense to approximate the integral as: \\[\n\\int_1^3 f(x)dx \\approx \\frac{h}{2} [ f(x_0) + f(x_1)], \\ x_0=1, x_1=3,\n\\]\nwhere \\(h\\) is defined as the interval width, i.e. \\(h = b-a = 3-1\\). Notice also, that in Figure 22.1 all that we did was to approximate the function by using a linear approximation using the two endpoints. It is natural to conjecture for what type of functions would the trapezoidal rule be exact for? Can you guess?",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Numerical Integration Basics</span>"
    ]
  },
  {
    "objectID": "NumIntBasics.html#sec-basics-integration",
    "href": "NumIntBasics.html#sec-basics-integration",
    "title": "22  Numerical Integration Basics",
    "section": "",
    "text": "Approach\n\n\n\nOur overall goal is to approximate the integral Equation 22.1 by computing \\(\\sum_{i=0}^{n} a_i f(x_i)\\) through the following 3 steps:\n\nWrite \\(f(x)\\) as an interpolating polynomial\nIntegrate the polynomial\nUnderstand/analyze the truncation error\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\nIn order to get a more accurate approximation, we could subdivide the total region into smaller trapezoids and sum over all of them. All of this is by way of developing some intuition on what we should do. To make this more rigorous we will need to develop our framework and compute error estimates for our approximations. We will return to this idea in Section 24.1 on Composite Integration",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Numerical Integration Basics</span>"
    ]
  },
  {
    "objectID": "NumIntBasics.html#interpolating-polynomials",
    "href": "NumIntBasics.html#interpolating-polynomials",
    "title": "22  Numerical Integration Basics",
    "section": "22.2 Interpolating Polynomials",
    "text": "22.2 Interpolating Polynomials\nStep 1. Write down our function as a Lagrange interpolating polynomial along with its truncation error.\nLet \\[\nf(x) = \\sum_{i=0}^{n} f(x_i) L_i(x) + \\prod_{i=0}^{n} (x - x_i)\\frac{f^{(n+1)} (\\xi(x))}{(n+1)!}.\n\\tag{22.2}\\]\nFor convenience, let’s denote\n\\[\n\\Psi_n(x) = \\prod_{i=0}^{n} (x - x_i).\n\\]\nWe can then write Equation 22.2 as:\n\\[\nf(x) = \\sum_{i=0}^{n} f(x_i) L_i(x) + \\Psi_n(x)\\ \\frac{f^{(n+1)} (\\xi(x))}{(n+1)!}.\n\\]\nStep 2. Integrate the interpolating polynomial:\n\\[\n\\int_a^b f(x) = \\int_a^b \\sum_{i=0}^{n} f(x_i) L_i(x) + \\int_a^b \\Psi_n(x)\\ \\frac{f^{(n+1)} (\\xi(x))}{(n+1)!}.\n\\]\nNotice we can move the integral under the sum for the first term. Now (again for convenience) let’s denote\n\\[\nc_i = \\int_a^b L_i(x) dx, \\ i=0, \\ldots, n.\n\\tag{22.3}\\]\nRearranging we get:\n\\[\n\\int_a^b f(x) = \\sum_{i=0}^{n} c_i f(x_i) + E(f),\n\\]\nwhere we denote the truncation error \\(E(f)\\) by:\n\\[\nE(f) = \\frac{1}{(n+1)!}\\int_a^b \\Psi_n(x)\\ f^{(n+1)} (\\xi(x)) dx.\n\\tag{22.4}\\]\nNotice we are partway to our goal of having written down the integral in the form we wanted:\n\\[\nI(f) = \\int_a^b f(x) dx \\approx \\sum_{i=0}^{n} a_i f(x_i).\n\\]\n\n\n\n\n\n\nRemark\n\n\n\nThe \\(a_i\\) and \\(c_i\\) (Equation 22.3) are not the same, but they are related in some yet to be determined way!\nWe’re now left with only two steps:\n\nCompute \\(c_i\\) for a specific interpolating polynomial, and\nUnderstand/analyze the error function \\(E(f)\\)\n\n\n\nSpecific Case: \\(n=1\\) (Linear Interpolating Polynomial)\nLet’s take the easiest case, \\(n=1\\), a linear Lagrange interpolating polynomial. To be consistent with our earlier notation we’ll also let \\(a = x_0\\) and \\(b = x_n = x_1\\) for this case.\nRecall, the first degree Lagrange polynomial takes the form:\n\\[\nP_1(x) = \\frac{(x - x_1)}{x_0 - x_1} f(x_0) + \\frac{(x - x_0)}{x_1 - x_0} f(x_1),\n\\tag{22.5}\\]\nand the truncation error Equation 22.4 reduces to\n\\[\nE(f) = \\frac{1}{2} \\int_{x_0}^{x_1}(x - x_0)(x - x_1) f^{\\prime\\prime}(\\xi(x)) dx.\n\\tag{22.6}\\]\nLet’s consider the truncation error first.\nIt would be nice if we could take \\(f^{\\prime\\prime}(\\xi(x))\\) term outside the integral to simplify the integral. Let’s first define \\(g(x) =(x - x_0)(x - x_1)\\), and notice that \\(g(x)\\) doesn’t change sign on \\([x_0,x_1]\\).\nThat means we can apply the Weighted Mean Value Theorem (WMVT) for integrals and pull the \\(f^{\\prime\\prime}(\\xi(x))\\) term outside of the integral.\n\n\nWeighted Mean Value Theorem for Integrals (): Suppose that \\(f \\in C[a,b]\\), the Riemann integral of \\(g\\) exists on \\([a,b]\\), and \\(g(x)\\) does not change sign on \\([a,b]\\). Then there exists a number \\(c \\in (a,b)\\) such that \\[\n\\int_a^b f(x) g(x) dx = f(c) \\int_a^b g(x) dx\n\\]\nThat simplifies \\(E(f)\\) so that\n\\[\nE(f) = \\frac{1}{2} f^{\\prime\\prime}(\\xi) \\int_{x_0}^{x_1}(x - x_0)(x - x_1)  dx,\n\\]\nfor some \\(\\xi \\in [x_0, x_1]\\).\nThat just leaves us with integrating the quadratic inside the integral, which reduces to:\n\\[\nE(f) = \\frac{1}{2} f^{\\prime\\prime}(\\xi) \\left[ \\frac{x^3}{3} - \\frac{(x_1 + x_0)}{2}x^2 + x_0x_1x \\right]_{x_0}^{x_1}.\n\\tag{22.7}\\]\nTo simplify the calculations, let’s first do a change of variable, \\(x^\\prime = x - x_0.\\) Also recall that \\(x_1 = x_0 + h\\). As a result, the limits reduce to \\(x_0 \\rightarrow 0, x_1 \\rightarrow h\\), and as a result, the term in brackets in Equation 22.7 evaluates to:\n\\[\n\\left[ \\frac{h^3}{3} - \\frac{(h) h^2}{2} + 0 \\right] = \\frac{-h^3}{6}.\n\\]\nThat simplifies \\(E(f)\\) to\n\\[\nE(f) =  - \\frac{h^3 f^{\\prime\\prime}(\\xi)}{12}.\n\\tag{22.8}\\]\nThat takes care of Step 3 - Understand/Analyze the Truncation Error \\(E(f)\\)!\nTo reach our final goal, we just need to complete the second step we need to compute the integrals of Equation 22.5, i.e.\n\\[\n\\begin{aligned}\n\\int_{x_0}^{x_1} P_1(x) &= \\int_{x_0}^{x_1} \\frac{(x - x_1)}{x_0 - x_1} f(x_0) + \\frac{(x - x_0)}{x_1 - x_0} f(x_1), \\\\\n&= \\left[ \\frac{(x - x_1)^2}{2(x_0 - x_1)} f(x_0) + \\frac{(x - x_0)^2}{2(x_1 - x_0)} f(x_1) \\right]_{x_0}^{x_1}.\n\\end{aligned}\n\\]\nNotice that for the upper value \\(x_1\\) the first term in the sum drops out, and likewise for the lower value \\(x_0\\) the second term drops out, leaving only 2 terms.\nEvaluating these two terms we get:\n\\[\n\\begin{aligned}\n\\int_{x_0}^{x_1} P_1(x) &= \\left[ \\frac{(x_1 - x_0)^2}{2(x_1 - x_0)} f(x_1) - \\frac{(x_0 - x_1)^2}{2(x_0 - x_1)} f(x_0) \\right], \\\\\n&= \\left[ \\frac{(x_1 - x_0)}{2} f(x_1) - \\frac{(x_0 - x_1)}{2} f(x_0) \\right], \\\\\n&= \\left[ \\frac{(x_1 - x_0)}{2} f(x_1) + \\frac{(x_1 - x_0)}{2} f(x_0) \\right], \\\\\n&= \\left( \\frac{x_1 - x_0}{2} \\right) \\left[ f(x_1) + f(x_0) \\right], \\\\\n&= \\frac{h}{2} \\left[ f(x_1) + f(x_0) \\right],\n\\end{aligned}\n\\] where the last line is due to the fact that \\(x_1 = x_0 + h\\).\nPulling everything together leads us to our desired result:\n\n\n\n\n\n\nTrapezoidal Rule\n\n\n\n\\[\n\\int_a^b f(x) dx = \\frac{h}{2} \\left[ f(x_0) + f(x_1) \\right] - \\frac{h^3}{12} f^{\\prime\\prime}(\\xi),\n\\]\nTrapezoidal Rule exact for polynomials of degree \\(\\leq\\) 1.\nSince the truncation error is given by \\(\\frac{h^3}{12}f^{\\prime\\prime}(\\xi)\\) we expect that for any function whose second derivative is identical to zero that the Trapezoidal Rule will be exact, and in particular for any polynomial of degree 1 or less.",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Numerical Integration Basics</span>"
    ]
  },
  {
    "objectID": "NumIntBasics.html#simpsons-rule",
    "href": "NumIntBasics.html#simpsons-rule",
    "title": "22  Numerical Integration Basics",
    "section": "22.3 Simpson’s Rule",
    "text": "22.3 Simpson’s Rule\n\n\n\n\n\n\nOptional\n\n\n\nThe derivation for Simpson’s Rule follows the one for the Trapezoidal Rule, with some minor modifications. The following is included for completeness (and for practice), but you may also want to skip down to the final formula (Equation 22.13) and discussion of the major properties of Simpson’s Rule.\n\n\nIn a similar fashion to our approach for deriving the Trapezoid Rule, if we integrate the second-degree Lagrange polynomial, we can derive Simpson’s Rule.\nConjecture\n\nFor what degree polynomials will Simpson’s rule be exact?\nWhat do you think the order of the truncation error will be for Simpson’s method?\n\n\nSetting up the integral of the interpolating polynomial.\nAs before, we will first approximate the integrand by an interpolating polynomial. In this case we will take 3 equally spaced points \\(x_0,x_1, x_2\\) such that \\(x_0 = a, x_1 = x_0 + h, x_2 = b\\), where \\(h = (b-a)/2\\).\nWe assumed that \\(f(x)\\) had as many derivatives as we needed. This time let’s write the Taylor expansion for \\(f(x)\\) about \\(x_1\\) going out to the 4th derivative term. The reason for going out to the 4th derivative will become clear in a minute.\n\\[\n\\begin{aligned}\nf(x) &= f(x_1) + f^{\\prime}(x_1)(x - x_1) + \\frac{1}{2} f^{\\prime\\prime} (x_1)(x - x_1)^2  \\\\\n&+ \\frac{1}{6} f^{\\prime\\prime\\prime}(x_1) (x - x_1)^3 + \\frac{1}{24} f^{(4)} (\\xi), \\qquad \\xi \\in[x_0, x_2]\n\\end{aligned}\n\\]\nNow let’s integrate this equation:\n\\[\n\\begin{aligned}\n\\int_{x_0}^{x_2} f(x) &= \\Big[ f(x_1)(x - x_1) + \\frac{1}{2} f^{\\prime} (x_1)(x - x_1)^2 \\\\\n&+ \\frac{1}{6} f^{\\prime\\prime}(x_1) (x - x_1)^3 + \\frac{1}{24} f^{\\prime\\prime\\prime}(x_1) (x - x_1)^4 \\Big]_{x_0}^{x_2} \\\\\n&+ \\frac{1}{24} \\int_{x_0}^{x_2}f^{(4)} (\\xi(x))(x-x_1)^4 dx. \\\\\n\\end{aligned}\n\\tag{22.9}\\]\nAs before let’s consider the error term first and notice that it would be nice to take the \\(f^{(4)} (\\xi(x))\\) in the last term outside of the integral.\nUsing the previous trick, we note that \\((x-x_1)^4\\) doesn’t change sign in the interval \\([x_0, x_1]\\), so we can again use the Weighted Mean Value Theorem for Integrals to pull the \\(f^{(4)}\\) term out from inside the integral.\n\\[\n\\begin{aligned}\nE(f) &= \\frac{1}{24} \\int_{x_0}^{x_2}f^{(4)} (\\xi(x))(x-x_1)^4 dx, \\\\\n&= \\frac{f^{(4)} (\\xi_1)}{24} \\int_{x_0}^{x_2}(x-x_1)^4 dx, \\\\\n&= \\frac{f^{(4)} (\\xi_1)}{120} (x-x_1)^5 \\Big|_{x_0}^{x_2}.\\\\\n\\end{aligned}\n\\]for some \\(\\xi_1 \\in [x_0, x_2]\\).\nNow we can use the fact that \\(h = x_2-x_1 = x_1 - x_0\\) to reduce the equation to:\n\\[\nE(f) = \\frac{h^5 f^{(4)} (\\xi_1)}{60}.\n\\tag{22.10}\\]\n\n\nEvaluating the integral of the interpolating polynomial.\nOur only remaining task is to evaluate the first term in Equation 22.9 to arrive at formulas for the \\(a_i(x)\\) coefficients and produce the approximation for \\(I(f)\\). :\n\\[\n\\begin{aligned}\n\\Big[ f(x_1)(x - x_1) &+ \\frac{1}{2} f^{\\prime} (x_1)(x - x_1)^2 \\\\\n&+ \\frac{1}{6} f^{\\prime\\prime}(x_1) (x - x_1)^3 + \\frac{1}{24} f^{\\prime\\prime\\prime}(x_1) (x - x_1)^4 \\Big]_{x_0}^{x_2}\n\\end{aligned}\n\\]\n\n\n\n\n\n\nTip:\n\n\n\nWhen faced with a daunting amount of algebra (recall our experience with the Trapezoid Rule), it helps to remember both the goal and the assumptions we’ve made that might help simplify the task. For example, recall our assumption of equally spaced nodes. We can replace \\(x_2-x_1 = x_1-x_0\\) by \\(h\\) – which reduces our formula to:\n\n\n\\[\n\\begin{aligned}\n&\\Big[ f(x_1)h + \\frac{1}{2} f^{\\prime} (x_1)h^2 + \\frac{1}{6} f^{\\prime\\prime}(x_1) h^3 + \\frac{1}{24} f^{\\prime\\prime\\prime}(x_1)h^4\\Big] - \\\\\n&\\Big[ f(x_1)(-h) + \\frac{1}{2} f^{\\prime} (x_1)h^2 + \\frac{1}{6} f^{\\prime\\prime}(x_1) (-h)^3 + \\frac{1}{24} f^{\\prime\\prime\\prime}(x_1)h^4 \\Big].\n\\end{aligned}\n\\]\nNicely, the \\(h^2\\) and \\(h^4\\) terms cancel out, leaving us with\n\\[\n2hf(x_1) + \\frac{h^3}{3} f^{\\prime\\prime} (x_1).\n\\tag{22.11}\\]\n\n\nRemark: We could just as easily have noticed that (under the assumption of equally spaced nodes), \\((x_2 - x_1)^k - (x_0 - x_1)^k = 0\\) for even \\(k\\) and that \\((x_2 - x_1)^k - (x_0 - x_1)^k = 2h^k\\) for odd \\(k\\).\nNow remember our goal was to write our approximation in terms of only \\(f(x_i)\\), meaning we should look for a way to replace the second derivative term in Equation 22.11.\nFor this task, we can take advantage of one last substitution, which is to use our finite difference approximation for the second derivative (derived in our previous lecture), i.e.\n\\[\nf^{\\prime \\prime}(x_1) = \\frac{f(x_0) - 2f(x_1) + f(x_2)}{h^2} -\\frac{h^2}{12} f^{(4)}(\\xi_2)\n\\]\nand not forgetting to include its own error term.\nWhen substituted into Equation 22.11 we get:\n\\[\n2hf(x_1) + \\frac{h^3}{3} \\left[\\frac{f(x_0) -  2f(x_1) + f(x_2)}{h^2} -\\frac{h^2}{12} f^{(4)}(\\xi_2) \\right]\n\\tag{22.12}\\]\nCombining Equation 22.12 with Equation 22.10 and simplifying terms we arrive at our final result, which is called Simpson’s Rule:\n\n\n\n\n\n\nSimpson’s Rule\n\n\n\n\\[\n\\int_{x_0}^{x_2} f(x)dx = \\frac{h}{3} [ f(x_0) + 4f(x_1) + f(x_2)] - \\frac{h^5}{90} f^{(4)}(\\xi).\n\\tag{22.13}\\]\nCaution: Other formulas use \\(\\frac{b-a}{6}\\) instead of \\(\\frac{h}{3}\\) in the definition of Simpson’s Rule. Just remember that here, we defined \\(h=x_2-x_1 = x_1-x_0\\), so \\(h=\\frac{b-a}{2},\\) as a result the two definitions are equivalent.\n\n\nI leave as an exercise how to combine the two \\(f^{(4)}\\) terms from Equation 22.10 and Equation 22.12 into one, i.e. show that\n\\[\n- \\frac{h^5}{60} f^{(4)}(\\xi_1) - \\frac{h^5}{36} f^{(4)}(\\xi_2)\n= - \\frac{h^5}{90} f^{(4)}(\\xi), \\quad \\xi \\in(a,b)\n\\]\nRemark: In some formulations, the leading term in Simpson’s Rule is \\(h/3\\) and sometimes it’s \\((b-a)/6.\\) This is a result of how one defines \\(h\\). Here we set it equal to \\(x_2-x_1 = x_1-x_0\\), hence \\(h = (b-a)/2\\).\nAn important result is that instead of the expected \\(O(h^4)\\) error term, we might have expected from going from a linear interpolant to a quadratic interpolant we have instead gained an additional order of accuracy in the error term!\n\nDefinition 22.1 The precision (also degree of accuracy) of a quadrature formula is defined as the largest positive integer \\(n\\) such that the quadrature formula is exact for \\(x^k\\), for \\(k=0,1, \\ldots, n\\).\n\n\n\n\n\n\n\nTip\n\n\n\nIn the case of Simpson’s rule, it is exact for any polynomial of degree 3 or less, hence the precision is 3. Similarly, the precision for the Trapezoid rule is 1. The easiest way to remember this is to take a look at the derivative in the error term and subtract one order. Please do not confuse this with the order of accuracy, which can be seen from the power in the \\(h\\) term!\n\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Numerical Integration Basics</span>"
    ]
  },
  {
    "objectID": "NumIntNewtonCotes.html",
    "href": "NumIntNewtonCotes.html",
    "title": "23  Newton-Cotes Methods",
    "section": "",
    "text": "23.1 Newton-Cotes\nThe basic quadrature rules derived so far are generally good, but what if we wanted to have formulas with greater accurarcy. The general approach we used still holds and leads to a family of quadrature formulas known as Newton-Cotes formulas. These are classified under either open or closed depending on whether the formulas include the end points or not.\nClosed Newton-Cotes include the endpoints of closed interval \\([a,b]\\) as nodes.\nOpen Newton-Cotes do not include the endpoints.\nTo be specific, for a closed Newton-Cotes quadrature formula we would choose the node points \\(x_i\\) through the formula:\n\\[\nx_i = a + i \\frac{b-a}{n-1}, \\quad i=0, 1, \\ldots, n-1.\n\\tag{23.1}\\]\nFor an open Newton-Cotes quadrature formula we would use the formula:\n\\[\nx_i = a + (i+1) \\frac{b-a}{n+1}, \\quad i=0, 1, \\ldots, n-1.\n\\tag{23.2}\\]\nOne example of an Open Newton-Cotes that we’ve already seen is the midpoint rule \\[\n\\int_a^b f(x) dx = 2h f(x_0) + \\frac{h^3}{3} f^{\\prime\\prime}(\\xi) \\; \\xi \\in (a,b)]\n\\] where \\(x_0\\) is the midpoint between \\(a\\) and \\(b\\). Likewise, both Trapezoidal and Simpson’s rules, which we introduced in Section 22.1 can be categorized as Closed Newton-Cotes.\nThere are many different formulas of both the Closed and Open variety all with corresponding error terms. All of them can be derived by the methods we’ve used for Trapezoid and Simpson’s rule, so there is little to be gained by re-deriving them.\nInstead we will present them here because an interesting pattern arises that is worth knowing about:",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Newton-Cotes Methods</span>"
    ]
  },
  {
    "objectID": "NumIntNewtonCotes.html#newton-cotes",
    "href": "NumIntNewtonCotes.html#newton-cotes",
    "title": "23  Newton-Cotes Methods",
    "section": "",
    "text": "Example 23.1 Suppose, we choose \\(n=5\\) on the interval [a,b] = [0,1].\nThen the closed Newton-Cotes formula would generate the points:\n\\[\n\\begin{aligned}\nx_i & = a + i \\ \\cdot \\frac{b-a}{n-1}, \\\\\n&= 0 + i \\frac{1}{4}, \\\\\n&= \\frac{i}{4}, \\quad i=0, 1, \\ldots, 4,\n\\end{aligned}\n\\] thereby yielding the set of nodes: \\(\\{x\\} = \\{ \\ 0, .25, .5, .75, 1.0\\ \\}.\\)\nSimilarly for the open Newton-Cotes formula would generate the points:\n\\[\n\\begin{aligned}\nx_i &= a + (i+1) \\cdot \\frac{b-a}{n+1},  \\\\\n&= 0 + (i+1) \\frac{1}{6}, \\\\\n&= \\frac{i+1}{6}, \\quad i=0, 1, \\ldots, 4,\n\\end{aligned}\n\\] which generates the set of nodes: \\(\\{x\\} = \\{ \\ 1/6, \\ 2/6, \\ 3/6, \\ 4/6, \\ 5/6 \\ \\}.\\)\n\n\n\n\n\nClosed Newton-Cotes formulas:\n\\(n = 2\\) (Trapezoid)\n\\[\nI(f) = \\frac{b-a}{2} [ f(x_0) + f(x_1)]\n\\tag{23.3}\\]\n\\(n=3\\) (Simpson’s)\n\\[\nI(f) = \\frac{b-a}{6} [ f(x_0) + 4f(x_1) + f(x_2)]\n\\tag{23.4}\\]\n\\(n=4\\) (Simpson’s 3/8) \\[\nI(f) = \\frac{b-a}{8} [ f(x_0) + 3f(x_1) + 3f(x_2) + f(x_3) ]\n\\]\n\\(n=5\\) (Boole’s rule) \\[\nI(f) = \\frac{b-a}{90} [ 7f(x_0) + 32f(x_1) + 12f(x_2) + 32f(x_3) + 7f(x_4)]\n\\]\n\n\n\n\n\n\nNotation\n\n\n\nThe formulas here are written using \\(b-a\\) versus \\(h\\) to make them easier to compare. However, you will see these formulas written in terms of \\(h\\) in many other places. You should be careful in understanding exactly what \\(h\\) represents as it often is taken to mean \\(h = (b-a)/(n-1), \\ n \\geq 1,\\) which corresponds to the number of node points used in the qudrature formula.\n\n\nIn theory, we could go as high as we wanted (and people have) in generating higher-order quadrature formulas, and of course with additional computational work. However, for large \\(n\\) the formulas can be shown to become numerically unstable (\\(n\\geq 11.)\\) One can actually prove that formulats do not converge for all integrands that are analytic. In practice, we tend to only use low-order formulas since they can still give us good accuracy (especially over small intervals (see Exercise 23.1 below).\n\n\nOpen Newton-Cotes formulas:\n\\(n = 1\\) (Midpoint)\n\\[\nI(f) = (b-a)f(x_0)\n\\]\n\\(n=2\\)\n\\[\nI(f) = \\frac{b-a}{2} [ f(x_0) +\nf(x_1)]\n\\]\n\\(n=3\\) \\[\nI(f) = \\frac{b-a}{3} [ 2f(x_0) - f(x_1) + 2f(x_2) ]\n\\]\nSimilarly to the closed Newton-Cotes formulas, we could continue and derive higher-order formulas - with the same consequences.",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Newton-Cotes Methods</span>"
    ]
  },
  {
    "objectID": "NumIntNewtonCotes.html#error-estimates",
    "href": "NumIntNewtonCotes.html#error-estimates",
    "title": "23  Newton-Cotes Methods",
    "section": "23.2 Error Estimates",
    "text": "23.2 Error Estimates\nIn both the closed and open Newton-Cotes cases, the formulas have error terms, which we have summarized in the table below, along with the precision of each:\n\n\n\nTable 23.1: Summary of Error Terms for Newton-Cotes quadrature formulas\n\n\n\n\n\n\n\n\n\n\n\nName\nNpts\nError\nPrecision\n\n\n\n\nTrapezoid\n2\n\\[                                                                                                                                                                                                               \n                                                                                                                                                                                                                             -\\frac{(b-a)^3}{12} f^{(2)}(\\xi)\\]\n1\n\n\nSimpson’s\n3\n\\[                                                                                                                                                                                                               \n                                                                                                                                                                                                                           -\\frac{(b-a)^5}{2880} f^{(4)}(\\xi)\\]\n3\n\n\nSimpson’s 3/8\n4\n\\[                                                                                                                                                                                                               \n                                                                                                                                                                                                                           -\\frac{(b-a)^5}{6480} f^{(4)}(\\xi)\\]\n3\n\n\nBoole\n5\n\\[                                                                                                                                                                                                               \n                                                                                                                                                                                                                        -\\frac{(b-a)^7}{1935360} f^{(6)}(\\xi)\\]\n5\n\n\nMidpoint\n1\n\\[                                                                                                                                                                                                               \n                                                                                                                                                                                                                              \\frac{(b-a)^3}{24} f^{(2)}(\\xi)\\]\n1\n\n\n\n2\n\\[                                                                                                                                                                                                               \n                                                                                                                                                                                                                              \\frac{(b-a)^3}{36} f^{(2)}(\\xi)\\]\n1\n\n\n\n3\n\\[                                                                                                                                                                                                               \n                                                                                                                                                                                                                           \\frac{(b-a)^5}{23040} f^{(4)}(\\xi)\\]\n3\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAn interesting feature of the quadrature formulas is that whenever \\(N\\) is odd then the precision of the formula \\(=N.\\) But when \\(N\\) is even then the precision is only \\(N-1\\). We lose one order in the precision whenever \\(N\\) is even! Or we could also say that we gain one order of precision for \\(N\\) odd.\n\n\nAs a final look into these methods, let’s compare several of the methods on a simple function to gain further insight into the behavior of the formulas.\n\nExercise 23.1 Compute the value of \\[ \\int_{0}^{1} e^x dx \\]\nusing the Trapezoid and Simpson’s Rule for:\n\na = 0, b = 1\na = 0.9, b = 1\n\nTrapezoid Rule:\n\\[\n\\int_a^b f(x) dx = \\frac{(b -a)}{2} \\Big [ f(x_0) + f(x_1) \\Big ],\n\\]\n\n\n\nSolution\n\n\nSimpson’s Rule:\n\\[\n\\int_a^b f(x) dx = \\frac{(b-a)}{6} [ f(x_0) + 4f(x_1) + f(x_2)]\n\\]\n\n\n\nSolution\n\n\n\nThe lesson from this example is that all of the formulas have a rather large error when we compute the integral over a large interval, whereas when we considered a smaller interval, the error was in fact quite small.",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Newton-Cotes Methods</span>"
    ]
  },
  {
    "objectID": "NumIntNewtonCotes.html#summary",
    "href": "NumIntNewtonCotes.html#summary",
    "title": "23  Newton-Cotes Methods",
    "section": "23.3 Summary",
    "text": "23.3 Summary\nLet’s take a step back and summarize the main results:\n\nWe can use a simple approach towards deriving basic quadrature rules by replacing the integrand with an interpolating polynomial and integrating the polynomial on a chosen set of \\(N\\) points.\nUsing Taylor’s theorem, we can also generate corresponding error terms that can provide us with estimates on how well the quadrature formula approximated the given integral.\nThe precision of a quadrature formula is the highest degree of the polynomial for which the formula is exact. When \\(N\\) is odd, the precision is also \\(N\\); but when \\(N\\) is even, the precision is \\(N-1\\).\nHigher-order quadrature formulas yield greater accuracy, but at greater additional computational work as well as a fundamental assumption on the higher-order derivatives being nicely behaved (i.e. bounded).\nBasic (and low-order) formulas can be quite accurate, but usually require a small interval. This observation will prove useful in the next sections.\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Newton-Cotes Methods</span>"
    ]
  },
  {
    "objectID": "NumIntComposite.html",
    "href": "NumIntComposite.html",
    "title": "24  Composite Quadrature Rules",
    "section": "",
    "text": "24.1 Composite Integration\nIn practice we can’t use Newton-Cotes over large intervals as it would require high degree polynomials, which would be unsuitable due to the highly oscillatory nature. Another disadvantage is that we would need to have equally spaced intervals, which are not suitable for many physical applications.\nThe strategy is to use something simple like Trapezoid or Simpson’s Rule on each of the subregions (often called panels), and then sum up the individual contributions to arrive at the solution to the original problem. As a quick note, there is nothing in this approach that directs us to use subregions of equal size, but for exposition, we will assume that they are for the time being. We will come back to this point in the next section on adaptive methods Section 25.1.\nIn the general case, let’s assume that we have sub-divided the interval \\([a,b]\\) Into \\(r\\) subregions, each of equal length \\(h = \\frac{b-a}{r}\\). See Figure 24.1 for the case \\(r=5\\).\nThen our composite quadrature rule could be written as:\n\\[\n\\int_a^b f(x) dx = \\sum_{i=1}^{r} \\int_{t_{i-1}}^{t_i} f(x) dx,\n\\] where \\(t_i = a + ih\\). All we need do now is to apply one of our earlier quadrature formulas to the integrals in each of the subintervals \\([t_{i-1},t_i]\\).\nLet’s work out an example in the simple case of the Trapezoid Rule:\n\\[\n\\begin{aligned}\n\\int_a^b f(x) dx &\\approx \\sum_{i=1}^{r} \\int_{t_{i-1}}^{t_i} f(x) dx, \\\\\n&\\approx \\sum_{i=1}^{r} \\frac{h}{2} \\left[ f(t_{i-1}) + f(t_i) \\right], \\\\\n&= \\frac{h}{2} \\left[ f(t_{0}) + 2f(t_1) + 2f(t_2) + \\ldots+ 2f(t_{r-1}) + f(t_r)\\right], \\\\\n&= \\frac{h}{2} \\left[ f(a) + 2f(t_1) + 2f(t_2) + \\ldots+ 2f(t_{r-1}) + f(b)\\right],\n\\end{aligned}\n\\] This leads to the Composite Trapezoid Rule:\nwhere \\(h = (b-a)/r\\); \\(t_i = a + ih, \\  i=0, 1, \\ldots, r\\) and \\(\\mu \\in (a,b)\\).\nA similar exercise will lead to the Composite Simpson’s Rule:\nwhere \\(h = (b-a)/r\\); \\(t_i = a + ih, \\  i=0, 1, \\ldots, r\\) and \\(\\mu \\in (a,b)\\).\nThe derivation for Composite Simpson’s rule isn’t difficult, and mostly a matter of getting the right indices. One observation that is helpful in deriving the formula is that because of the need for 3 nodes in Simpson’s rule we should consider the panels in pairs. For this reason, the number of panels for Simpson’s rule must always be an even number.\nExample: Let’s consider the simplest case with 4 panels, which we can group into two pairs, as depicted in the figure below. Here you should think of the first integration region spanning the first two panels so as to encompass the area in the interval \\([t_0,t_2]\\). Likewise, the second region will cover the interval \\([t_2,t_4]\\).\nRecall Simpson’s rule (Equation 23.4),\n\\[\nI(f) = \\frac{b-a}{6} [ f(x_0) + 4f(x_1) + f(x_2)],\n\\]\nwhich we can apply to each one of the two sub-intervals, \\([t_0,t_2]\\) and \\([t_2,t_4].\\) Let’s call the integrals over the two sub-intervals, \\(S_1\\) and \\(S_2:\\)\n\\[\n\\begin{aligned}\nS_1 &= \\frac{t_2 - t_0}{6} [ f(t_0) + 4f(t_1) + f(t_2)], \\\\\nS_2 &= \\frac{t_4 - t_2}{6} [ f(t_2) + 4f(t_3) + f(t_4)].\\end{aligned}\n\\]\nThe total integral is then just the sum of these two. Here we need to notice that each sub-interval is of length \\(2h\\), allowing us to also simplify the sums a bit.\n\\[\n\\begin{aligned}\nI(f) = \\ & S_1 + S_2 \\\\\n= \\ &\\frac{h}{3} [ f(t_0) + 4f(t_1) + f(t_2)] \\  + \\\\\n& \\frac{h}{3} [ f(t_2) + 4f(t_3) + f(t_4)].\n\\end{aligned}\n\\]\nNow, rearraning the terms we get:\n\\[\n\\begin{aligned}\nI_{Simp}(f) &= \\frac{h}{3} [ f(t_0) + 4f(t_1) + 2f(t_2) + 4f(t_3) + f(t_4)], \\\\\n&= \\frac{h}{3} [ f(t_0) + 4 [f(t_1)+f(t_3)] + 2f(t_2) + f(t_4)].\n\\end{aligned}\n\\]\nIt should be clear how the general pattern follows.",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Composite Quadrature Rules</span>"
    ]
  },
  {
    "objectID": "NumIntComposite.html#sec-composite-integration",
    "href": "NumIntComposite.html#sec-composite-integration",
    "title": "24  Composite Quadrature Rules",
    "section": "",
    "text": "Idea\n\n\n\nInstead of trying to approximate the integral accurately over the entire interval with one polynomial, break up the domain into smaller regions and use low-order polynomials on each of them.\n\n\n\n\n\n\n\n\n\nDivide and Conquer (Redux)\n\n\n\nThe idea behind breaking the original problem into several smaller problems is used in many situations and is often referred to as a divide-and-conquer strategy. Recall, that we used a similar approach in Section 18.1 when we chose to break up the problem of interpolation via piecewise functions over a set of sub-intervals instead of one single interpolating polynomial.\n\n\n\n\n\n\n\nFigure 24.1: Approximating the integral by sudviding the region into multiple “panels” and using the trapezoid rule will lead to higher accuracy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComposite Trapezoidal Rule\n\n\n\n\\[\n\\int_a^b f(x) dx = \\frac{h}{2} \\left[ f(a) + 2 \\sum_{i=1}^{r-1}f(t_i) + f(b) \\right] - \\frac{(b-a)}{12} h^2 f^{\\prime\\prime}(\\mu),\n\\tag{24.1}\\]\n\n\n\n\n\n\n\n\n\n\nComposite Simpson’s Rule\n\n\n\n\\[\n\\begin{aligned}\n\\int_{x_0}^{x_2} f(x)dx &= \\frac{h}{3} [ f(a) + 2 \\sum_{i=1}^{r/2-1}f(t_{2i}) + 4 \\sum_{i=1}^{r/2}f(t_{2i-1}) + f(b)] \\ \\\\\n&- \\frac{(b-a)}{180} h^4 f^{(4)}(\\mu).\n\\end{aligned}\n\\tag{24.2}\\]\n\n\n\n\n\n\n\n\n\n\n\nFigure 24.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAn immediate consequence of this approach is that the quadrature formulas lose one order of \\(h\\) in their approximations. This should not be surprising as even though each individual panel has the original truncation error, when we add up all the panels, the errors from each of the individual panels add up and we lose one order of magnitude. However, since \\(h\\) is smaller, the overall result is a win!",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Composite Quadrature Rules</span>"
    ]
  },
  {
    "objectID": "NumIntComposite.html#error-analysis-and-stability",
    "href": "NumIntComposite.html#error-analysis-and-stability",
    "title": "24  Composite Quadrature Rules",
    "section": "24.2 Error Analysis and Stability",
    "text": "24.2 Error Analysis and Stability\nWhile we have a fairly good handle on the error analysis of quadrature formulas and the order of convergence, one question we haven’t addressed yet is the stability of quadrature formulas.\nFirst, we know that the truncation error is well-behaved and will go to zero at varying degrees depending on the degree of the interpolating polynomial we use. What caused problems before was that roundoff error could increase dramatically leading to unstable algorithms.\nLet’s proceed as before, by performing a floating point error analysis similar to the one we used for numerical differentiation. Recall, that we first assumed that a computation of a function value always incurs some roundoff error, in other words, we can write:\n\\[\nf(t_i) = \\hat{f}(t_i) + e_i, \\ i = 0, 1, \\ldots, n,\n\\]\nwhere \\(\\hat{f}\\) is the floating point representation and \\(e_i\\) is the roundoff error incurred when computing the function value. As before, we will assume that the errors are uniformly bounded:\n\\[\ne_i &lt; \\epsilon, \\quad \\epsilon &gt; 0.\n\\]\nfor all \\(i\\).\nIf we substitute into the Composite Simpson’s rule we can write the error as:\n\\[\n\\begin{aligned}\n| e(h)| &= \\Big | \\frac{h}{3} \\big ( e_0 + 2 \\sum_{i=1}^{r/2-1}e_{2i} + 4 \\sum_{i=1}^{r/2}e_{2i-1} + e_r \\big ) \\Big |, \\\\\n&\\leq \\frac{h}{3} \\big ( \\epsilon + 2 (\\frac{r}{2}-1)\\epsilon + 4 (\\frac{r}{2})\\epsilon + \\epsilon \\big ), \\\\\n& \\leq \\frac{h}{3}\\big ( 3r \\epsilon \\big ) = r h \\epsilon.\n\\end{aligned}\n\\]\nFinally, let’s remember that \\(h= (b-a)/r,\\) which means that the error is bounded by:\n\\[\n| e(h) | \\leq (b-a) \\ \\epsilon,\n\\]which is independent of both \\(h\\) and \\(r\\).\n\n\n\n\n\n\nImportant\n\n\n\nIn other words, Simpson’s rule is stable!\n\n\nFurthermore, it should be obvious that we can do the same analysis for any of the open or closed Newton-Cotes quadrature formulas. Unlike numerical differentiation, quadrature is generarlly more stable.\n\nExercise 24.1 Determine values of \\(h\\) that will ensure an approximation error of \\(&lt; 0.00002\\) when approximating \\[\n\\int_0^{\\pi} \\sin x dx\n\\] using\n\nComposite Trapezoidal Rule\nComposite Simpson’s Rule\n\n\nSolution:\nComposite Trapezoid. Our starting point is the formula for the truncation error. For composite Trapezoid we use Equation 24.1:\n\\[\nE(f) = -\\frac{b-a}{12} h^2 f^{\\prime\\prime}(\\xi).\n\\]\nWe would like this term to be less than the tolerance \\(\\epsilon = 2 \\cdot 10^{-5}\\)\n\\[\n\\begin{aligned}\n\\left | E(f) \\right | &= \\left | \\frac{\\pi}{12}  h^2\\sin (\\xi) \\right| \\\\\n&= \\frac{\\pi}{12}  h^2 \\left |  \\sin (\\xi) \\right|  \\\\\n&\\leq \\frac{\\pi h^2}{12} &lt; 2 \\cdot 10^{-5}\n\\end{aligned}\n\\] with the last inequality because \\(| \\sin(x) |\\leq 1.\\)\nSolving for \\(h\\) is then an easy matter:\n\\[\n\\begin{aligned}\n\\frac{\\pi h^2}{12} &&lt; 2 \\cdot 10^{-5}, \\\\\nh^2 & &lt; \\frac{24 \\cdot 10^{-5} }{\\pi}, \\\\\nh &&lt; \\sqrt {\\frac{24 \\cdot 10^{-5} }{\\pi}}. \\\\\n\\implies h &\\approx 0.00874.\n\\\\\n\\end{aligned}\n\\]\nTo achieve the desired accuracy, would then require \\(r = (b-a)/h\\) panels or \\(r \\approx 360\\) panels.\nComposite Simpson. As before, our starting point is the formula for the truncation error. For composite Simpson we use Equation 24.2:\n\\[\nE(f) = -\\frac{b-a}{180} h^4 f^{(4)}(\\xi).\n\\]\nWe would like this term to be less than the tolerance \\(\\epsilon = 2 \\cdot 10^{-5}\\)\n\\[\n\\begin{aligned}\n\\left | E(f) \\right | &= \\left | \\frac{\\pi}{12}  h^4\\sin (\\xi) \\right|, \\\\\n&= \\frac{\\pi}{12}  h^4 \\left |  \\sin (\\xi) \\right|,  \\\\\n&\\leq \\frac{\\pi h^4}{180} &lt; 2 \\cdot 10^{-5},\n\\end{aligned}\n\\] with the last inequality because \\(| \\sin(x) |\\leq 1.\\)\nSolving for \\(h\\):\n\\[\n\\begin{aligned}\n\\frac{\\pi h^4}{180} &&lt; 2 \\cdot 10^{-5}, \\\\\nh^4 & &lt; \\frac{360 \\cdot 10^{-5} }{\\pi}, \\\\\nh &&lt; \\sqrt[\\LARGE{4}] {\\frac{360 \\cdot 10^{-5} }{\\pi}}. \\\\\n\\implies  h &\\approx 0.18399\n\\end{aligned}\n\\]\nTo achieve the desired accuracy, would then require \\(r = (b-a)/h\\) panels or \\(r \\approx 18\\) panels. For this example, it is clear that Composite Simpson is a much better choice than Composite Trapezoid.",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Composite Quadrature Rules</span>"
    ]
  },
  {
    "objectID": "NumIntComposite.html#summary",
    "href": "NumIntComposite.html#summary",
    "title": "24  Composite Quadrature Rules",
    "section": "24.3 Summary",
    "text": "24.3 Summary\nThere are several choices to be made when considering which quadrature method to use and what size of \\(h\\) to choose. Deciding between a lower order method versus a higher order method can also be tricky. The error term will depend on both the size of \\(h\\) as well as the magnitude of the highest derivative required. Choosing \\(h\\) will require (as in the case of numerical differentiation) a balance between truncation error and roundoff error.\n\n\n\n\n\n\nPractical Tips\n\n\n\n\nThe smaller \\(h\\) is, the greater the accuracy for all methods; however that also implies we have more panels and hence a higher computational load.\nIf the function that is to be integrated is smooth then higher order methods are likely to work well.\nHowever, if the the function is rapidly changing, then the higher derivatives will likely be large and one might want to consider lower order methods, especially if the integral interval is small.\n\n\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Composite Quadrature Rules</span>"
    ]
  },
  {
    "objectID": "NumIntAdaptive.html",
    "href": "NumIntAdaptive.html",
    "title": "25  Adaptive Quadrature",
    "section": "",
    "text": "25.1 Adaptive Quadrature\nComposite quadrature formulas can be quite effective as we discussed in the last section. There is one drawback however - so far we have only used a uniform spacing for the nodes. We did this mainly to simplify the analysis, and to highlight the main ideas. However, there was no underlying need to do so. In fact, there are many situations where it is clear that a uniform spacing might not be optimal. Consider for example, the following function:\n\\[\nf(x) = e^{-3x} \\sin(4x), \\ x \\in [0,10]\n\\]\nIf we attempt to use a uniform spacing that tries to approximate the integral of this function, we will be caught between two competing interests. To capture the behavior of the function towards the right end of the interval a spacing of \\(h=0.5\\) or even \\(h=1.0\\) would likely be adequate. However, if we want to capture the behavior of the function towards the left end of the interval, then it looks likely that we would need to have a spacing of \\(h\\) that is much smaller. And if we choose the smaller \\(h\\) then we will be committed to doing additional computational work that is not needed on the right end of the interval.\nThis problem can be exacerbated when working in two or three dimensions, where the computational work could increase dramatically, if we have to choose a uniform \\(h\\) in all of the dimensions. In the above example, suppose we had to choose one \\(h\\) for the entire region. The table below depicts the size of the problem in terms of the number of “cells” one would have to compute over the interval \\([0,10]\\) with a uniform grid, and a nonuniform grid where the majority of the points are chosen in a small subinterval, say \\(x \\in[0,2]\\). The difference isn’t particularly noteworthy in one dimension but when you reach a three-dimensional problem, there is an additional factor of 1000 to consider when using a uniform grid.\nThe solution is obvious, which is to find a value of \\(h\\) that is adapted to what the function is doing over a particular subinterval. But the big question is how do we know this without evaluating the function at many different points and how do we choose a good value of \\(h\\) that gives us good accuracy without also increasing the computational workload too much.\nLet’s consider the Composite Trapezoid Rule first. Recall that we can write the quadrature formula as:\n\\[\nI(f) = \\int_a^b f(x) dx = \\frac{h}{2} \\left[ f(a) + 2 \\sum_{i=1}^{r-1}f(t_i) + f(b) \\right] - \\frac{(b-a)}{12} h^2 f^{\\prime\\prime}(\\mu),\n\\]\nSuppose we write the approximation to the integral as: \\[\nR_1 = \\frac{h}{2} \\Big [ f(a) + 2f(a+h) + \\ldots + 2f(b-h) + f(b) \\Big ] + K h^2,\n\\] Now let’s suppose we cut \\(h\\) in half and write the Trapezoid rule again: \\[\nR_2 = \\frac{h}{4} \\Big [ f(a) + 2f(a+h/2) + \\ldots + 2f(b-h/2) + f(b) \\Big ] + K \\Big (\\frac{h}{2} \\Big )^2,\n\\]\nLet’s now consider the error in each of these formulas: \\[\n\\begin{aligned}\nI(f) - R_1 &\\approx K h^2,\\\\\nI(f) - R_2 &\\approx K \\Big (\\frac{h}{2} \\Big )^2 = \\frac{1}{4} K h^2.\n\\end{aligned}\n\\] The next step requires us to make an assumption, namely that the terms that constitute the constant \\(K\\) in both of the above terms are approximately equal. This should be true if the fourth derivative terms in each of the constants are comparable, which seems reasonable since they are from the same function and over similar intervals: \\[\nf^{(4)} (\\xi_1) \\approx f^{(4)} (\\xi_2).\n\\]\nSubstituting the first equation into the second we get: \\[\nI(f) - R_2 \\approx \\frac{1}{4} [ I(f) - R_1 ].\n\\tag{25.1}\\] Let’s now consider the error for \\(R_1\\): \\[\n\\begin{aligned}\nI(f) - R_1 &= (I(f) - R_2) + (R_2 - R_1), \\\\\n& \\approx \\frac{1}{4} [ I(f) - R_1] + (R_2 - R_1) \\\\\n\\\\\n\\implies I(f) - R_1 &\\approx \\frac{4}{3} (R_2 - R_1).\n\\end{aligned}\n\\tag{25.2}\\] Finally, we can combine Equation 25.1 and Equation 25.2 to get:\n\\[\n\\begin{aligned}\nI(f) - R_2 &\\approx \\frac{1}{4} [ I(f) - R_1 ] \\\\\n& \\approx \\frac{1}{4} \\Big [ \\frac{4}{3} (R_2 - R_1) \\Big ] \\\\ \\\\\n\\implies I(f) - R_2 & \\approx \\frac{1}{3} \\Big [ (R_2 - R_1) \\Big ] \\\\\n\\end{aligned}\n\\tag{25.3}\\]\nThe important thing to note is that once everything on the right hand sides (specifically \\(R_1, R_2\\)), have been computed, we can generate an estimate for the error in both quadrature approximations. These types of computations are known as a posteriori error estimates.\nIn a similar manner we can produce a posteriori error estimates for composite Simpson’s rule and write:\nWe can interpret this to mean that the error from the quadrature approximation with \\(h/2\\) (\\(S_2\\)) should be about 1/15 of the difference between the two Simpson’s rule approximations at \\(h\\) and \\(h/2\\).\nThis observation can lead us to develop a strategy for deciding when to subdivide a panel and when to stop. Specifically, suppose we want the error to be less than a certain tolerance, \\(\\epsilon\\). Then we can ask whether for a given panel\n\\[\n\\frac{1}{15} \\Big ( S_2 - S_1  \\Big ) &lt; \\epsilon.\n\\]\nIf this is true, then we can stop for that given panel. If however, the difference doesn’t satisfy the tolerance, that is an indication that we should subdivide the region in half again.\nA general algorithm might look something like:",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Adaptive Quadrature</span>"
    ]
  },
  {
    "objectID": "NumIntAdaptive.html#sec-adaptive-integration",
    "href": "NumIntAdaptive.html#sec-adaptive-integration",
    "title": "25  Adaptive Quadrature",
    "section": "",
    "text": "Figure 25.1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\n\\(h\\)\n\\(N\\)\n\\(N^2\\)\n\\(N^3\\)\n\n\n\n\nUniform\n\\(0.1\\)\n\\(100\\)\n\\(\\approx 10^4\\)\n\\(\\approx 10^6\\)\n\n\n\n\\(0.01\\)\n\\(1000\\)\n\\(\\approx 10^6\\)\n\\(\\approx 10^9\\)\n\n\nNonuniform\n\\(0.1\\)\n\\(\\approx 20\\)\n\\(\\approx 400\\)\n\\(\\approx 8000\\)\n\n\n\n\\(0.01\\)\n\\(\\approx 110\\)\n\\(\\approx 10^4\\)\n\\(\\approx 10^6\\)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIdea\n\n\n\nIf we could predict the variation in the function, then we could choose a smaller \\(h\\) in only those regions that need it to attain the accuracy we want! Our strategy will be to leverage our error analysis to help us predict the variation.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimpson a posteriori error estimates\n\n\n\n\\[\n\\begin{aligned}\nI(f) - S_1 &\\approx  \\frac{16}{15} \\Big ( S_2 - S_1 \\Big ), \\\\\nI(f) - S_2 &\\approx  \\frac{1}{15} \\Big ( S_2 - S_1 \\Big ).\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\n\nInitialize by computing Simpson’s on \\([a,b]\\), i.e. \\(S_1\\)\nFor \\(i=1, 2, \\ldots\\)\n\nsubdivide the interval into 2 sub-regions and compute \\(S_{i+1}\\) by applying Simpson on each subinterval\nIf \\(|S_{i+1} - S_i | &lt; 15 \\epsilon\\)\n\nconverged\nelse repeat.",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Adaptive Quadrature</span>"
    ]
  },
  {
    "objectID": "NumIntAdaptive.html#summary",
    "href": "NumIntAdaptive.html#summary",
    "title": "25  Adaptive Quadrature",
    "section": "25.2 Summary",
    "text": "25.2 Summary\nThis is just a brief introduction into adaptive quadrature. There are many other techniques one can use to enhance both the accuracy and the efficiency of these methods. An interested reader, can find many references under topics such as adaptive mesh refinement.\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Numerical Integration (Quadrature)",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Adaptive Quadrature</span>"
    ]
  },
  {
    "objectID": "IVPODE.html",
    "href": "IVPODE.html",
    "title": "Initial-Value Problems for ODEs",
    "section": "",
    "text": "Initial-Value Problems for ODEs\nThe areas we will cover include:\n\nGeneral statement of Initial Value Problems, systems of ODEs, etc.\nEuler’s Method including a simple error analysis\nHigher-order methods\nMulti-step methods\n\nThe material on the existence and uniqueness of the IVP was moved to the Appendix, including:\n\nConcepts of Lipschitz continuity and convex sets\nFundamental Existence and Uniqueness of solutions to the IVP\nConcept of well-posed problems\n\nLet’s first start with a roadmap for the lectures to follow.\nAs we discussed in class last time, we will:\n\nbe mostly concerned with introducing methods for the solution of IVPs and providing advantages and disadvantages of them\nnot discuss problems that are ill-posed, stiff ODE’s, or have other structure\n\nOur reason for this particular focus is that there is a lot of good software available for these problems, so you may never need to actually implement one of these methods. Nevertheless, it will be important to know the differences between the methods, what types of problems they can be used on, and the pros and cons of each method.",
    "crumbs": [
      "Initial-Value Problems for ODEs"
    ]
  },
  {
    "objectID": "IVPEuler.html",
    "href": "IVPEuler.html",
    "title": "26  Euler’s Method",
    "section": "",
    "text": "26.1 Introduction\nThe scalar initial-value problem (IVP) has the form:\n\\[  y^{\\prime} = \\frac{dy}{dt} = f(t,y(t)), \\quad a \\leq t \\leq b, \\quad y(a) = \\alpha.  \\tag{26.1}\\]\nIn the general case, we would consider a system of ODEs, i.e.\n\\[  y^{\\prime} = \\frac{dy}{dt} = f(t,y), \\quad a \\leq t \\leq b, \\quad y(a) = \\alpha, \\]\nwhere \\[\ny^{\\prime} = \\begin{bmatrix} y^{\\prime}_1 \\\\ \\vdots \\\\ y^{\\prime}_n \\end{bmatrix} \\; f(t,y) = \\begin{bmatrix} f_1(t,y_1, \\ldots, y_n) \\\\ \\vdots \\\\ f_n(t,y_1, \\dots, y_n)\\end{bmatrix}\n\\tag{26.2}\\]\nSince all of the solution techniques we will study can be generalized to a system of ODEs, we will keep it simple for now and assume we have an IVP of the form given by Equation 26.1.\nReduction of higher-order ODE to a system of ODEs\nIt can be shown that a general n-th order ODE:\n\\[\ny^{(m)}(t) = f(t, y(t), y^{\\prime}(t), \\ldots, y^{(m-1)}(t)).\n\\] can be written in the form of a system of ODEs.",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Euler's Method</span>"
    ]
  },
  {
    "objectID": "IVPEuler.html#introduction",
    "href": "IVPEuler.html#introduction",
    "title": "26  Euler’s Method",
    "section": "",
    "text": "Example 26.1 Consider the simple second order IVP given by:\n\\[\ny^{\\prime\\prime} + a y^\\prime + by = f\n\\]\nIf we let:\n\\[\n\\begin{aligned}\ny_1 &= y \\\\\ny_2 &= y^\\prime \\\\\n\\end{aligned}\n\\]\nthen we can rewrite the IVP as two first order ODEs in the form of Equation 26.2:\n\\[\n\\begin{aligned}\ny_1^\\prime &= y_2 \\\\\ny_2^\\prime &= f - (ay_2 + by_1) .\n\\end{aligned}\n\\]\n\n\n\n\n\n\n\nAutonomous Systems\n\n\n\nAn IVP where the function \\(f\\) does not depend explicitly on \\(t\\) is said to be in autonomous form, i.e.\n\\[\ny^\\prime = f(y)\n\\]\nMany software packages for the solution of IVPs assume that the function is given in this form. This is generally achieved through the addition of an additional equation of the form \\(t^\\prime = 1\\).",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Euler's Method</span>"
    ]
  },
  {
    "objectID": "IVPEuler.html#eulers-method",
    "href": "IVPEuler.html#eulers-method",
    "title": "26  Euler’s Method",
    "section": "26.2 Euler’s Method",
    "text": "26.2 Euler’s Method\nWe will now present the simplest method for solving an IVP.\n\n\n\n\n\n\nNote\n\n\n\nFor the remainder of the discussion we will assume that our IVP is well-posed. See Section B.1 for details.\n\n\nRecall we are looking for solutions to the IVP:\n\\[  \\frac{dy}{dt} = f(t,y), \\quad a \\leq t \\leq b, \\quad y(a) = \\alpha .\\]\nAs in previous lectures, we will take an approach for numerically solving this problem by approximating it on a discrete grid.\nIn this case, the points are referred to as mesh points and are typically of the form:\n\\[\nt_i = a + ih, \\; i=0, 1, 2, \\ldots, N,\n\\]\nwhere the \\(t_i\\) are assumed to be equally spaced. Here, the distance between two consecutive points \\(t_{i+1} - t_i\\) is called the step size and is given by:\n\\[\nt_{i+1} - t_i = \\frac{(b-a)}{N} = h.\n\\]\n\n\n\n\n\n\n\nTerminology\n\n\n\nWe will denote the step size by \\(h\\). Many other references denote it by \\(\\Delta t\\) since we are usually referring to the time evolution of the IVP. Also note that the step size is sometimes called the time step, again in reference to the time variable.\n\n\n\nIn order to derive Euler’s method we can either make use of Taylor’s Theorem or just use the numerical approximation for the first derivative that we used in Section 19.1 : \\[\ny(t_{i+1}) = y(t_i) + h y^\\prime (t_i) + \\frac{h^2}{2} y^{\\prime\\prime} (\\xi_i) \\quad i = 0, 1, 2, \\ldots, N-1,\n\\]where \\(h = t_{i+1} - t_i\\), and \\(\\xi_i \\in [t_i, t_{i+1}]\\).\nNow remember that \\(y^{\\prime}\\) satifies the IVP. As a result, we can rewrite the above equation as:\n\\[\ny(t_{i+1}) = y(t_i) + h f(t_i, y(t_i)) + \\frac{h^2}{2} y^{\\prime\\prime} (\\xi_i)\n\\tag{26.3}\\] Taking the first 2 terms on the right hand side of this equation as our approximation to \\(y(t_{i+1})\\) leads us to propose the following algorithm, which we will call:\n\n\n\n\n\n\nEuler’s Method\n\n\n\n\\[\n\\begin{aligned}\ny_0 &= \\alpha \\\\\ny_{i+1} &= y_i + hf(t_i, y_i), \\quad i=0, 1, \\ldots, N-1\n\\end{aligned}\n\\tag{26.4}\\] Here \\(y_i \\approx y(t_i)\\).\n\n\nThis type of equation is known as a difference equation. You can think of it as being derived from a forward difference approximation to the derivative. Another interpretation is that it is the discretization (in time) of the continuous differential equation.\n\nExample 26.2 Solve the IVP given by: \\[\ny^\\prime = f(t,y) = y - t^2 + 1 \\quad y(0) = 0.5 \\quad 0 \\leq t \\leq 2,\n\\]\nwith \\(h = 0.5\\).\n\nI find it easier before I start, to write down a table with some of the important variables, where I can keep track of the steps. Something like the following is helpful:\n\nEuler Computations\n\n\n\\(i\\)\n\\(t_i\\)\n\\(y_i\\)\n\n\n\n\n0\n\\(t_0 = a\\)\n\\(y_0 = y(a)\\)\n\n\n1\n\\(t_1 = a + h\\)\n\\(y_1 = \\ldots\\)\n\n\n2\n\\(t_2 = a + 2h\\)\n\n\n\n3\n\n\n\n\n\\(\\ldots\\)\n\\(\\ldots\\)\n\\(\\ldots\\)\n\n\n\\(N\\)\n\\(t_N = b\\)\n\n\n\n\nI then fill in the initial conditions in the first row and as I compute subsequent \\(y_i\\) I fill in the table with those values.\nLet’s first code the function, specifically \\(f(t,y) = y - t^2+ 1\\). Note that this IVP has an exact solution given by \\((t+1)^2 - 0.5 \\exp(t)\\)\n\n\nCode\nftyex1 &lt;- function(t, y, pars) {\n  # Note that we don't use pars, so it's only here as a dummy parameter required by the ODE solver\n    yprime &lt;- y - t^2 + 1\n    return(list(c(yprime)))\n}\n# define the exact solution as well\nyexact &lt;- function(t,y) {\n    yexact &lt;- (t+1)^2 - 0.5*exp(t)\n    return(yexact)\n}\n\n\nLet’s now solve the IVP with a step size of \\(h = 0.5\\) using the built-in ODE solver with method chosen to be “euler”. We can also compute the true solution and the associated error generated by Euler’s method.\n\n\nCode\n# Call the ODE solver with several values for the initial condition\nlibrary(deSolve)\n\n# Set time integration limits and initial condition\na &lt;- 0\nb &lt;- 2\ny0 = 0.5\n\n# Set up the ode solver\nh &lt;- 0.5\nparms &lt;- c() # Set some of the parameters\ntimes1 &lt;- seq(a,b, by=h)   # Create the timestep mesh\ninit &lt;- c(y = y0)          # Set up the initial condition for the solver\n\nex1out0 &lt;- as.data.frame(ode(init, times1, ftyex1, parms, method = \"euler\"))\n\n# Compute exact solution for comparison\nytrue &lt;- data.frame(ex1out0$time,yexact(times1,0))\ncolnames(ytrue) &lt;- c(\"time\", \"y\")\nyerr &lt;- data.frame(ex1out0$time, abs(ytrue$y - ex1out0$y))\ncolnames(yerr) &lt;- c(\"time\", \"yerr\")\n\n\nThe table below summarizes the output from the ode solver and compares it to the exact solution. What do you notice about the error, especially as time increases?\n\nExact Solution versus Euler’s method Solution\n\n\n  time   ysol   yexact      yerr\n1  0.0 0.5000 0.500000 0.0000000\n2  0.5 1.2500 1.425639 0.1756394\n3  1.0 2.2500 2.640859 0.3908591\n4  1.5 3.3750 4.009155 0.6341555\n5  2.0 4.4375 5.305472 0.8679720\n\n\nLet’s plot the solution from Euler alongside the exact solution\n\n\n\n\n\nEuler’s method example\n\n\n\n\nLet’s explore what happens to the solutions by solving the IVP with several different initial conditions (see the plot below).\nOne immediate observation is that the IVP generates a family of solutions that can be parameterized by the specific initial condition chosen. In this case, also notice that the curves do not converge to a single line. What implications would this have on the solutions generated by Euler’s method? We’ll have more to say in later lectures on what is happening and what we can do to help us attain more accurate solutions.\n\n\n\n\n\nIVP with different ICs\n\n\n\n\n\nExercise 26.1 Solve the IVP given by:\n\\[\ny^\\prime = f(t,y) = 1 + (t - y)^2 \\quad y(2) = 1.0 \\quad 2 \\leq t \\leq 3\n\\]\nwith \\(h = 0.5\\) Fill out the table below with your calculations.\n\nSolution:\n\nIn class exercise\n\n\n\n\n\n\n\n\\(i\\)\n\\(\\quad \\quad t_i \\quad \\quad\\)\n\\(\\quad \\quad y_i \\quad \\quad\\)\n\n\n\n\n0\n\n\n\n\n1\n\n\n\n\n2\n\n\n\n\n3\n\n\n\n\n\\(\\ldots\\)\n\n\n\n\n\\(N\\)",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Euler's Method</span>"
    ]
  },
  {
    "objectID": "IVPEuler.html#backward-euler",
    "href": "IVPEuler.html#backward-euler",
    "title": "26  Euler’s Method",
    "section": "26.3 Backward Euler",
    "text": "26.3 Backward Euler\nWhat if we had used a backward difference formula to approximate the derivative of \\(y\\)? In other words:\n\\[\ny^\\prime(t_i) = \\frac{y(t_i) - y(t_{i-1})}{h} = f(t_i, y(t_i))\n\\]\nFollowing the same procedure as before we would have:\n\\[\ny(t_{i}) = y(t_{i-1}) + h f(t_i, y(t_i))\n\\]\nSince we really want to compute the approximation at the next time step, let’s shift the index by 1:\n\\[\ny(t_{i+1}) = y(t_{i}) + h f(t_{i+1}, y(t_{i+1}))\n\\]\nAgain, letting the approximation to the true solution be denoted by \\(y_i \\approx y(t_i)\\), leads to what is known as Backward Euler:\n\n\n\n\n\n\nBackward Euler\n\n\n\n\\[\n\\begin{aligned}\ny_0 &= \\alpha \\\\\ny_{i+1} &= y_i + hf(t_{i+1}, y_{i+1}), \\quad i=0, 1, \\ldots, N-1\n\\end{aligned}\n\\]\n\n\nThis seems like a straightforward alternative, but now notice that the computation of \\(y_{i+1}\\) will depend implicitly on itself since it appears on both the right and left hand sides of this equation. This type of method is known as an implicit method and will require some sort of iterative method to be able to compute the solution at the next time step.\n\n\n\n\n\n\nExplicit/Implicit Methods\n\n\n\n(Forward) Euler’s Method is an example of a type of method called an explicit method, because everything we need to compute a quantity at time \\(t_{i+1}\\) is given by known quantities at the previous time step \\(t_i.\\) Backward Euler on the other hand is an example of an implicit method since we have \\(y_{i+1}\\) on both sides of the equation. There are advantages and disadvantages to both approaches. In general, one can take longer timesteps with an implicit method. On the other hand, an implicit method will generally require the solution of a nonlinear system.",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Euler's Method</span>"
    ]
  },
  {
    "objectID": "IVPEuler.html#key-points",
    "href": "IVPEuler.html#key-points",
    "title": "26  Euler’s Method",
    "section": "26.4 Key Points",
    "text": "26.4 Key Points\n\nInitial Value Problems arise in many scientific and engineering problems\nEuler’s method can be used to solve the IVP by using a forward difference approximation to the derivative of \\(y\\).\nUsing the backward difference approximation yields a similar method, but requires having to solve the difference equation implicitly.\nForward Euler is easy to implement and relatively cheap.\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Euler's Method</span>"
    ]
  },
  {
    "objectID": "IVPEulerErrAny.html",
    "href": "IVPEulerErrAny.html",
    "title": "27  Error Analysis for Euler’s Method",
    "section": "",
    "text": "27.1 Error Analysis\nIn order to discuss the error in Euler’s method as well as its convergence, we will need to define a few terms.\nFirst let’s recall that we are seeking to approximate the solution to the IVP at a set of discrete points in time or mesh points typically of the form:\n\\[\nt_i = a + ih, \\; i=0, 1, 2, \\ldots, N.\n\\]\nWe start with a few definitions.",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Error Analysis for Euler's Method</span>"
    ]
  },
  {
    "objectID": "IVPEulerErrAny.html#error-analysis",
    "href": "IVPEulerErrAny.html#error-analysis",
    "title": "27  Error Analysis for Euler’s Method",
    "section": "",
    "text": "Definition 27.1 The difference method\n\\[\n\\begin{aligned}\ny_0 &= \\alpha \\\\\ny_{i+1} &= y_i + h \\phi(t_i, y_i), \\quad i=0, 1, \\ldots, N-1\n\\end{aligned}\n\\] has local truncation error\n\\[\nd_{i+1} = \\frac{y_{i+1} - (y_i + h \\phi(t_i,y_i))}{h},\n\\]where \\(y_i\\) denotes the solution of the difference equation at \\(t_i\\), and \\(\\phi(t,y)\\) is a given function.\nWe say that a method is consistent (or accurate) of order \\(q\\) if \\(q\\) is the lowest positive integer such that\n\\[\n\\max_i \\ |d_i | = O(h^q).\n\\]\nFinally, the global error is defined as\n\\[\ne_i = y(t_i) - y_i \\quad i=0, 1, \\ldots N,\n\\] where \\(y(t_i)\\) is the true solution at time, \\(t_i\\).\n\n\nExample 27.1 Show that Euler’s method has local truncation error of \\(O(h)\\).\nFor Euler’s method (Equation 26.4) \\(\\phi(t_i, y_i) = f(t_i,y_i)\\). As such we can write the local truncation error as:\n\\[\n\\begin{aligned}\nd_{i+1} &= \\frac{y_{i+1} - (y_i + h \\phi(t_i,y_i))}{h} ,\\\\\n&= \\frac{h}{2} y^{\\prime\\prime} (\\xi_i), \\quad \\xi_i \\in (t_i, t_{i+1}),\n\\end{aligned}\n\\tag{27.1}\\] where the second equation is as a result of Equation 26.3. If we assume that the second derivative of \\(y\\) is bounded by some constant \\(M\\), then we have: \\[\n\\begin{aligned}\n| d_{i+1} | &\\leq \\frac{h}{2} M ,\\\\\n\\\\\n\\implies d_{i+1} &= O(h) \\implies \\mbox{Euler is first order accurate},\n\\end{aligned}\n\\] and hence the local truncation error is \\(O(h)\\).\nRemark: We call \\(d_{i+1}\\)local because it measures the accuracy of the solution at a specific point (step) in time. Notice also that the error will depend on 1) the ODE, and 2) the step size.\nBy the same argument, it is easy to see that Backward Euler is also first order accurate.",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Error Analysis for Euler's Method</span>"
    ]
  },
  {
    "objectID": "IVPEulerErrAny.html#convergence-and-global-error-estimates",
    "href": "IVPEulerErrAny.html#convergence-and-global-error-estimates",
    "title": "27  Error Analysis for Euler’s Method",
    "section": "27.2 Convergence and Global Error Estimates",
    "text": "27.2 Convergence and Global Error Estimates\nWe now state a theorem that provides error bounds on the approximations generated by Euler’s method.\n\nTheorem 27.1 (Euler Method Convergence.) Suppose \\(f(t,y)\\) is continuous and Lipschitz continuous in \\(y\\), with constant \\(L\\) on a region \\(D = \\{ (t,y) | \\ a \\leq t \\leq b, \\ -\\infty &lt; y &lt; \\infty \\}\\).\nLet \\(y_1, \\ldots, y_N\\) be approximations generated by Euler’s method for some integer \\(N &gt; 0.\\) Then Euler’s method converges and its global error decreases linearly in \\(h\\).\nFurthermore if a constant \\(M\\) exists with\n\\[\n| y^{\\prime \\prime} | \\leq M \\quad \\forall t \\in [a,b],\n\\] then the global error satisfies\n\\[\n| e_i | \\leq \\frac{hM}{2L} \\left[ e^{L(t_i-a)} - 1 \\right] \\; \\forall i=0, 1, 2, \\ldots, N\n\\tag{27.2}\\]\n\n\nProof. See Section 27.4\n\nLet’s take a quick look to see what the error bound is saying.\nNote that:\n\nthe bound is exactly zero for \\(t_i = a\\), which makes sense since \\(y_0 = y(a)\\), the given initial condition.\nthe last term depends on the Lipschitz constant, as well as the term \\(t_i - a\\). But \\(t_i-a\\) is bounded by \\(b-a\\), so the entire term is also bounded.\nThe bound depends on both the Lipschitz constant as well as the bound, \\(M\\), on the second derivative of \\(y(t)\\).\nthe error bound is linear in \\(h\\).\n\nTo summarize: the good news is that we can bound the error at each time step. Nonetheless it is clear that the error bound will increase at each time step \\(t_i\\). Our hope is that by choosing a small enough \\(h\\) we can compensate for the other terms and make the error bound small enough to generate an accurate approximation to \\(y(t)\\).\n\n\n\n\n\n\nRemark\n\n\n\nNote that the theorem requires a bound on the second derivative. We can sometimes use some knowledge of the partial derivatives to obtain an error bound. The important aspect is that the error bounds are linear in \\(h\\). Not surprisingly, as the number of computations grow so will the roundoff error.",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Error Analysis for Euler's Method</span>"
    ]
  },
  {
    "objectID": "IVPEulerErrAny.html#roundoff-error-analysis",
    "href": "IVPEulerErrAny.html#roundoff-error-analysis",
    "title": "27  Error Analysis for Euler’s Method",
    "section": "27.3 Roundoff Error Analysis",
    "text": "27.3 Roundoff Error Analysis\n\n\n\n\n\n\nAdvanced\n\n\n\nThis section was not discussed in class, but follows the textbook closely.)\n\n\nAs in the numerical differentiation lectures, we can derive an error analysis that includes the roundoff error. This leads us to the following error bound:\n\\[\n| y(t_i) - y_i | \\leq \\frac{1}{L} \\left( \\frac{hM}{2} + \\frac{\\delta}{h} \\right) \\left[ e^{L(t_i-a)} - 1 \\right] + |\\delta_0| e^{L(t_i-a)},\n\\]\nwhere \\(\\delta, \\delta_0\\) are constants representing the amount of roundoff error incurred at each time step.\nNotice that we have the same situation as before with numerical differentiation – one of the terms is going to \\(0\\) while the second term blows up as \\(h \\rightarrow 0\\).\nA similar type of calculation as in the case of numerical differentiation, yields an optimal \\(h\\):\n\\[\nh = \\sqrt \\frac{2\\delta}{M}\n\\]\nthat will depend on both \\(\\delta\\) and \\(M\\). If we assume that \\(\\delta \\approx \\epsilon\\), i.e machine epsilon, then depending on the value of \\(M\\), this implies \\(h\\) should be roughly the square root of machine epsilon. For IVPs, the more important question is stability, which will depend on choosing an appropriate \\(h.\\) Unfortunately, we don’t have time to cover that topic here.",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Error Analysis for Euler's Method</span>"
    ]
  },
  {
    "objectID": "IVPEulerErrAny.html#sec-ivpeulerconvg",
    "href": "IVPEulerErrAny.html#sec-ivpeulerconvg",
    "title": "27  Error Analysis for Euler’s Method",
    "section": "27.4 Proof of Convergence for Euler’s Method",
    "text": "27.4 Proof of Convergence for Euler’s Method\nWe had to bypass the proof of the convergence of Euler’s method. It is not a difficult proof and it uses standard techniques. If you’re interested this section will provide a brief overview of the proof.\nFirst, we will need a few lemmas that are used in the proof of the convergence of Euler’s method. They are included here for completeness.\nLemma 5.7. For all \\(x \\geq 1\\) and any positive \\(m\\) we have\n\\[\n0 \\leq (1 + x)^m \\leq e^{mx}\n\\tag{27.3}\\]\nProof. Straightforward application of Taylor’s Theorem to \\(f(x) = e^x\\) about \\(x_0 = 0\\).\nLemma 5.8. If\n\n\\(s,t\\) are positive real numbers\n\\(\\{a_i\\}_{i=0}^{k}\\) is a sequence satisfying \\(a_0 \\geq -\\frac{t}{s}\\)\n\\(a_{i+1} \\leq (i+s) a_i + t \\quad i=0, 1, \\ldots, k-1\\)\n\nThen\n\\[\na_{i+1} \\leq e^{(i+1)s} ( a_0 + \\frac{t}{s}) - \\frac{t}{s} .\n\\]\nProof. Left as an exercise. In case you’re interested in trying to prove it, the idea is to use a geometric series to show that under our assumptions that\n\\[\na_{i+1} \\leq (i+s)^{i+1}  ( a_0 + \\frac{t}{s}) - \\frac{t}{s}\n\\]\nfollowed by an application of Equation 27.3, with \\(x = s\\) to show result.\n\nProof. Convergence for Euler’s method Theorem 27.1.\nA method is said to converge if the maximum global error tends to 0 as \\(h\\) tends to 0 (assuming that an exact solution exists and is sufficiently smooth. For Euler’ method, which is \\(O(h)\\), we would then expect that \\(e_i = y(t_i) - y_i\\) should be of the same order.\nLet’s consider the local truncation error first:\n\n\\[\n\\begin{aligned}\nd_{i} &= \\frac{y(t_{i+1}) - y(t_i)}{h} - f(t_i,y(t_i)),\\\\\n0 &= \\frac{y_{i+1} - y_i}{h} - f(t_i,y_i),\n\\end{aligned}\n\\]\nSubtracting the two, gives us a difference formula for the local truncation error:\n\\[\nd_{i} = \\frac{e_{i+1} - e_i}{h} - \\left [ f(t_i,y(t_i))-f(t_i,y_i) \\right ]\n\\]\nSolving for the error at \\(t_{i+1}\\), we have:\n\\[\ne_{i+1} = e_i  + h\\left [ f(t_i,y(t_i))-f(t_i,y_i) \\right ] +hd_{i}\n\\]\nNow taking absolute values:\n\\[\n| e_{i+1} | \\leq | e_i | + h |\\left [ f(t_i,y(t_i))-f(t_i,y_i) \\right ] | + |hd|,\n\\]where \\(d\\) is the maximum of \\(|d_i|\\) over all time steps.\n\nSince \\(f\\) is Lipschitz continuous with constant L, we can simplify the error difference equation to:\n\\[\n\\begin{aligned}\n| e_{i+1} | &\\leq | e_i | + h L |e_i| + |hd|, \\\\\n& \\leq (1 + hL) | e_i | + hd.\n\\end{aligned}\n\\]\nAlmost there (hang in there) …\nNow note that we can do the same estimate with \\(e_i\\), which would gives us:\n\\[\n\\begin{aligned}\n| e_{i+1} | &\\leq (1 + hL) | e_i | + hd, \\\\\n&\\leq (1 + hL) [(1 + hL) | e_{i-1} + hd | + hd = (1 + hL)^2 |e_{i-1}| + (1 + hL) hd + hd \\\\\n&\\leq \\cdots \\leq (1 + hL)^{i-1} |e_{0}| + hd \\sum_{j=0}^{i} (1 + hL)^j \\\\\n&\\leq d \\left[ e^{L(t_i-a)} - 1 \\right]/ L\n\\end{aligned},\n\\] where we’ve used the Lemmas above to compute the sum and the fact that \\(e_0 = 0\\).\nThe final step is to note that by definition of we have that:\n\\[\n\\begin{aligned}\nd &\\geq \\max_{0\\leq i \\leq N-1 }| d_i| \\\\\nd_i &= \\frac{h}{2} y^{\\prime\\prime} (\\xi_i)\n\\end{aligned}\n\\]\nSo if we can bound the second derivative such that:\n\\[\nM = \\max_{a\\leq t \\leq b } | y^{\\prime\\prime} (t) |,\n\\]then we can set\n\\[\nd = \\frac{h}{2}M.\n\\]\nwhich gives us our desired error bound:\n\\[\n| e_{i} |  \\leq \\frac{Mh}{2L} \\left[ e^{L(t_i-a)} - 1 \\right], \\quad i=0,1, \\ldots, N.\n\\]\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Error Analysis for Euler's Method</span>"
    ]
  },
  {
    "objectID": "IVPHigherOrder.html",
    "href": "IVPHigherOrder.html",
    "title": "28  Higher-order Methods",
    "section": "",
    "text": "28.1 Higher-order Taylor Methods\nIn a similar vein to what we did to derive Euler’s method, we can derive higher-order methods by extending the Taylor series approximation to include the higher derivatives. This will yield methods that are more accurate, but at a cost of having to compute the higher derivatives.\nThere will always be a tradeoff between higher accuracy methods and computational cost. Here computational cost is usually measured in terms of function evaluations. This is important to remember because in a real-world problem each function evaluation could cost hours of computer time.\nWe note in passing that while higher-order Taylor methods can be generated, they are rarely used in practice, as the requirement of having higher-order derivatives is rarely met in real-world problems.\nLet’s start by writing down the Taylor series expansion of \\(y(t)\\) about the current time step.\n\\[\n\\begin{aligned}\ny(t_{i+1}) &= y(t_i)+ h y^{\\prime}(t_i) + \\frac{h^2}{2} y^{\\prime\\prime}(t_i) + \\ldots + \\\\ & \\frac{h^{(n)}}{n!} y^{(n)}(t_i) + \\frac{h^{(n+1)}}{(n+1)!} y^{(n+1)}(\\xi_i),  \\; \\xi_i \\in [t+i, i_{i+1} ]\n\\end{aligned}\n\\]\nUsing the statement of the IVP, we know that \\(y^\\prime = f(t,y)\\), so we can replace the derivatives of \\(y\\) by the corresponding derivative of \\(f(t,y)\\)\nThis leads to: \\[\n\\begin{aligned}\ny(t_{i+1}) &= y(t_i)+ h f(t_i,y(t_i)) + \\frac{h^2}{2} f^{\\prime}(t_i,y(t_i)) + \\ldots + \\\\ & \\frac{h^{(n)}}{n!} f^{(n-1)}(t_i,y(t_i)) + \\frac{h^{(n+1)}}{(n+1)!} f^{(n)}(t_i,y(t_i)),  \\; \\xi_i \\in [t+i, i_{i+1} ]\n\\end{aligned}\n\\]\nFor convenience let’s denote the function \\(T^{(n)}\\) as: \\[\nT^{(n)} = f(t_i,y(t_i)) + \\frac{h}{2} f^{\\prime}(t_i,y(t_i)) + \\ldots + \\frac{h^{(n-1)}}{n!} f^{(n-1)}(t_i,y(t_i)).\n\\]In a manner similar to Euler’s method, this leads us to propose the following algorithm for higher-order Taylor methods\n\\[\n\\begin{aligned}\ny_0 &= \\alpha \\\\\ny_{i+1} &= y_i + h T^{(n)}(t_i, y_i), \\; i=0, 1, \\ldots, N-1.\n\\end{aligned}\n\\]\nRemark: Clearly Euler’s method is the special case of \\(n=1\\).\nRemark: Also, by the definition of the local truncation error, we can see that the higher-order Taylor method will have a local truncation error of \\(O(h^n)\\), using the same argument that we used for Euler’s method.\nFor example, if we wanted to have a second order method, we would use \\(T^{(2)}\\) in our difference equation:\n\\[\nT^{(2)} = f(t_i,y(t_i)) + \\frac{h}{2} f^{\\prime}(t_i,y(t_i))\n\\]",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Higher-order Methods</span>"
    ]
  },
  {
    "objectID": "IVPHigherOrder.html#higher-order-taylor-methods",
    "href": "IVPHigherOrder.html#higher-order-taylor-methods",
    "title": "28  Higher-order Methods",
    "section": "",
    "text": "Idea\n\n\n\nIf Euler’s method used a Taylor series expansion truncated after the first derivative (i.e. \\(n=1\\)), let’s try higher values of \\(n\\).",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Higher-order Methods</span>"
    ]
  },
  {
    "objectID": "IVPHigherOrder.html#runge-kutta-order-2-methods",
    "href": "IVPHigherOrder.html#runge-kutta-order-2-methods",
    "title": "28  Higher-order Methods",
    "section": "28.2 Runge-Kutta Order 2 Methods",
    "text": "28.2 Runge-Kutta Order 2 Methods\nAnother approach we can use leads to the well-known class of Runge-Kutta methods.\n\n\n\n\n\n\nIdea\n\n\n\nThe idea for the Runge-Kutta methods is to have the high-order local truncation error of Taylor methods without the need to compute and evaluate the derivatives of \\(f(t,y)\\). Ideally, we should only need function evaluations.\n\n\nLet’s first rewrite the IVP as an integral:\n\\[\ny(t_{i+1}) = y(t_i) + \\int_{t_i}^{t_{i+1}} f(t,y(t))dt.\n\\]\nOne simple idea is to now use our methods from the numerical integration sections to evaluate the integral, for example the Trapezoid rule:\n\\[\ny_{i+1} = y_i + \\frac{h}{2}( f(t_i,y_i)+ f(t_{i+1},y_{i+1})).\n\\tag{28.1}\\]\nAs with our discussion of Backward Euler, we can see that this is an implicit equation as \\(y_{i+1}\\) is both on the right and left hand sides of the equation and would require the solution of a nonlinear equation.\nBut what if we could approximate the value of \\(y_{i+1}\\) on the right hand side with an explicit method? Since we only know one explicit method (Euler’s method), let’s try it out and see what happens.\nLet’s define:\n\\[\nY = y_i + h f(t_i,y_i),\n\\]\nand substitute \\(Y\\) for \\(y_{i+1}\\) into Equation 28.1:\n\\[\ny_{i+1} = y_i + \\frac{h}{2}( f(t_i,y_i)+ f(t_{i+1},Y)).\n\\]\nThis equation is known as the explicit trapezoidal method. This method is also known as a two-stage method - the second stage comes about because we have to evaluate the function at a second point, namely \\(f(t_{i+1},Y).\\) We can summarize this by the following steps:\n\n\n\n\n\n\nExplicit Trapezoid\n\n\n\n\\[\n\\begin{aligned}\nY  &= y_i + hf(t_i,y_i) \\\\\ny_{i+1} &= y_i + \\frac{h}{2}(f(t_i,y_i)  + f(t_{i+1},Y)) \\\\\n\\end{aligned}\n\\tag{28.2}\\]\n\n\nIt can be shown that this method is second order accurate.\nA similar process but using the midpoint rule instead of the trapezoid rule will also work and yields the following two-stage algorithm, known as the explicit midpoint method:\n\n\n\n\n\n\nExplicit Midpoint\n\n\n\n\\[\n\\begin{aligned}\nY &= y_i + \\frac{h}{2} f(t_i,y_i) \\\\\ny_{i+1} &= y_i + h f(t_{i+1/2},Y)  \\\\\n\\end{aligned}\n\\tag{28.3}\\]\n\n\n\n\n\n\n\n\nProgramming Tip\n\n\n\nWhen coding the algorithms above, for example the explicit trapezoidal method, the algorithm is usually stated in terms of the following:\n\\[\n\\begin{aligned}\nk_1 &= f(t_i,y_i) \\\\\nk_2 &= f(t_{i+1},y_i+ hk_1) \\\\\ny_{i+1} &= y_i + \\frac{h}{2}( k_1 + k_2) \\\\\n\\end{aligned}\n\\]\nYou should convince yourself that these are the same.",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Higher-order Methods</span>"
    ]
  },
  {
    "objectID": "IVPHigherOrder.html#runge-kutta-order-4",
    "href": "IVPHigherOrder.html#runge-kutta-order-4",
    "title": "28  Higher-order Methods",
    "section": "28.3 Runge Kutta Order 4",
    "text": "28.3 Runge Kutta Order 4\nWe can derive higher-order Runge-Kutta methods using similar techniques. One of the most popular is the 4th order method, which can be written as:\n\n\\[\n\\begin{aligned}\nk_1 &= f(t_i, y_i), \\\\\nk_2 &= f(t_{i+1/2}, y_i + \\frac{h}{2}k_1), \\\\\nk_3 &= f(t_{i + 1/2}, y_i + \\frac{h}{2}k_2), \\\\\nk_4 &= f(t_{i+1}, y_i + hk_3), \\\\\ny_{i+1} &= y_i + \\frac{h}{6} (k_1 + 2k_2 + 2k_3 + k_4) .\n\\end{aligned}\n\\]\n\nAs the name implies, this method is \\(O(h^4)\\).\n\nExample 28.1 Solve our favorite IVP problem using the Explicit Midpoint Method and the Explicit Trapezoidal method. \\[\n\\begin{aligned}\ny^{\\prime} &= y - t^2 + 1, \\quad 0 \\leq t \\leq 2 \\\\\ny(0) &= 0.5\n\\end{aligned}\n\\]\nNote: The complete worked out example for both methods can be found in the notebook Math130-IVP-RK.Rmd. Include Rmd file here???",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Higher-order Methods</span>"
    ]
  },
  {
    "objectID": "IVPHigherOrder.html#summary",
    "href": "IVPHigherOrder.html#summary",
    "title": "28  Higher-order Methods",
    "section": "28.4 Summary",
    "text": "28.4 Summary\n\nHigher-order Taylor methods can be derived, extending the accuracy of Euler’s method, although these methods are rarely use in practice.\nAnother approach is to use the same idea but replace higher derivatives of \\(f\\) with other approximations.\nLeads to multi-stage methods such as explicit Trapezoidal, explicit midpoint methods and the widely used and popular class of methods known as Runge-Kutta methods.\nChoosing a good method will depend on the problem, how smooth the functions are, and the desired accuracy.",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Higher-order Methods</span>"
    ]
  },
  {
    "objectID": "IVPHigherOrder.html#general-form-for-runge-kutta-methods",
    "href": "IVPHigherOrder.html#general-form-for-runge-kutta-methods",
    "title": "28  Higher-order Methods",
    "section": "28.5 General form for Runge Kutta methods",
    "text": "28.5 General form for Runge Kutta methods\n\n\n\n\n\n\nAdvanced - not covered in class\n\n\n\n\n\n\nThe general form of the Runge-Kutta equations with \\(s\\) stages is given by:\n\\[\ny_{i+1} = y_i + h \\sum_{j=1}^{s} b_j k_j,\n\\tag{28.4}\\]\nwhere the \\(k_i\\) terms are given by:\n\\[\n\\begin{aligned}\nk_1 &= f(t_i, y_i), \\\\\nk_2 &= f(t_i + h c_2, y_i + a_{21} k_1), \\\\\nk_3 &= f(t_i + h c_3, y_i + a_{31} k_1 + a_{32} k_2), \\\\\n& \\vdots \\\\\nk_s &= f(t_i + h c_s, y_i + a_{s1} k_1 + a_{s2} k_2+ \\ldots + a_{s,s-1} k_{s-1}), \\\\\n\\end{aligned}\n\\tag{28.5}\\]\nThe coefficients, \\(a_{ij}, b_i, c_i\\), are determined by the process we introduced earlier that compares partial derivatives.\nIn addition, for consistency, we ask that the coefficients satisfy the equations: \\[\n\\sum_{j=1}^{i-1} a_{ij} = c_i, \\quad i =2, \\ldots, s\n\\] and \\[\n\\sum_{j=1}^{s} b_{j} = 1,\n\\]\nAn easy way to visualize the coefficients is to use the Butcher tableau: \\[\n\\begin{array}{c|c}\nc & A \\\\\n\\hline\n& b^T\n\\end{array}\n\\]\nwhere \\(c, b\\) are vectors of coefficients, and \\(A\\) is a matrix of coefficients, as defined in Equation 28.4 and Equation 28.5.\nUsing this tableau, we can, for example, summarize the formula for the Runge-Kutta method of order 2 (RK2) as: \\[\n\\begin{array}{c|l}\n0 & 0 \\\\\n\\frac{1}{2} & \\frac{1}{2} \\quad 0\\\\\n\\hline\n& 0 \\quad \\;1\n\\end{array}\n\\] Substituting into Equation 28.5 yields the formulas:\n\\[\n\\begin{aligned}\nk_1 &= f(t_i, y_i), \\\\\nk_2 &= f(t_i + \\frac{1}{2}h, y_i + \\frac{1}{2}h k_1), \\\\\ny_{i+1} &= y_i + hk_2 .\n\\end{aligned}\n\\]\nWe can also derive a similar set of formulas for a Runge-Kutta method with 4 stages that will yield a method of \\(O(h^4)\\). The corresponding tableau is given by.\n\\[\n\\begin{array}{c|l}\n0 & 0 \\\\\n\\frac{1}{2} & \\frac{1}{2} \\; 0\\\\\n\\frac{1}{2} & 0 \\;\\; \\frac{1}{2} \\; 0 \\\\\n1 & 0 \\; \\; 0 \\;\\; 1 \\;\\; 0 \\\\\n\\hline\n& \\frac{1}{6} \\; \\frac{1}{3} \\;\\frac{1}{3} \\;\\frac{1}{6} \\\\\n\\end{array}\n\\] Again, substituting into Equation 28.5, yields the Runge-Kutta method of order 4:\n\\[\n\\begin{aligned}\nk_1 &= f(t_i, y_i), \\\\\nk_2 &= f(t_i + \\frac{1}{2}h, y_i + \\frac{1}{2}h k_1), \\\\\nk_3 &= f(t_i + \\frac{1}{2}h, y_i + \\frac{1}{2}hk_2), \\\\\nk_4 &= f(t_i + h, y_i + hk_3), \\\\\ny_{i+1} &= y_i + \\frac{1}{6}h (k_1 + 2k_2 + 2k_3 + k_4) .\n\\end{aligned}\n\\]\nRecall that our goal was to replace the need for higher order derivatives while retaining the higher order local discretization error. The price we had to pay was in the form of extra function evaluations.\nIn the case of RK-2, it was an additional 2 function evaluations. For RK-4, it was 4 extra function evaluations. It can be shown that the following relationship holds between the additional function evaluations and the local discretization error holds for Runge-Kutta methods:\n\nFunction Evals vs. Local Error\n\n\nFunction Evaluations\nLocal Discretization Error\n\n\n\n\n\\(2\\)\n\\(O(h^2)\\)\n\n\n\\(3\\)\n\\(O(h^3)\\)\n\n\n\\(4\\)\n\\(O(h^4)\\)\n\n\n\\(5 \\leq n \\leq 7\\)\n\\(O(h^{n-1})\\)\n\n\n\\(8 \\leq n \\leq 9\\)\n\\(O(h^{n-2})\\)\n\n\n\\(10 \\leq n\\)\n\\(O(h^{n-3})\\)\n\n\n\nAs you can see, when \\(n&gt;4\\), there is no big advantage to increasing the order in terms of increasing the order of the local discretization error. As a consequence, the most popular of the Runge-Kutta methods is the one of order \\(4\\).\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Higher-order Methods</span>"
    ]
  },
  {
    "objectID": "IVPMultistep.html",
    "href": "IVPMultistep.html",
    "title": "29  Multi-Step Methods for IVP",
    "section": "",
    "text": "29.1 Motivation\nAll the methods so far belong to a class of methods known as one-step methods, which is to say that all of the information used in the computation of the approximation at the next time step only used information from the immediately prior time step.\nHowever, you might ask yourself, can we use information from other previous steps to improve our approximation. This would be especially useful in the case when each of the function evaluations are computationally expensive. This leads us to proposing a set of methods that attempt to take advantage of all of this additional information already available to us.\nLet’s first start with some notation and a definition. As before, let’s assume that we have equally spaced time steps such that \\(t_i = a + ih, i=0, 1, N.\\)\nDefinition: an s-step linear multistep method for solving the IVP has a difference equation of the form:\n\\[\n\\begin{aligned}\n\\sum_{j=0}^{s} \\alpha_j y_{i+1-j}  = h\\sum_{j=0}^{s} \\beta_j f_{i+1-j},\n\\end{aligned}\n\\tag{29.1}\\] where we let \\(f_{i+1-j} = f(t_{i+1-j},y_{i+1-j})\\). Without loss of generality, we can assume that \\(\\alpha_0 = 1\\) since we can rescale all of the equations.\nIt will also be useful to distinguish between cases that need the function value \\(f(t_{i+1},y_{i+1})\\) at the next time step to compute \\(y_{i+1}\\). In particular, if \\(b_0 = 0\\) the method is called an explicit (open) method and we can write Equation 29.1 as:\n\\[\n\\begin{aligned}\ny_{i+1} = -\\sum_{j=1}^{s} \\alpha_j y_{i+1-j} + h\\sum_{j=1}^{s} \\beta_j f_{i+1-j}\n\\end{aligned}\n\\]\nNotice that we can recover Euler’s method from the explicit form of this equation by setting \\(\\beta_0 = 0, s=1, \\alpha_1 = -1, \\beta_1 =1.\\)\nThe second case is if we let \\(b_0 \\neq 0\\) and the method is then called implicit (closed) as \\(y_{i+1}\\) appears on both sides of Equation 29.1 so it is only implicitly defined.\n\\[\n\\begin{aligned}\ny_{i+1} - h \\beta_0 f_{i+1}= -\\sum_{j=1}^{s} \\alpha_j y_{i+1-j} + h\\sum_{j=1}^{s} \\beta_j f_{i+1-j}\n\\end{aligned}\n\\]\nHow then should be develop higher-order formulas for solving the IVP. We’ve already decided that it would be good to use some of the past information and in particular, we should try to use the past values of \\(y_i\\) that we have already computed. This leads to the following idea:\nThere are many methods one could use to solve the IVP and we will give examples of several of the more popular multi-step methods including the Adams-Bashforth (explicit) and Adams-Moulton (implicit) methods. We will not derive the following methods here, but if you’re interested we give a brief derivation in the supplemental section Section 29.4.\nAdams-Bashforth fourth-order\n\\[\n\\begin{aligned}\ny_0 &= \\alpha_0, \\; y_1 = \\alpha_1, \\; y_2 = \\alpha_2, \\; y_3 = \\alpha_3, \\\\\ny_{i+1} & =  y_{i} + \\frac{h}{24} \\left[ 55 f(t_{i}, y_{i}) -  59 f(t_{i-1}, y_{i-1}) + 37 f(t_{i-2}, y_{i-2}) - 9 f(t_{i-3}, y_{i-3}) \\right]\n\\end{aligned}\n\\]\nAdams-Moulton fourth-order\n\\[\n\\begin{aligned}\ny_0 &= \\alpha_0, \\; y_1 = \\alpha_1, \\; y_2 = \\alpha_2, \\\\\ny_{i+1} & =  y_{i} + \\frac{h}{24} \\left[ 9 f(t_{i+1}, y_{i+1}) + 19 f(t_{i}, y_{i}) -  5 f(t_{i-1}, y_{i-1}) + f(t_{i-2}, y_{i-2}) \\right]\n\\end{aligned}\n\\]",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Multi-Step Methods for IVP</span>"
    ]
  },
  {
    "objectID": "IVPMultistep.html#motivation",
    "href": "IVPMultistep.html#motivation",
    "title": "29  Multi-Step Methods for IVP",
    "section": "",
    "text": "Remark\n\n\n\nIn general implicit methods are more accurate than explicit methods and we can get by with larger time steps. The disadvantage is that we need to solve a system of linear (or nonlinear) equations at each time step. Additionally, the solution may not be unique (or even exist).\n\n\n\n\n\n\n\n\n\nIdea\n\n\n\nUse some number of past values of \\(y_i\\) (e.g. \\(y_i, y_{i-1}, y_{i-2}, \\ldots )\\) to fit an interpolating polynomial to \\(f\\), which can then be used to derive a higher order method using techniques similar to the ones we used to derive the multi-stage (i.e. Explicit Trapezoid, Runge-Kutta, etc.) methods\n\n\n\n\n\nMulti-step method uses past computed values\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemark\n\n\n\nNote that in both cases, one needs to supply additional initial values. For example, in the case of Adams-Bashforth fourth-order method, we need to have 4 initial values in total. These are usually computed through an explicit method, for example a Runge-Kutta method.",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Multi-Step Methods for IVP</span>"
    ]
  },
  {
    "objectID": "IVPMultistep.html#demo-basic-sir-model",
    "href": "IVPMultistep.html#demo-basic-sir-model",
    "title": "29  Multi-Step Methods for IVP",
    "section": "29.2 Demo: Basic SIR Model",
    "text": "29.2 Demo: Basic SIR Model\nWe demonstrated the use of a simple ODE/IVP solver by solving a problem of predicting the breakout of an epidemic using data from Merced County COVID cases taken from: USA Facts Merced County, California coronavirus cases and deaths\nTo model an epidemic of an infectious disease, the usual approach is to use what is known as the SIR Model.\nThe SIR equations are given by: \\[\\begin{aligned}\\frac{dS}{dt} &= - \\alpha S I  \\\\\\frac{dI}{dt} &= \\alpha S I - \\gamma I \\\\\\frac{dR}{dt} &= \\gamma I \\\\N &= S + I + R\\end{aligned}\n\\] where \\(S\\) is the number of susceptible (healthy) individuals, \\(I\\) represents the number of infected individuals, \\(R\\) is the number of people who have recovered from the disease, and \\(N\\) is the total population.\nThe demo we presented had 4 parameters you can play with: initial population (N), the number of days to run the simulation for, and the 2 parameters that represent the rates between susceptible and infected (\\(\\alpha\\)) and between infected and recovered (\\(\\gamma\\)).\nThe solver used comes from the deSolve package in R called ode. The default solver is “lsoda” (Petzold & Hindmarsh), but other choices are available. Calling the ode solver requires the initial conditions (init), the times at which to compute the solution (times, the function to evaluate the ode (sir in this case), and a list of parameters that the ode solver passes along to the ode function.\nThe original data taken from the site gave us the following plot:\n\n\n\nMerced County Covid Cases (weekly average)\n\n\nIn the demo, we played around with the parameters for the SIR model to match the data as best we could. According to the model, the basic Reproduction number \\(R_0 = 8.5.\\) For comparison, for measles one of the more contagious diseases, \\(R_0 = 12-18\\) while the normal flu has \\(R_0 \\approx 1.28\\).\n\n\n\nSIR demo using Merced County data",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Multi-Step Methods for IVP</span>"
    ]
  },
  {
    "objectID": "IVPMultistep.html#summary-of-methods-studied",
    "href": "IVPMultistep.html#summary-of-methods-studied",
    "title": "29  Multi-Step Methods for IVP",
    "section": "29.3 Summary of Methods Studied",
    "text": "29.3 Summary of Methods Studied\nLet’s take a step back and summarize our main results:\n\nComparison of Different Solution Methods for IVP\n\n\n\n\n\n\n\n\nMethod\nLocal Truncation Error\nExplicit/Implicit\nStability\n\n\n\n\nEuler\n\\(\\frac{hM}{2L} \\left[ e^{L(t_i-a)} - 1 \\right]\\)\nE\n\n\n\nBackward Euler\n\\(O(h)\\)\nI\n\n\n\nHigher Order Taylor\n\\(O(h^n)\\)\nE\n\n\n\nMidpoint\n\\(O(h^2)\\)\nE\n\n\n\nRunge-Kutta Order 2\n\\(O(h^2)\\)\nE\n\n\n\nRunge-Kutta Order 4\n\\(O(h^4)\\)\nE\n\n\n\nAdams-Bashforth\n\\(O(h^4)\\)\nE\n\n\n\nAdams-Moulton\n\\(O(h^4)\\)\nI\n\n\n\n\nWe did not talk much about the stability of the algorithms, but this will prove to be an important characteristic of any method we choose for an IVP.",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Multi-Step Methods for IVP</span>"
    ]
  },
  {
    "objectID": "IVPMultistep.html#sec-ivpderivmultistep",
    "href": "IVPMultistep.html#sec-ivpderivmultistep",
    "title": "29  Multi-Step Methods for IVP",
    "section": "29.4 Derivation of multi-step methods",
    "text": "29.4 Derivation of multi-step methods\n\n\n\n\n\n\nAdvanced: Not covered in class\n\n\n\nThis derivation closely follows the proof in Burden and Faires, pages 304-305.\n\n\nFirst we write:\n\\[\n\\begin{aligned}\ny(t_{i+1}) - y(t_{i}) &= \\int_{t_{i}}^{t_{i+1}} y^{\\prime} (t) dt \\\\\n&= \\int_{t_{i}}^{t_{i+1}} f(t, y(t)) dt\n\\end{aligned}\n\\]\nLet \\(y_i \\approx y(t_i)\\), and rearrange the equation to give us an expression for the approximation at the next time step \\(t_{i+1}\\)\n\\[\ny(t_{i+1}) \\approx y_{i} + \\int_{t_{i}}^{t_{i+1}} f(t, y(t)) dt\n\\tag{29.2}\\]\nThis should remind us of a similar problem we studied earlier, namely the numerical approximation for an integral, i.e. quadrature. Recall that in the earlier case, we chose to replace the function by a polynomial, for which it will be easier to compute the integral. In that case, we used a Lagrange interpolating polynomial.\nIn this case, it will be more convenient to use a Newton backward-difference polynomial because we can more easily incorporate previously calculated values.\nAs reminder we can write the \\(m-1\\) degree interpolating polynomial as (ref: equation 3.13, p. 130 textbook):\n\\[\nP_{m-1} (t) =  \\sum_{k=0}^{m-1}(-1)^k \\binom{-s}{k} \\nabla^k f(t).\n\\tag{29.3}\\]\nWe can then use this polynomial (along with the remainder term) as an approximation to \\(f(t,y)\\)\n\\[\nf(t,y) = P_{m-1}(t) + \\frac{1}{m!} f^{(m)}(\\xi_i,y(\\xi_i))(t - t_{i})(t - t_{i-1}) \\ldots (t - t_{i+1-m})\n\\tag{29.4}\\]\nwhere \\(\\xi_i \\in (t_{i+1-m}, t_i)\\).\nSubstituting Equation 29.3 and Equation 29.4 into Equation 29.2, and taking the integral of both sides, yields:\n\\[\n\\begin{aligned}\n\\int_{t_{i}}^{t_{i+1}} f(t, y(t)) dt &= \\int_{t_{i}}^{t_{i+1}} \\sum_{k=0}^{m-1}  (-1)^k \\binom{-s}{k}\\nabla^{k} f(t_i, y(t_i)) dt \\\\\n&+ \\int_{t_{i}}^{t_{i+1}} \\frac{1}{m!} f^{(m)}(\\xi_i,y(\\xi_i))(t - t_{i})(t - t_{i-1}) \\ldots (t - t_{i+1-m}) dt.\n\\end{aligned}\n\\tag{29.5}\\]\nThe integral is easier to solve by using the variable substitution:\n\\[\n\\begin{aligned}\nt &= t_i + sh \\\\\ndt &= h ds\n\\end{aligned}\n\\]\nin Equation 29.5\n\\[\n\\begin{aligned}\n\\int_{t_{i}}^{t_{i+1}} f(t, y(t)) dt &=  h \\left[ \\sum_{k=0}^{m-1} \\nabla^{k} f(t_i, y(t_i)) \\;  (-1)^k  \\int_{0}^{1} \\binom{-s}{k} ds \\right] \\\\\n&+ \\frac{h^{m+1}}{m!} \\int_{0}^{1}  (s)(s +1) \\ldots (s+m-1) f^{(m)}(\\xi_i,y(\\xi_i)) ds\n\\end{aligned}\n\\]\nThe integrals involving the binomial function are easily computed. Using the values of the computed integrals in Table 5.12, we can write the formula as\n\\[\n\\begin{aligned}\n\\int_{t_{i}}^{t_{i+1}} f(t, y(t)) dt &= h\\left[ f(t_i,y_i) + \\frac{1}{2} \\nabla f(t_i,y_i) + \\frac{5}{12} \\nabla^2 f (t_i,y_i) + \\frac{3}{8} \\nabla^3 f (t_i,y_i)+ \\ldots \\right] \\\\\n&+ \\frac{h^{m+1}}{m!} \\int_{0}^{1} (s)(s +1) \\ldots (s+m-1) f^{(m)}(\\xi_i,y(\\xi_i)) ds\n\\end{aligned}\n\\]\nNote: The header in Table 5.12 in your textbook incorrectly states the second column. It should read \\((-1)^k \\int_0^1 \\binom{-s}{k}ds\\)\n\n\nRecall that \\(\\nabla p_n = p_n - p_{n-1}, n \\geq 1\\) and \\(\\nabla^{k} p_n = \\nabla ( \\nabla^{k-1} p_n ), k \\geq 2\\) (see p. 130, textbook)\nThe last step is to recognize that: \\[\n\\begin{aligned}\n\\nabla^0 f(t_i,y_i) &= f(t_i,y_i) \\\\\n\\nabla^1 f(t_i,y_i) &= f(t_i,y_i) - f(t_{i-1},y_{i-1}) \\\\\n\\nabla^2 f(t_i,y_i) &= \\nabla ( \\nabla^1 f(t_i,y_i)) \\\\\n\\nabla^3 f(t_i,y_i) &= \\nabla ( \\nabla^2 f(t_i,y_i))\n\\end{aligned}\n\\]\nto expand the backward difference terms in the integral, followed by collecting like terms to arrive at the Adams-Bashforth Four-Step (\\(m=4\\)) Method:\n\\[\n\\begin{aligned}\ny_0 &= \\alpha_0, \\; y_1 = \\alpha_1, \\; y_2 = \\alpha_2, \\; y_3 = \\alpha_3, \\\\\ny_{i+1} & =  y_{i} + \\frac{h}{24} \\left[ 55 f(t_{i}, y_{i}) -  59 f(t_{i-1}, y_{i-1}) + 37 f(t_{i-2}, y_{i-2}) - 9 f(t_{i-3}, y_{i-3}) \\right]\n\\end{aligned}\n\\]",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Multi-Step Methods for IVP</span>"
    ]
  },
  {
    "objectID": "IVPMultistep.html#section",
    "href": "IVPMultistep.html#section",
    "title": "29  Multi-Step Methods for IVP",
    "section": "29.5 ",
    "text": "29.5 \n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"",
    "crumbs": [
      "Initial-Value Problems for ODEs",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Multi-Step Methods for IVP</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "30  Summary",
    "section": "",
    "text": "Thank you for checking out this book. Any comments or suggestions would be appreciated. Please feel free to write to me at jcmeza@ucmerced.edu.\nHappy Computing!",
    "crumbs": [
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Apostol, T. M. 1974. Mathematical Analysis. Addison-Wesley\nSeries in Mathematics. Addison-Wesley. https://books.google.com/books?id=Le5QAAAAMAAJ.\n\n\nBailey, David H. 1993. “Algorithm 719: Multiprecision Translation\nand Execution of FORTRAN Programs.” ACM Transactions on\nMathematical Software 19 (3): 288–319. https://doi.org/10.1145/155743.155767.\n\n\nBerrut, Jean-Paul, and Lloyd N. Trefethen. 2004. “Barycentric\nLagrange Interpolation.” SIAM Review 46 (3): 501–17. https://doi.org/10.1137/S0036144502417715.\n\n\nDavis, Philip J. 1975. Interpolation and Approximation. Courier\nCorporation.\n\n\nGoldberg, David. 1991. “What Every Computer Scientist Should Know\nabout Floating-Point Arithmetic.” ACM Computing Surveys\n(CSUR) 23 (1): 548.\n\n\nHennessy, John L., and David A. Patterson. 2011. Computer\nArchitecture, Fifth Edition: A Quantitative Approach. 5th ed. San\nFrancisco, CA, USA: Morgan Kaufmann Publishers Inc.\n\n\nHigham, Nicholas J. 2021. “The Mathematics of Floating-Point\nArithmetic.” LMS Newsletter 493: 35–41. https://nickhigham.files.wordpress.com/2021/04/high21m.pdf.\n\n\nHigham, Nicholas J. 2002. Accuracy and Stability of Numerical\nAlgorithms. 2nd ed. Philadelphia: Society for Industrial; Applied\nMathematics.\n\n\n———. 2004. “The Numerical Stability of Barycentric Lagrange\nInterpolation.” IMA Journal of Numerical Analysis 24\n(4): 547–56. https://doi.org/10.1093/imanum/24.4.547.\n\n\nKnuth, Donald E. 1997. The Art of Computer Programming: Fundamental\nAlgorithms, Volume 1. Addison-Wesley Professional.\n\n\nMeza, Juan C. 2011. “Newton’s Method.” Wiley\nInterdisciplinary Reviews: Computational Statistics 3 (1): 75–78.\n\n\nOverton, Michael L. 2001. Numerical Computing with IEEE Floating\nPoint Arithmetic. Society for Industrial; Applied Mathematics. https://doi.org/10.1137/1.9780898718072.\n\n\nPapakonstantinou, JM. 2009. “Historical Development of the BFGS\nSecant Method and Its Characterization Properties,” April, 1167.\n\n\nShampine, Lawrence F., and M. K. Gordon. 1975. Computer Solution of\nOrdinary Differential Equations: The Initial Value Problem. San\nFrancisco: W. H. Freeman.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "BigONotation.html",
    "href": "BigONotation.html",
    "title": "Appendix A — Big O Notation",
    "section": "",
    "text": "A.1 Introduction\nBig O Notation is frequently used both in mathematics and computer science. While it can be confusing at first, the thing to remember is that it is mostly a means to characterize and understand how an algorithm or an approximation behaves asymptotically. In fact, one of the chief advantages to using this notation is that it hides some of the detailed information that isn’t usually useful to the analysis.\nThe goals of this worksheet are to provide a few examples of Big O notation and to illustrate the usefulness of this notation in numerical analysis. There are two main uses that you will see for Big O Notation in this class. The first use is to understand how an approximation to a given function behaves - for example, when we use Taylor’s Theorem to approximate a function. In these cases, we usually use \\(h\\) or \\(x\\) for our notation and implicitly assume that \\(h\\) or \\(x\\) are small or tending to zero.\nThe second use is to assess the computational workload of an algorithm as a function of the dimension of the problem, typically denoted by \\(n.\\) This case is much more prominent in computer science applications when analyzing the complexity of an algorithm, but we will have use for it as well in numerical analysis. In these cases, we usually assume that \\(n\\) is large or tending to infinity.\nThe power of Big O notation is that it is a high-level description that allows us to quickly say something about an algorithm or an approximation without getting into all the messy details. As such, it can be used to compare two algorithms to see which one is more efficient or to compare two approximations to see which one is more accurate.\nBut beware – in both cases the statements are understood to be in the limit. For specific cases there may be (and usually are) counterexamples.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Big O Notation</span>"
    ]
  },
  {
    "objectID": "BigONotation.html#big-o-for-approximations",
    "href": "BigONotation.html#big-o-for-approximations",
    "title": "Appendix A — Big O Notation",
    "section": "A.2 Big O for approximations",
    "text": "A.2 Big O for approximations\nLet’s first review what we studied in the Error Lectures. There, we introduced the notation, \\(O(h)\\) (read Big O of h), to mean that a quantity is proportional to the value of \\(h\\) (or \\(x\\)).\nFor example, let’s suppose we have a quantity, \\(g(h)\\) that depends on the parameter \\(h\\). If\n\\[\n\\lim\\limits_{h \\to 0}\\frac{\\left | g(h) \\right |}{h} = C &lt; \\infty\n\\tag{A.1}\\]\nfor some constant \\(C,\\) then we say that \\(g\\) is \\(O(h).\\)\n\n\n\n\n\n\nOther formulations\n\n\n\nYou may also see Big O notation written in a different but equivalent form:\n\\[\n|g(h)| \\leq C \\cdot h,\n\\tag{A.2}\\]\nfor some constant \\(C\\) as \\(h\\) goes to \\(0.\\) Also note that in some applications, the quantity we are interested in is known to always be positive, so the absolute values are sometimes left off.\n\n\nIn class, we looked at an approximation to the derivative of a function. After writing down our Taylor polynomial, we discarded all higher order terms, and found that we could approximate the first derivative at \\(x_0\\) by:\n\\[\n\\left | f^{\\prime}(x_0) - \\frac{f(x_0 + h) - f(x_0)}{h} \\right | \\approx  \\left | \\frac{h}{2}f^{\\prime\\prime}(x_0) \\right |.\n\\]\nLetting\n\\[\ng(h) = \\left | \\frac{h}{2}f^{\\prime\\prime}(x_0) \\right |.\n\\]\nand using Equation A.1 we see that:\n\\[\n\\lim\\limits_{h \\to 0}\\frac{\\left | g(h) \\right |}{h} =\\lim\\limits_{h \\to 0}\\frac{\\left | \\frac{h}{2}f^{\\prime\\prime}(x_0) \\right |}{h} =  \\left | \\frac{f^{\\prime\\prime}(x_0)}{2} \\right | = C &lt; \\infty\n\\]\nas long as the second derivative exists and is bounded at \\(x_0.\\)\nAnother use for Big O notation is to describe terms that we throw away when making an approximation. Let’s take for example the Taylor series approximation for \\(\\arctan (x)\\):\n\\[\n\\arctan (x) =  x - \\frac{x^3}{3} + \\frac{x^5}{5} + \\cdots\n\\]\nas \\(x \\rightarrow 0.\\) One can imagine truncating the series after a different number of terms, which would give us different degrees of accuracy, each one of which can be described in Big O notation.\n\\[\n\\begin{aligned}\n\\arctan (x) &=  x - \\frac{x^3}{3} + \\frac{x^5}{5} - \\cdots \\\\\n&=  x - \\frac{x^3}{3} + O(x^5), \\quad \\mbox{... truncate after cubic term}\\\\\n&=  x + O(x^3). \\quad \\quad \\quad \\mbox{... truncate after linear term} \\\\\n\\end{aligned}\n\\]\n\n\n\n\n\n\nTip\n\n\n\nThe easiest way to remember this is that the term used in the Big O notation is the first term of all of the quantities that were thrown away - \\(x^5\\) for the first approximation, and \\(x^3\\) for the second approximation, without any additional constants. Note also, that the sign is not important in the last formulation.\n\n\nThe rationale for using Big O notation is that if \\(x \\rightarrow 0,\\) then of the terms we’re discarding, the error can be described predominantly by the first term discarded as all of the other terms will go to 0 much faster.\n\n\n\n\n\n\nEquals doesn’t mean equal\n\n\n\nA word of caution. As mathematicians, we’re used to thinking that \\(=\\) means that the two sides of the equation are equal. When using Big O notation, this interpretation doesn’t necessarily hold, so one needs to be careful when comparing terms. Donald Knuth calls these one-sided equalities. For a fuller explanation, check out the wikipedia entry on Big O Notation.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Big O Notation</span>"
    ]
  },
  {
    "objectID": "BigONotation.html#big-o-for-computational-workload",
    "href": "BigONotation.html#big-o-for-computational-workload",
    "title": "Appendix A — Big O Notation",
    "section": "A.3 Big O for computational workload",
    "text": "A.3 Big O for computational workload\nIn computer science, Big O notation is also used, but the applications are mostly to characterize the computational workload of an algorithm. Since many algorithms can be quite complicated, it can be difficult to compare one against another. In addition, counting every single arithmetic operation could be tedious (and with modern computers not as important).\nNonetheless, it is important to understand how the workload will behave as the size of a problem increases. An algorithm that works fine on a problem of dimension \\(1, 2,\\) or \\(3,\\) can be prohibitively expensive when applied to a problem with dimension \\(1,000,000\\). As such, computer scientists have used Big O notation to express how this workload will grow with the size of the problem without diving into all of the details of the algorithm. Recall that unlike the first case, when we use Big \\(O\\) notation here, \\(n\\) is assumed to be large.\n\n\n\n\n\n\nOther formulations\n\n\n\nMuch like before you may see Big O notation written in a different form for the case using the problem size. According to Knuth(Knuth 1997), the number \\(x_n\\) is said to be \\(O(f(n))\\):\n\\[\n|x_n| \\leq M \\ | f(n) |, \\quad \\forall \\mbox{ integers }n \\geq n_0\n\\]\nfor some constants \\(M &gt; 0, n_0 &gt; 0.\\) It should also be noted that neither one of the constants \\(M, n_0\\) are known.\n\n\nLet’s take a simple example. Suppose we wanted to compute the mean of a set of \\(n\\) numbers. The formula is:\n\\[\n\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i\n\\]\nIt is easy to see that the formula entails adding \\(n\\) numbers, which amounts to \\(n-1\\) additions. We then have to divide by \\(n\\), so there’s 1 division. The total is therefore \\(n\\) floating point operations (flops).\nEverything else being equal, that’s also the computational workload for this simple algorithm. If \\(n=100\\), then we have \\(100\\) flops; if \\(n = 1,000,000\\) then we have \\(1,000,000\\) flops.\nWe say that this algorithm is \\(O(n)\\), because the workload increases linearly with the dimension of the problem \\(n\\).\n\n\n\n\n\n\nImportant\n\n\n\nAn important point to remember is that we are only interested with how the computational workload of an algorithm behaves as the dimension increases, and not with the details of the computation.\n\n\nConsider the following modification to the problem.\n\\[\n\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} w_i x_i,\n\\] where the \\(w_i\\) are weights assigned to each of the \\(x_i\\). If we counted flops, then in addition to the count before, we also have \\(n\\) multiplications to consider, one for each of the weights times the \\(x_i\\). That increases the cost of the computation, but it only grows by a constant factor - the flop count is now \\(2n\\). The important point is that the algorithm is still \\(O(n)\\).\nFinally, let’s consider a slightly more complicated problem. Let’s suppose we want to multiply a matrix \\(A\\) by a vector \\(x.\\) As you know, we can write this as:\n\\[\n\\begin{bmatrix}\na_{11} & a_{12} & \\cdots & a_{1n}\\\\         \na_{21} & a_{22} & \\cdots & a_{2n}\\\\          \\vdots & \\vdots & \\ddots & \\vdots\\\\\na_{n1} & a_{n2} & \\cdots & a_{nn}      \\end{bmatrix}  \n\\begin{bmatrix}         \nx_{1} \\\\         \nx_{2} \\\\          \n\\vdots \\\\          \nx_{n}     \n\\end{bmatrix}\n      =     \n\\begin{bmatrix}         \nb_{1} \\\\         \nb_{2} \\\\          \n\\vdots \\\\          \nb_{n}     \n\\end{bmatrix}\n\\]\nwhere\n\\[\nb_{i}= a_{i1} x_{1} + a_{i2} x_{2} +\\cdots+ a_{in}x_{n} = \\sum_{k=1}^n a_{ik}x_{k}, \\qquad i = 1, 2, \\ldots, n.\n\\]\nWere we to write this in code to compute \\(b\\) we would need to have a nested loop to compute all of the elements of \\(b\\).\n\n\n\n\n\n\nNested Loops\n\n\n\nWhen we say a nested loop, we mean that a for loop is inside another for loop. The first loop is called the outer loop versus the one inside, which is called the inner loop. That means whatever computational work is being done in the inner loop has to be done at each iteration of the outer loop.\n\n\nIn python, the matrix-vector multiply might look something like this:\n# Example: Multiply an nxn matrix a by a vector x of dimension n\n# (assume all vectors and matrices have been initialized somewhere else)\n#\nfor i in range (0,n): # outer loop\n  for k in range (0,n): # inner loop\n    b[i] = b[i] + a[i,k]*x[k]\n    \nHere, we see that each of the \\(b_i\\) terms will require \\(n\\) multiplications and \\(n-1\\) additions using the same argument as before. But we have to do this for all \\(n\\) of the \\(b_i.\\) So the total work is \\(n*(n + n-1) = 2n^2 - n\\) flops. We say that this algorithm Is \\(O(n^2)\\) since it grows as the square of the dimension of the problem. Of course the linear term is still there, but the \\(n^2\\) term will dominate the computational work. Here, one can see that the workload will increase much faster with the dimension of the problem than the previous example.\n\n\n\n\n\n\nTip\n\n\n\nOne easy way to determine the Big O for computational workload is to look at the number of nested for loops required to compute a quantity. Notice that in the first 2 examples, we could compute the mean using one for loop. In the second example of a matrix-vector multiply, we had to have a for loop inside another for loop. That usually means the algorithm is \\(O(n^2)\\), the number 2 coming from the 2-level nested for loop and assuming both loops are of the same size.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Big O Notation</span>"
    ]
  },
  {
    "objectID": "BigONotation.html#summary-why-is-this-important",
    "href": "BigONotation.html#summary-why-is-this-important",
    "title": "Appendix A — Big O Notation",
    "section": "A.4 Summary: Why is this important?",
    "text": "A.4 Summary: Why is this important?\nAs we said before, the power of Big O notation is that it is a high-level description that allows us to say something about an algorithm or an approximation. This is useful when comparing the computational efficiency of algorithms or when comparing the accuracy of two numerical approximations. Most of all, it is critical to understand that the Big O notation only gives us a sense of how the algorithm/approximation behaves in the limit.\nFor example, say we want to quickly estimate and compare running times of two different algorithms. Suppose for the sake of argument that the time to compute a given quantity was 1 second on a computer of your choosing for a problem of size \\(n=10\\).\nIf I use an \\(O(n)\\) algorithm, and if the problem grows by a factor of 1000, then the algorithm should only take about \\(1 \\times 1000\\) seconds or about 16.67 minutes. Again, there may be constants involved, but this should be a good estimate.\nBut if the algorithm is \\(O(n^2)\\), the time will grow as the square of the size of the problem. That same problem would take about \\(1 \\times 1000^2\\) seconds or about 11.6 days.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Big O Notation</span>"
    ]
  },
  {
    "objectID": "BigONotation.html#references",
    "href": "BigONotation.html#references",
    "title": "Appendix A — Big O Notation",
    "section": "A.5 References",
    "text": "A.5 References\n\nMath 130 Lecture Notes\nBig O notation, https://en.wikipedia.org/wiki/Big_O_notation\nThe Art of Computer Programming, (Knuth 1997)\n\n\n\nCode\ntoday &lt;- Sys.Date()\nformat(today, format=\"Revised: %B %d %Y\")\n\n\n[1] \"Revised: May 07 2024\"\n\n\n\n\n\n\nKnuth, Donald E. 1997. The Art of Computer Programming: Fundamental Algorithms, Volume 1. Addison-Wesley Professional.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Big O Notation</span>"
    ]
  },
  {
    "objectID": "IVPExtUniq.html",
    "href": "IVPExtUniq.html",
    "title": "Appendix B — Existence and Uniqueness of IVP",
    "section": "",
    "text": "B.1 The Initial Value Problem (IVP)\nThe initial-value problem has the form:\n\\[  y^{\\prime} = \\frac{dy}{dt} = f(t,y), \\quad a \\leq t \\leq b, \\quad y(a) = \\alpha  \\tag{B.1}\\]\nIn the general case, we would consider a system of ODEs, i.e.\n\\[  y^{\\prime} = \\frac{dy}{dt} = f(t,y), \\quad a \\leq t \\leq b, \\quad y(a) = \\alpha \\]\nwhere \\[\ny^{\\prime} = \\begin{bmatrix} y^{\\prime}_1 \\\\ \\vdots \\\\ y^{\\prime}_n \\end{bmatrix} \\; f(t,y) = \\begin{bmatrix} f_1(t,y_1, \\ldots, y_n) \\\\ \\vdots \\\\ f_n(t,y_1, \\dots, y_n)\\end{bmatrix}\n\\tag{B.2}\\]\nSince all of the solution techniques we will study can be generalized to a system of ODEs, we will keep it simple for now and assume we have an IVP of the form given by Equation B.1.\nReduction of higher-order ODE to a system of ODEs\nIt can be shown that a general n-th order ODE can be written in the form of a system of ODEs.\n\\[\ny^{(m)}(t) = f(t, y(t), y^{\\prime}(t), \\ldots, y^{(m-1)}(t)).\n\\]",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Existence and Uniqueness of IVP</span>"
    ]
  },
  {
    "objectID": "IVPExtUniq.html#sec-ivpextuniq",
    "href": "IVPExtUniq.html#sec-ivpextuniq",
    "title": "Appendix B — Existence and Uniqueness of IVP",
    "section": "",
    "text": "Advanced\n\n\n\nMost software packages assume that the IVP is given in autonomous form.\n\\[\n\\frac{dy}{dt} = f(y)\n\\]\ni.e. \\(f\\) does not depend explicitly on \\(t\\). This is generally achieved through the addition of an additional equation of the form …",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Existence and Uniqueness of IVP</span>"
    ]
  },
  {
    "objectID": "IVPExtUniq.html#lipschitz-condition-and-convex-sets",
    "href": "IVPExtUniq.html#lipschitz-condition-and-convex-sets",
    "title": "Appendix B — Existence and Uniqueness of IVP",
    "section": "B.2 Lipschitz Condition and Convex Sets",
    "text": "B.2 Lipschitz Condition and Convex Sets\nTo start off with, let’s present a few definitions that will prove useful in our analyses.\n\n\nRemark: One way to think about a Lipschitz condition (in a loose sense) is as being somewhere between continuity and continuously differentiable. Another way to think about it is as a strong form of uniform continuity.\nDefinition. A function f(t,y) is said to satisfy a Lipschitz condition in the variable \\(y\\) on a set \\(D \\subset \\mathbb{R}^2\\) if a constant \\(L &gt; 0\\) exists with\n\\[\n| f(t,y_1) - f(t,y_2) | \\leq L | y_1 - y_2 |,\n\\tag{B.3}\\]\nwhenever \\((t,y_1)\\) and \\((t,y_2)\\) are in \\(D\\). The constant \\(L\\) is called a Lipschitz constant for \\(f\\).\nKnowing whether a function satisfies a Lipschitz condition, will often prove to be useful in our analysis of IVP.\nExample.\nLet \\(f(t,y) = t |y|\\) on \\(D = {(t,y) | 1 \\leq t \\leq 2, \\; -3 \\leq y \\leq 4 }\\).\nFor any two points \\((t, y_1), (t,y_2)\\), we can write\n\\[\n\\begin{aligned}\n| f(t,y_1) - f(t,y_2)| &= | \\; t|y_1| - t|y_2| \\; |, \\\\\n&= t \\; | \\; |y_1| - |y_2| \\; |, \\\\\n&\\leq 2 \\; | y_1 - y_2 |.\n\\end{aligned}\n\\]\n\n\nThe reverse triangle inequality states that \\(\\big| \\; |y_1| - |y_2|  \\; \\big| \\leq | y_1 - y_2 |\\) (e.g., see (Apostol 1974) )\nThe last line is true because \\(t \\leq 2\\) on the interval and using the (reverse) triangle inequality.\nAs a result, \\(f\\) satisfies a Lipschitz condition on \\(D\\) in the variable \\(y\\) with constant 2.\nNext we develop the notion of a convex set.\nDefinition. A set \\(D \\subset \\mathbb{R}^2\\) is said to be convex if whenever \\((t,y_1)\\) and \\((t,y_2)\\) belong to \\(D\\), then\n\\[((1-\\lambda)t_1 + \\lambda t_2, (1-\\lambda) y_1 + \\lambda y_2 ) \\tag{B.4}\\]\nalso belongs to \\(D\\) for every \\(\\lambda\\) in \\([0,1]\\).\n\n\n\n\n\n\nFigure B.1: Convex Set\n\n\n\nGeometrically, (see Figure B.1) what this says is that whenever 2 points belong to \\(D\\) , then every point in the straight-line segment connecting the 2 points also belongs to \\(D\\).\nExample.\n\nIn addition to the previous 2 definitions, we will sometimes use the following characterization to help us show Lipschitz continuity under certain assumptions on the IVP.\nTheorem 5.3 Suppose \\(f(t,y)\\) is defined on a convex set \\(D \\subset \\mathbb{R}^2.\\) If a constant \\(L &gt; 0\\) exists with\n\\[ \\left| \\frac{\\partial f}{\\partial y} (t,y) \\right| \\leq L, \\quad \\forall \\ (t,y) \\in D, \\tag{B.5}\\]\nthen \\(f\\) satisfies a Lipschitz condition on D in the variable \\(y\\) with Lipschitz constant \\(L\\).\nProof. See Exercise 6 (Straightforward application of MVT).\nRemark: It will be useful to know when a function is Lipschitz continuous and Equation B.5 is sometimes easier to apply.\nRemark: It should be noted that Equation B.5 is only a sufficient condition. In our previous example, \\(f(t,y) = t |y |\\) is Lipschitz continuous but the partial derivative does not exist at \\(y=0\\).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Existence and Uniqueness of IVP</span>"
    ]
  },
  {
    "objectID": "IVPExtUniq.html#fundamental-existence-and-uniqueness-of-ivp",
    "href": "IVPExtUniq.html#fundamental-existence-and-uniqueness-of-ivp",
    "title": "Appendix B — Existence and Uniqueness of IVP",
    "section": "B.3 Fundamental Existence and Uniqueness of IVP",
    "text": "B.3 Fundamental Existence and Uniqueness of IVP\nWe’re now in a position to state the fundamental existence and uniqueness theorem for the IVP problem Equation B.1 (or Equation B.2 ).\nTheorem 5.4 Suppose \\(D = \\{ (t,y) | \\ a \\leq t \\leq b, \\ -\\infty &lt; y &lt; \\infty \\},\\) and that \\(f(t,y)\\) is continuous on \\(D\\). If \\(f\\) satisfies a Lipschitz condition on D in the variable \\(y\\) , then the initial-value problem\n\\[ y^{\\prime}(t) = f(t,y), \\quad a \\leq t \\leq b, \\quad y(a) = \\alpha \\]\nhas a unique solution \\(y(t)\\) for \\(a \\leq t \\leq b\\).\nProof. See any text on ODEs (e.g. Birkhoff and Rota). For those interested see a brief sketch of the proof below.\nExample: Show that the following IVP has a unique solution.\n\\[\n\\begin{aligned}\ny^{\\prime} &= 1 + tsin(ty) \\quad 0\\leq t \\leq 2 \\\\\ny(a) &= y(0) = 0\n\\end{aligned}\n\\]\nSolution:\nTo start with, we can see that \\(f(t,y)\\) is continuous on \\(D\\). So all we need to show is that it also satisfies a Lipschitz condition. To show this, first hold \\(t\\) constant and apply the MVT to \\(f(t,y) = 1 + t sin(ty).\\)\nFor \\(y_1 &lt; y_2\\) the MVT states that there exists \\(\\xi \\in (y_1, y_2)\\) such that\n\\[\n\\begin{aligned}\n\\frac{f(t,y_2) - f(t,y_1)}{y_2 - y_1} &= \\frac{\\partial}{\\partial y} f(t, \\xi) \\\\\n&= t^2 cos (\\xi t)\n\\end{aligned}\n\\]\nRearranging and taking absolute values on both sides we get:\n\\[\n\\begin{aligned}\n\\left| f(t,y_2) - f(t,y_1) \\right| &= | y_2 - y_1 | \\cdot | t^2 cos (\\xi t) | \\\\\n&\\leq 4 | y_2 - y_1 |\n\\end{aligned}\n\\]\nsince \\(0 \\leq t \\leq 2\\) and \\(|cos(\\xi t)|\\) is bounded by 1. This shows that \\(f\\) satisfies a Lipschitz condition on \\(y\\) with \\(L=4\\). Since \\(f\\) is continuous on \\(D\\), by our theorem the IVP has a unique solution.\nIn class example: Show uniqueness for \\[\n\\begin{aligned}\ny^{\\prime} &= \\frac{sin (2t) - 2ty}{t^2} \\quad 1 \\leq t \\leq 2 \\\\\ny(1) &=  2\n\\end{aligned}\n\\]\n\n\n\n\n\n\nSketch of proof (Shampine and Gordon 1975), pp. 10-12\n\n\n\n\nAssume that a solution extends from \\(y(a)\\) to \\(t_i\\).\nIt can be shown that the solution has to extend somewhere on the boundary of the box region \\(R\\), here denoted as a box.\nWe then have to show that the solution can’t reach the top or the bottom of \\(R\\). Here we would use the Lipschitz condition.\nSo the solution has to reach the right side of the box \\(R\\), with \\(\\delta\\) bounded away from 0.\nRepeat steps 1-4 until you reach \\(t = b\\).\n\n\n\n\n\n\n\nFigure B.2: Sketch of Proof",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Existence and Uniqueness of IVP</span>"
    ]
  },
  {
    "objectID": "IVPExtUniq.html#well-posed-problems",
    "href": "IVPExtUniq.html#well-posed-problems",
    "title": "Appendix B — Existence and Uniqueness of IVP",
    "section": "B.4 Well-Posed Problems",
    "text": "B.4 Well-Posed Problems\nIt will be important to understand when we can expect to be able to compute a solution to a problem in the situation when there are small changes to the statement of the IVP.\nTo do this we will need one more definition.\nDefinition. The IVP (Equation B.1) is said to be well-posed if:\n\nA unique solution, \\(y(t)\\), to the problem exists, and\nThere exist constants \\(\\epsilon_0\\) and \\(k &gt; 0\\) such that for any \\(\\epsilon\\) with \\(\\epsilon_0 &gt; \\epsilon &gt; 0\\), whenever \\(\\delta(t)\\) is continuous with \\(|\\delta(t)| &lt; \\epsilon\\) for all \\(t\\) in \\([a,b]\\), and when\n\\(| \\delta_0 | &lt; \\epsilon\\),\n\nthe IVP\n\\[\n\\frac{dz}{dt} = f(t,z) + \\delta(t), \\; a \\leq t \\leq b, \\; z(a) = \\alpha + \\delta_0,\n\\tag{B.6}\\] has a unique solution \\(z(t)\\) that satisfies \\[\n| z(t) - y(t) | &lt; k \\epsilon \\; \\forall t \\in [a,b]\n\\]\nEquation B.6 is called a perturbed problem associated with the original IVP given by Equation B.1.\n\n\nNumerical methods always solve a perturbed problem due to roundoff error on every computer. This leads to the notion that a numerical algorithm always solves (at best) a “nearby problem”.\n\n\n\n\n\n\nImportant\n\n\n\nRemark: The idea of “well-posed” refers to a property of a problem not the algorithm. For algorithms we talk about stability instead.\n\n\nThis leads very naturally to ask, under what conditions is an initial value problem “well-posed”? We will tackle this problem next with a theorem that provides one criteria that can be used based on being able to show that \\(f(t,y)\\) satisfies the Lipschitz condtion.\n\nTheorem 5.6 Suppose \\(D = \\{ (t,y) | \\ a \\leq t \\leq b, \\; -\\infty &lt; y &lt; \\infty \\}.\\) If \\(f\\) is continuous and satisfies a Lipschitz condition in the variable \\(y\\) on the set \\(D\\), then the initial-value problem\n\\[  \\frac{dy}{dt} = f(t,y), \\quad a \\leq t \\leq b, \\quad y(a) = \\alpha  \\tag{B.7}\\]\nis well-posed.\nIn class example Show that the IVP defined by: \\[\n\\begin{aligned}\ny^{\\prime} &= \\frac{1+y}{1+t} \\quad 0 \\leq t \\leq 1 \\\\\ny(0) &= 1\n\\end{aligned}\n\\] Solution\nUse Theorem 5.6 to show the IVP is well-posed. Consider \\[\n\\begin{aligned}\n\\frac{\\partial f}{\\partial y} (t,y) &= \\frac{\\partial}{\\partial y} \\left[ \\frac{1 + y}{1 + t} \\right] \\\\\n\\frac{\\partial f}{\\partial y} (t,y) &=  \\frac{1}{1 + t} \\\\\n\\left| \\frac{\\partial f}{\\partial y} (t,y) \\right| &= \\left| \\frac{1}{1 + t} \\right| \\leq 1,\n\\end{aligned}\n\\] since \\(0 \\leq t \\leq 1\\). Since the partial derivative is bounded, by Theorem 5.3, \\(f\\) is Lipschitz, hence by Theorem 5.6, the IVP is well-posed.\n\n\n\n\nApostol, T. M. 1974. Mathematical Analysis. Addison-Wesley Series in Mathematics. Addison-Wesley. https://books.google.com/books?id=Le5QAAAAMAAJ.\n\n\nShampine, Lawrence F., and M. K. Gordon. 1975. Computer Solution of Ordinary Differential Equations: The Initial Value Problem. San Francisco: W. H. Freeman.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Existence and Uniqueness of IVP</span>"
    ]
  },
  {
    "objectID": "datasets.html",
    "href": "datasets.html",
    "title": "Appendix C — DataSets",
    "section": "",
    "text": "This is a future section that will contain pointers to various open source data sets that are used in the book for the examples.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>DataSets</span>"
    ]
  }
]